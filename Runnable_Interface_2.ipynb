{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb9a1021-80d9-47df-b0b8-60f8b9f578af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI 1\\.conda\\envs\\oaivenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.runnables import RunnablePassthrough,RunnableLambda, Runnable, RunnableParallel,RunnableConfig\n",
    "from langchain_core.messages import AIMessage\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools.render import render_text_description\n",
    "from langchain.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate,SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from operator import itemgetter\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "import json\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import FAISS,Chroma\n",
    "from operator import itemgetter\n",
    "import time\n",
    "import grandalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7baa65c0-b251-4a5c-a250-a1fd841db12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv(\"D:\\LLM Courses\\Master Langchain Udemy\\.env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "690ea463-62e0-4bb9-824a-12544700ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "# llm=ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0704ec51-a830-4859-870e-bd51e3e89e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_template(\n",
    "    template=\"Tell me a Joke about {topic}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e5e322f-eadb-44ee-a87c-fe9d929670ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87f1b53-bc30-481b-a2ee-8a1d68a183e4",
   "metadata": {},
   "source": [
    "<h2> Input Schema </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdec1c4b-c237-4dcb-b63d-2dea95828551",
   "metadata": {},
   "source": [
    "<h5>The Input Schema of the chain is the input schema of its first part, the prompt</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f516968-f75b-4b50-9fa3-76d6a6504baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PromptInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'topic': {'title': 'Topic', 'type': 'string'}},\n",
       " 'required': ['topic']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1345d7c-1a5a-48a1-a8ab-c28e02e51563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PromptInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'topic': {'title': 'Topic', 'type': 'string'}},\n",
       " 'required': ['topic']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6777a6c-9a01-4a5f-982c-fd520100f156",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ChatGoogleGenerativeAIInput',\n",
       " 'anyOf': [{'type': 'string'},\n",
       "  {'$ref': '#/definitions/StringPromptValue'},\n",
       "  {'$ref': '#/definitions/ChatPromptValueConcrete'},\n",
       "  {'type': 'array',\n",
       "   'items': {'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "     {'$ref': '#/definitions/HumanMessage'},\n",
       "     {'$ref': '#/definitions/ChatMessage'},\n",
       "     {'$ref': '#/definitions/SystemMessage'},\n",
       "     {'$ref': '#/definitions/FunctionMessage'},\n",
       "     {'$ref': '#/definitions/ToolMessage'}]}}],\n",
       " 'definitions': {'StringPromptValue': {'title': 'StringPromptValue',\n",
       "   'description': 'String prompt value.',\n",
       "   'type': 'object',\n",
       "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'StringPromptValue',\n",
       "     'enum': ['StringPromptValue'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['text']},\n",
       "  'ToolCall': {'title': 'ToolCall',\n",
       "   'type': 'object',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'object'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'type': {'title': 'Type', 'enum': ['tool_call'], 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id']},\n",
       "  'InvalidToolCall': {'title': 'InvalidToolCall',\n",
       "   'type': 'object',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'error': {'title': 'Error', 'type': 'string'},\n",
       "    'type': {'title': 'Type',\n",
       "     'enum': ['invalid_tool_call'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'error']},\n",
       "  'UsageMetadata': {'title': 'UsageMetadata',\n",
       "   'type': 'object',\n",
       "   'properties': {'input_tokens': {'title': 'Input Tokens', 'type': 'integer'},\n",
       "    'output_tokens': {'title': 'Output Tokens', 'type': 'integer'},\n",
       "    'total_tokens': {'title': 'Total Tokens', 'type': 'integer'}},\n",
       "   'required': ['input_tokens', 'output_tokens', 'total_tokens']},\n",
       "  'AIMessage': {'title': 'AIMessage',\n",
       "   'description': 'Message from an AI.\\n\\nAIMessage is returned from a chat model as a response to a prompt.\\n\\nThis message represents the output of the model and consists of both\\nthe raw output as returned by the model together standardized fields\\n(e.g., tool calls, usage metadata) added by the LangChain framework.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ai',\n",
       "     'enum': ['ai'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'},\n",
       "    'tool_calls': {'title': 'Tool Calls',\n",
       "     'default': [],\n",
       "     'type': 'array',\n",
       "     'items': {'$ref': '#/definitions/ToolCall'}},\n",
       "    'invalid_tool_calls': {'title': 'Invalid Tool Calls',\n",
       "     'default': [],\n",
       "     'type': 'array',\n",
       "     'items': {'$ref': '#/definitions/InvalidToolCall'}},\n",
       "    'usage_metadata': {'$ref': '#/definitions/UsageMetadata'}},\n",
       "   'required': ['content']},\n",
       "  'HumanMessage': {'title': 'HumanMessage',\n",
       "   'description': 'Message from a human.\\n\\nHumanMessages are messages that are passed in from a human to the model.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Instantiate a chat model and invoke it with the messages\\n        model = ...\\n        print(model.invoke(messages))',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'human',\n",
       "     'enum': ['human'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'ChatMessage': {'title': 'ChatMessage',\n",
       "   'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'chat',\n",
       "     'enum': ['chat'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role']},\n",
       "  'SystemMessage': {'title': 'SystemMessage',\n",
       "   'description': 'Message for priming AI behavior.\\n\\nThe system message is usually passed in as the first of a sequence\\nof input messages.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Define a chat model and invoke it with the messages\\n        print(model.invoke(messages))',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'system',\n",
       "     'enum': ['system'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['content']},\n",
       "  'FunctionMessage': {'title': 'FunctionMessage',\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.\\n\\nFunctionMessage are an older version of the ToolMessage schema, and\\ndo not contain the tool_call_id field.\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'function',\n",
       "     'enum': ['function'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['content', 'name']},\n",
       "  'ToolMessage': {'title': 'ToolMessage',\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.\\n\\nToolMessages contain the result of a tool invocation. Typically, the result\\nis encoded inside the `content` field.\\n\\nExample: A ToolMessage representing a result of 42 from a tool call with id\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        ToolMessage(content=\\'42\\', tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\')\\n\\n\\nExample: A ToolMessage where only part of the tool output is sent to the model\\n    and the full output is passed in to artifact.\\n\\n    .. versionadded:: 0.2.17\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        tool_output = {\\n            \"stdout\": \"From the graph we can see that the correlation between x and y is ...\",\\n            \"stderr\": None,\\n            \"artifacts\": {\"type\": \"image\", \"base64_data\": \"/9j/4gIcSU...\"},\\n        }\\n\\n        ToolMessage(\\n            content=tool_output[\"stdout\"],\\n            artifact=tool_output,\\n            tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\',\\n        )\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'tool',\n",
       "     'enum': ['tool'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'},\n",
       "    'artifact': {'title': 'Artifact'},\n",
       "    'status': {'title': 'Status',\n",
       "     'default': 'success',\n",
       "     'enum': ['success', 'error'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['content', 'tool_call_id']},\n",
       "  'ChatPromptValueConcrete': {'title': 'ChatPromptValueConcrete',\n",
       "   'description': 'Chat prompt value which explicitly lists out the message types it accepts.\\nFor use in external schemas.',\n",
       "   'type': 'object',\n",
       "   'properties': {'messages': {'title': 'Messages',\n",
       "     'type': 'array',\n",
       "     'items': {'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "       {'$ref': '#/definitions/HumanMessage'},\n",
       "       {'$ref': '#/definitions/ChatMessage'},\n",
       "       {'$ref': '#/definitions/SystemMessage'},\n",
       "       {'$ref': '#/definitions/FunctionMessage'},\n",
       "       {'$ref': '#/definitions/ToolMessage'}]}},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ChatPromptValueConcrete',\n",
       "     'enum': ['ChatPromptValueConcrete'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['messages']}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not the same as the the chain and the prompt\n",
    "llm.input_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7d711c-a094-4759-b1f5-3623ef7a45bf",
   "metadata": {},
   "source": [
    "<h3>Output Schema</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b06cf2-c065-49c5-ba49-9b3e2d852d7f",
   "metadata": {},
   "source": [
    "<h5>The Output Schema of the chain is the output schema of its last part, in this case a ChatModel, which outputs a ChatMessage</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25bd8448-09f7-47d2-9c0d-f3e738d37e3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ChatGoogleGenerativeAIOutput',\n",
       " 'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "  {'$ref': '#/definitions/HumanMessage'},\n",
       "  {'$ref': '#/definitions/ChatMessage'},\n",
       "  {'$ref': '#/definitions/SystemMessage'},\n",
       "  {'$ref': '#/definitions/FunctionMessage'},\n",
       "  {'$ref': '#/definitions/ToolMessage'}],\n",
       " 'definitions': {'ToolCall': {'title': 'ToolCall',\n",
       "   'type': 'object',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'object'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'type': {'title': 'Type', 'enum': ['tool_call'], 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id']},\n",
       "  'InvalidToolCall': {'title': 'InvalidToolCall',\n",
       "   'type': 'object',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'error': {'title': 'Error', 'type': 'string'},\n",
       "    'type': {'title': 'Type',\n",
       "     'enum': ['invalid_tool_call'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'error']},\n",
       "  'UsageMetadata': {'title': 'UsageMetadata',\n",
       "   'type': 'object',\n",
       "   'properties': {'input_tokens': {'title': 'Input Tokens', 'type': 'integer'},\n",
       "    'output_tokens': {'title': 'Output Tokens', 'type': 'integer'},\n",
       "    'total_tokens': {'title': 'Total Tokens', 'type': 'integer'}},\n",
       "   'required': ['input_tokens', 'output_tokens', 'total_tokens']},\n",
       "  'AIMessage': {'title': 'AIMessage',\n",
       "   'description': 'Message from an AI.\\n\\nAIMessage is returned from a chat model as a response to a prompt.\\n\\nThis message represents the output of the model and consists of both\\nthe raw output as returned by the model together standardized fields\\n(e.g., tool calls, usage metadata) added by the LangChain framework.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ai',\n",
       "     'enum': ['ai'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'},\n",
       "    'tool_calls': {'title': 'Tool Calls',\n",
       "     'default': [],\n",
       "     'type': 'array',\n",
       "     'items': {'$ref': '#/definitions/ToolCall'}},\n",
       "    'invalid_tool_calls': {'title': 'Invalid Tool Calls',\n",
       "     'default': [],\n",
       "     'type': 'array',\n",
       "     'items': {'$ref': '#/definitions/InvalidToolCall'}},\n",
       "    'usage_metadata': {'$ref': '#/definitions/UsageMetadata'}},\n",
       "   'required': ['content']},\n",
       "  'HumanMessage': {'title': 'HumanMessage',\n",
       "   'description': 'Message from a human.\\n\\nHumanMessages are messages that are passed in from a human to the model.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Instantiate a chat model and invoke it with the messages\\n        model = ...\\n        print(model.invoke(messages))',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'human',\n",
       "     'enum': ['human'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'ChatMessage': {'title': 'ChatMessage',\n",
       "   'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'chat',\n",
       "     'enum': ['chat'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role']},\n",
       "  'SystemMessage': {'title': 'SystemMessage',\n",
       "   'description': 'Message for priming AI behavior.\\n\\nThe system message is usually passed in as the first of a sequence\\nof input messages.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Define a chat model and invoke it with the messages\\n        print(model.invoke(messages))',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'system',\n",
       "     'enum': ['system'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['content']},\n",
       "  'FunctionMessage': {'title': 'FunctionMessage',\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.\\n\\nFunctionMessage are an older version of the ToolMessage schema, and\\ndo not contain the tool_call_id field.\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'function',\n",
       "     'enum': ['function'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['content', 'name']},\n",
       "  'ToolMessage': {'title': 'ToolMessage',\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.\\n\\nToolMessages contain the result of a tool invocation. Typically, the result\\nis encoded inside the `content` field.\\n\\nExample: A ToolMessage representing a result of 42 from a tool call with id\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        ToolMessage(content=\\'42\\', tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\')\\n\\n\\nExample: A ToolMessage where only part of the tool output is sent to the model\\n    and the full output is passed in to artifact.\\n\\n    .. versionadded:: 0.2.17\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        tool_output = {\\n            \"stdout\": \"From the graph we can see that the correlation between x and y is ...\",\\n            \"stderr\": None,\\n            \"artifacts\": {\"type\": \"image\", \"base64_data\": \"/9j/4gIcSU...\"},\\n        }\\n\\n        ToolMessage(\\n            content=tool_output[\"stdout\"],\\n            artifact=tool_output,\\n            tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\',\\n        )\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'tool',\n",
       "     'enum': ['tool'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'},\n",
       "    'artifact': {'title': 'Artifact'},\n",
       "    'status': {'title': 'Status',\n",
       "     'default': 'success',\n",
       "     'enum': ['success', 'error'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['content', 'tool_call_id']}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.output_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4286c156-5ad8-48e6-9c62-000bd802c5d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ChatGoogleGenerativeAIOutput',\n",
       " 'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "  {'$ref': '#/definitions/HumanMessage'},\n",
       "  {'$ref': '#/definitions/ChatMessage'},\n",
       "  {'$ref': '#/definitions/SystemMessage'},\n",
       "  {'$ref': '#/definitions/FunctionMessage'},\n",
       "  {'$ref': '#/definitions/ToolMessage'}],\n",
       " 'definitions': {'ToolCall': {'title': 'ToolCall',\n",
       "   'type': 'object',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'object'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'type': {'title': 'Type', 'enum': ['tool_call'], 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id']},\n",
       "  'InvalidToolCall': {'title': 'InvalidToolCall',\n",
       "   'type': 'object',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'error': {'title': 'Error', 'type': 'string'},\n",
       "    'type': {'title': 'Type',\n",
       "     'enum': ['invalid_tool_call'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'error']},\n",
       "  'UsageMetadata': {'title': 'UsageMetadata',\n",
       "   'type': 'object',\n",
       "   'properties': {'input_tokens': {'title': 'Input Tokens', 'type': 'integer'},\n",
       "    'output_tokens': {'title': 'Output Tokens', 'type': 'integer'},\n",
       "    'total_tokens': {'title': 'Total Tokens', 'type': 'integer'}},\n",
       "   'required': ['input_tokens', 'output_tokens', 'total_tokens']},\n",
       "  'AIMessage': {'title': 'AIMessage',\n",
       "   'description': 'Message from an AI.\\n\\nAIMessage is returned from a chat model as a response to a prompt.\\n\\nThis message represents the output of the model and consists of both\\nthe raw output as returned by the model together standardized fields\\n(e.g., tool calls, usage metadata) added by the LangChain framework.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ai',\n",
       "     'enum': ['ai'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'},\n",
       "    'tool_calls': {'title': 'Tool Calls',\n",
       "     'default': [],\n",
       "     'type': 'array',\n",
       "     'items': {'$ref': '#/definitions/ToolCall'}},\n",
       "    'invalid_tool_calls': {'title': 'Invalid Tool Calls',\n",
       "     'default': [],\n",
       "     'type': 'array',\n",
       "     'items': {'$ref': '#/definitions/InvalidToolCall'}},\n",
       "    'usage_metadata': {'$ref': '#/definitions/UsageMetadata'}},\n",
       "   'required': ['content']},\n",
       "  'HumanMessage': {'title': 'HumanMessage',\n",
       "   'description': 'Message from a human.\\n\\nHumanMessages are messages that are passed in from a human to the model.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Instantiate a chat model and invoke it with the messages\\n        model = ...\\n        print(model.invoke(messages))',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'human',\n",
       "     'enum': ['human'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'ChatMessage': {'title': 'ChatMessage',\n",
       "   'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'chat',\n",
       "     'enum': ['chat'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role']},\n",
       "  'SystemMessage': {'title': 'SystemMessage',\n",
       "   'description': 'Message for priming AI behavior.\\n\\nThe system message is usually passed in as the first of a sequence\\nof input messages.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Define a chat model and invoke it with the messages\\n        print(model.invoke(messages))',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'system',\n",
       "     'enum': ['system'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['content']},\n",
       "  'FunctionMessage': {'title': 'FunctionMessage',\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.\\n\\nFunctionMessage are an older version of the ToolMessage schema, and\\ndo not contain the tool_call_id field.\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'function',\n",
       "     'enum': ['function'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['content', 'name']},\n",
       "  'ToolMessage': {'title': 'ToolMessage',\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.\\n\\nToolMessages contain the result of a tool invocation. Typically, the result\\nis encoded inside the `content` field.\\n\\nExample: A ToolMessage representing a result of 42 from a tool call with id\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        ToolMessage(content=\\'42\\', tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\')\\n\\n\\nExample: A ToolMessage where only part of the tool output is sent to the model\\n    and the full output is passed in to artifact.\\n\\n    .. versionadded:: 0.2.17\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        tool_output = {\\n            \"stdout\": \"From the graph we can see that the correlation between x and y is ...\",\\n            \"stderr\": None,\\n            \"artifacts\": {\"type\": \"image\", \"base64_data\": \"/9j/4gIcSU...\"},\\n        }\\n\\n        ToolMessage(\\n            content=tool_output[\"stdout\"],\\n            artifact=tool_output,\\n            tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\',\\n        )\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'tool',\n",
       "     'enum': ['tool'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'},\n",
       "    'artifact': {'title': 'Artifact'},\n",
       "    'status': {'title': 'Status',\n",
       "     'default': 'success',\n",
       "     'enum': ['success', 'error'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['content', 'tool_call_id']}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.output_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a2e88e-80eb-4dba-b0c8-a03760444e3b",
   "metadata": {},
   "source": [
    "<h3>Stream</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c090f21-8c75-447c-8c01-4ebc54ea0ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't they play poker in the forest? \n",
      "\n",
      "Because there's too many cheetahs! \n"
     ]
    }
   ],
   "source": [
    "for s in chain.stream(input={'topic':'bear'}):\n",
    "    print(s.content,end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc05fbb-1792-4f7d-95f0-01cebd14270e",
   "metadata": {},
   "source": [
    "<h3>Invoke</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c986bbfd-367f-4a7a-8651-db741acae6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the bear say no to dessert? \\n\\nBecause he was stuffed! üêª \\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input={\"topic\":\"bear\"}).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d4369-dab9-4cd6-90fc-b9caa073b5ec",
   "metadata": {},
   "source": [
    "<h3>Batch</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6026869a-45cf-4e0c-94a6-d138746fd3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Why did the bear say no to dessert?\\n\\nBecause he was already stuffed! üêª \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-b4925534-6e32-4c8d-ae19-e47eab51ac82-0'),\n",
       " AIMessage(content=\"Why did Virat Kohli get a job at the bank? \\n\\nBecause he's a master at chasing runs! üèèüí∞ \\n\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-5b28eefe-fe12-459b-8e82-5b26ee250c78-0')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch(inputs=[\n",
    "    {\"topic\":\"bear\"},\n",
    "    {\"topic\":\"Virat Kohli\"}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99e530de-b3bd-4921-9e38-7f98c0fcb999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"Why don't they play poker in the forest? \\n\\nBecause there's too many cheetahs! \\n\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-0fdad0bc-57d8-4435-b8d0-4be640bcd1bc-0'),\n",
       " AIMessage(content=\"Why did Virat Kohli get a job at the library?\\n\\nBecause he's a real bookworm, and he's always chasing runs! üèèüìö \\n\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'LOW', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-e623d777-8e4b-4004-867c-24e84b7fbf0f-0')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting Concurrency\n",
    "\n",
    "chain.batch(\n",
    "    inputs=[\n",
    "    {\"topic\":\"bear\"},\n",
    "    {\"topic\":\"Virat Kohli\"},\n",
    "    ],\n",
    "    config={\n",
    "        \"max_concurrency\":5\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85a7468-1394-49f8-a250-6259beb0917e",
   "metadata": {},
   "source": [
    "<h3>Async Stream</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dea5abef-d6bb-4110-b3a2-ce8648091047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't they play poker in the forest?\n",
      "\n",
      "Because there's too many cheetahs! \n"
     ]
    }
   ],
   "source": [
    "async for s in chain.astream(input={'topic':'bear'}):\n",
    "    print(s.content,end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647defea-f37e-43c9-921e-e32e59b5a4a6",
   "metadata": {},
   "source": [
    "<h3> Async Invoke </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "557a4aa5-fb9b-4c86-bc13-c5c5f6555a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Why did Rohit Sharma get a job at a bank?\\n\\nBecause he's a master at handling pressure and knows how to hit sixes! üèèüí∞ \\n\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'LOW', 'blocked': False}]}, id='run-204ca80e-f48d-4006-8bd4-0fbded573d82-0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chain.ainvoke(input={\"topic\":\"Rohit Sharma\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba824958-097a-4ca4-bc01-831142e48470",
   "metadata": {},
   "source": [
    "<h3>Async Batch </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bea462f3-40e2-4ead-99d8-7ea02727555b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"Why did Sachin Tendulkar always carry a spare bat to the cricket ground?\\n\\nBecause he knew he'd be hitting a century! üèèüòÑ \\n\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-204719cd-0947-459b-b34e-226e96f0fc01-0'),\n",
       " AIMessage(content='Why did Shane Warne always bring a spare ball to the cricket match?\\n\\nBecause he knew he\\'d \"bowl\" over the opposition! üòú \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-52a19ac9-a681-410b-9f1c-f85a978a90f9-0')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chain.abatch(inputs=[{\"topic\":\"Sachin Tendulkar\"},{\"topic\":\"Shane Warne\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2baecc-f5bf-4720-b663-f0c54f9715bc",
   "metadata": {},
   "source": [
    "<h3>Event Reference</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "28f36f6f-6634-4e23-aac2-19cf07a38209",
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(template=template)\n",
    "\n",
    "vectorStore=FAISS.from_texts(\n",
    "    texts=[\"Ritish has a 2.5 month old son !\",\n",
    "           \"Rohit is Ritish's Younger Brother\",\n",
    "           \"Eklavya is Ritish's Son\"\n",
    "           \"Rekha is the name of Ritish's Mother\",\n",
    "           \"Anirban is Ritish's Father\"],\n",
    "    embedding=SentenceTransformerEmbeddings())\n",
    "\n",
    "retriever=vectorStore.as_retriever()\n",
    "\n",
    "outputParser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7e681b51-acb8-4abe-8afb-ab229b94cac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrievalChain=RunnablePassthrough.assign(context=itemgetter(\"question\")|retriever.with_config(run_name=\"Docs\") ) | prompt | llm.with_config(run_name=\"my_llm\") | outputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7f83a4f7-29ab-4ade-8f55-90048d1f9c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question={\"question\":\"Who is Anirban's Wife and who is Eklavya's Uncle?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cbbe73d9-ab29-4ab6-8e21-f96209d8484d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the breakdown based on the provided context:\n",
      "\n",
      "* **Anirban's Wife:**  The context states \"Rekha is the name of Ritish's Mother\". Since Anirban is Ritish's father, **Rekha is Anirban's wife**. \n",
      "* **Eklavya's Uncle:** We know Ritish has a 2.5 month old son. We can infer that this son is named Eklavya.  Ritish is Eklavya's father, and Rohit is Ritish's brother. Therefore, **Rohit is Eklavya's uncle**. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(retrievalChain.invoke(input=question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bf744572-c802-4a2e-8dc1-288b0415b69d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_retriever_start', 'name': 'Docs', 'run_id': '3f5917f3-d872-483e-a07e-a5b87a7e70cd', 'tags': ['seq:step:2', 'FAISS', 'HuggingFaceEmbeddings'], 'metadata': {'ls_retriever_name': 'vectorstore', 'ls_vector_store_provider': 'FAISS', 'ls_embedding_provider': 'HuggingFaceEmbeddings'}, 'data': {'input': {'query': \"Who is Anirban's Wife and who is Eklavya's Uncle?\"}}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_retriever_end', 'name': 'Docs', 'run_id': '3f5917f3-d872-483e-a07e-a5b87a7e70cd', 'tags': ['seq:step:2', 'FAISS', 'HuggingFaceEmbeddings'], 'metadata': {'ls_retriever_name': 'vectorstore', 'ls_vector_store_provider': 'FAISS', 'ls_embedding_provider': 'HuggingFaceEmbeddings'}, 'data': {'input': {'query': \"Who is Anirban's Wife and who is Eklavya's Uncle?\"}, 'output': {'documents': [Document(page_content=\"Anirban is Ritish's Father\"), Document(page_content=\"Rekha is the name of Ritish's Mother\"), Document(page_content=\"Rohit is Ritish's Younger Brother\"), Document(page_content='Ritish has a 2.5 month old son !')]}}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_start', 'name': 'my_llm', 'run_id': 'e04a853f-646c-475a-a446-51656cb7d228', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'googlegenerativeai', 'ls_model_type': 'chat', 'ls_model_name': 'models/gemini-1.5-flash', 'ls_temperature': 0.7}, 'data': {'input': {'messages': [[HumanMessage(content='\\nAnswer the question based only on the following context:\\n[Document(page_content=\"Anirban is Ritish\\'s Father\"), Document(page_content=\"Rekha is the name of Ritish\\'s Mother\"), Document(page_content=\"Rohit is Ritish\\'s Younger Brother\"), Document(page_content=\\'Ritish has a 2.5 month old son !\\')]\\n\\nQuestion: Who is Anirban\\'s Wife and who is Eklavya\\'s Uncle?\\n')]]}}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e04a853f-646c-475a-a446-51656cb7d228', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'googlegenerativeai', 'ls_model_type': 'chat', 'ls_model_name': 'models/gemini-1.5-flash', 'ls_temperature': 0.7}, 'data': {'chunk': AIMessageChunk(content=\"Here's the\", response_metadata={'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-e04a853f-646c-475a-a446-51656cb7d228')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e04a853f-646c-475a-a446-51656cb7d228', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'googlegenerativeai', 'ls_model_type': 'chat', 'ls_model_name': 'models/gemini-1.5-flash', 'ls_temperature': 0.7}, 'data': {'chunk': AIMessageChunk(content=\" breakdown based on the provided context:\\n\\n* **Anirban's Wife:**\", response_metadata={'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-e04a853f-646c-475a-a446-51656cb7d228')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e04a853f-646c-475a-a446-51656cb7d228', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'googlegenerativeai', 'ls_model_type': 'chat', 'ls_model_name': 'models/gemini-1.5-flash', 'ls_temperature': 0.7}, 'data': {'chunk': AIMessageChunk(content=\" We know Anirban is Ritish's father, and Rekha is\", response_metadata={'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-e04a853f-646c-475a-a446-51656cb7d228')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e04a853f-646c-475a-a446-51656cb7d228', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'googlegenerativeai', 'ls_model_type': 'chat', 'ls_model_name': 'models/gemini-1.5-flash', 'ls_temperature': 0.7}, 'data': {'chunk': AIMessageChunk(content=\" Ritish's mother. Therefore, **Rekha is Anirban's wife**.\\n* **Eklavya's Uncle:**  We know\", response_metadata={'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-e04a853f-646c-475a-a446-51656cb7d228')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e04a853f-646c-475a-a446-51656cb7d228', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'googlegenerativeai', 'ls_model_type': 'chat', 'ls_model_name': 'models/gemini-1.5-flash', 'ls_temperature': 0.7}, 'data': {'chunk': AIMessageChunk(content=\" Ritish has a 2.5-month-old son.  It's reasonable to assume that Ritish is Eklavya's father.\", response_metadata={'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-e04a853f-646c-475a-a446-51656cb7d228')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e04a853f-646c-475a-a446-51656cb7d228', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'googlegenerativeai', 'ls_model_type': 'chat', 'ls_model_name': 'models/gemini-1.5-flash', 'ls_temperature': 0.7}, 'data': {'chunk': AIMessageChunk(content=\"  Since Rohit is Ritish's younger brother, **Rohit is Eklavya's uncle**. \\n\", response_metadata={'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-e04a853f-646c-475a-a446-51656cb7d228')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_end', 'name': 'my_llm', 'run_id': 'e04a853f-646c-475a-a446-51656cb7d228', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'googlegenerativeai', 'ls_model_type': 'chat', 'ls_model_name': 'models/gemini-1.5-flash', 'ls_temperature': 0.7}, 'data': {'input': {'messages': [[HumanMessage(content='\\nAnswer the question based only on the following context:\\n[Document(page_content=\"Anirban is Ritish\\'s Father\"), Document(page_content=\"Rekha is the name of Ritish\\'s Mother\"), Document(page_content=\"Rohit is Ritish\\'s Younger Brother\"), Document(page_content=\\'Ritish has a 2.5 month old son !\\')]\\n\\nQuestion: Who is Anirban\\'s Wife and who is Eklavya\\'s Uncle?\\n')]]}, 'output': {'generations': [[{'text': \"Here's the breakdown based on the provided context:\\n\\n* **Anirban's Wife:** We know Anirban is Ritish's father, and Rekha is Ritish's mother. Therefore, **Rekha is Anirban's wife**.\\n* **Eklavya's Uncle:**  We know Ritish has a 2.5-month-old son.  It's reasonable to assume that Ritish is Eklavya's father.  Since Rohit is Ritish's younger brother, **Rohit is Eklavya's uncle**. \\n\", 'generation_info': {'finish_reason': 'STOPSTOPSTOPSTOPSTOPSTOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, 'type': 'ChatGenerationChunk', 'message': AIMessageChunk(content=\"Here's the breakdown based on the provided context:\\n\\n* **Anirban's Wife:** We know Anirban is Ritish's father, and Rekha is Ritish's mother. Therefore, **Rekha is Anirban's wife**.\\n* **Eklavya's Uncle:**  We know Ritish has a 2.5-month-old son.  It's reasonable to assume that Ritish is Eklavya's father.  Since Rohit is Ritish's younger brother, **Rohit is Eklavya's uncle**. \\n\", response_metadata={'finish_reason': 'STOPSTOPSTOPSTOPSTOPSTOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-e04a853f-646c-475a-a446-51656cb7d228')}]], 'llm_output': None, 'run': None}}, 'parent_ids': []} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "async for event in retrievalChain.astream_events(input=question,\n",
    "                                                 version=\"v1\",\n",
    "                                                 include_names=[\"Docs\",\"my_llm\"]\n",
    "                                                ):\n",
    "    print(event,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3230d52e-7091-4cf2-b888-dcf370d5fb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved the following Documents:\n",
      "[Document(page_content=\"Anirban is Ritish's Father\"), Document(page_content=\"Rekha is the name of Ritish's Mother\"), Document(page_content=\"Rohit is Ritish's Younger Brother\"), Document(page_content='Ritish has a 2.5 month old son !')]\n",
      "\n",
      "Streaming LLM\n",
      "Here's the| breakdown based on the provided context:\n",
      "\n",
      "* **Anirban's Wife:**|  The context states \"Rekha is the name of Ritish's Mother|\". Since Anirban is Ritish's father, **Rekha is Anirban's wife**. \n",
      "* **Eklavya's| Uncle:** The context mentions \"Ritish has a 2.5 month old son!\". We can infer that Ritish's son is named Eklavya.|  Since Rohit is Ritish's younger brother, **Rohit is Eklavya's uncle**. \n",
      "|Done Streaming LLM.\n"
     ]
    }
   ],
   "source": [
    "async for event in retrievalChain.astream_events(input=question,\n",
    "                                                 version=\"v1\",\n",
    "                                                 include_names=[\"Docs\",\"my_llm\"]\n",
    "                                                ):\n",
    "    kind=event['event']\n",
    "    if kind==\"on_chat_model_stream\":\n",
    "        print(event[\"data\"][\"chunk\"].content,end=\"|\")\n",
    "    elif kind==\"on_chat_model_start\":\n",
    "        print(\"\\nStreaming LLM\")\n",
    "    elif kind==\"on_chat_model_end\":\n",
    "        print(\"Done Streaming LLM.\")\n",
    "    elif kind==\"on_retriever_end\":\n",
    "        print(\"Retrieved the following Documents:\")\n",
    "        print(event[\"data\"][\"output\"][\"documents\"])\n",
    "    elif kind==\"on_tool_end\":\n",
    "        print(f\"Ended Tool: {event['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "859e0241-7e14-428e-8fb7-929500d9f0be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "RunLogPatch({'op': 'replace',\n",
      "  'path': '',\n",
      "  'value': {'final_output': None,\n",
      "            'id': '2fc15f6d-8774-4034-b849-82439898aafc',\n",
      "            'logs': {},\n",
      "            'name': 'RunnableSequence',\n",
      "            'streamed_output': [],\n",
      "            'type': 'chain'}})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/Docs',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '687397bd-b966-470a-84a9-9e6b2e327be6',\n",
      "            'metadata': {'ls_embedding_provider': 'HuggingFaceEmbeddings',\n",
      "                         'ls_retriever_name': 'vectorstore',\n",
      "                         'ls_vector_store_provider': 'FAISS'},\n",
      "            'name': 'Docs',\n",
      "            'start_time': '2024-09-24T20:41:52.687+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:2', 'FAISS', 'HuggingFaceEmbeddings'],\n",
      "            'type': 'retriever'}})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/Docs/final_output',\n",
      "  'value': {'documents': [Document(page_content=\"Anirban is Ritish's Father\"),\n",
      "                          Document(page_content=\"Rekha is the name of Ritish's Mother\"),\n",
      "                          Document(page_content=\"Rohit is Ritish's Younger Brother\"),\n",
      "                          Document(page_content='Ritish has a 2.5 month old son !')]}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/Docs/end_time',\n",
      "  'value': '2024-09-24T20:41:52.725+00:00'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': \"Here's the\"},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': \"Here's the\"})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': \" breakdown:\\n\\n* **Anirban's Wife:** We know Anir\"},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': \"Here's the breakdown:\\n\\n* **Anirban's Wife:** We know Anir\"})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': \"ban is Ritish's father and Rekha is Ritish's mother\"},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': \"Here's the breakdown:\\n\"\n",
      "           '\\n'\n",
      "           \"* **Anirban's Wife:** We know Anirban is Ritish's father and Rekha \"\n",
      "           \"is Ritish's mother\"})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': \". Therefore, **Anirban's wife is Rekha.** \\n\"\n",
      "           '\\n'\n",
      "           \"* **Eklavya's Uncle:**  We know Ritish has a\"},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': \"Here's the breakdown:\\n\"\n",
      "           '\\n'\n",
      "           \"* **Anirban's Wife:** We know Anirban is Ritish's father and Rekha \"\n",
      "           \"is Ritish's mother. Therefore, **Anirban's wife is Rekha.** \\n\"\n",
      "           '\\n'\n",
      "           \"* **Eklavya's Uncle:**  We know Ritish has a\"})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': ' 2.5 month old son. We can assume this son is named Eklavya. Since '\n",
      "           \"Rohit is Ritish's younger brother, **Rohit is\"},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': \"Here's the breakdown:\\n\"\n",
      "           '\\n'\n",
      "           \"* **Anirban's Wife:** We know Anirban is Ritish's father and Rekha \"\n",
      "           \"is Ritish's mother. Therefore, **Anirban's wife is Rekha.** \\n\"\n",
      "           '\\n'\n",
      "           \"* **Eklavya's Uncle:**  We know Ritish has a 2.5 month old son. We \"\n",
      "           \"can assume this son is named Eklavya. Since Rohit is Ritish's \"\n",
      "           'younger brother, **Rohit is'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': \" Eklavya's Uncle.** \\n\"},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': \"Here's the breakdown:\\n\"\n",
      "           '\\n'\n",
      "           \"* **Anirban's Wife:** We know Anirban is Ritish's father and Rekha \"\n",
      "           \"is Ritish's mother. Therefore, **Anirban's wife is Rekha.** \\n\"\n",
      "           '\\n'\n",
      "           \"* **Eklavya's Uncle:**  We know Ritish has a 2.5 month old son. We \"\n",
      "           \"can assume this son is named Eklavya. Since Rohit is Ritish's \"\n",
      "           \"younger brother, **Rohit is Eklavya's Uncle.** \\n\"})\n"
     ]
    }
   ],
   "source": [
    "async for chunk in retrievalChain.astream_log(input=question,include_names=[\"Docs\"]):\n",
    "    print(\"-\"*40)\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "51648bec-669e-42cd-a6c8-af81db67ade0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "RunLog({'final_output': None,\n",
      " 'id': '285c7584-ffc6-4fda-8de4-3a2a96530f6c',\n",
      " 'logs': {},\n",
      " 'name': 'RunnableSequence',\n",
      " 'streamed_output': [],\n",
      " 'type': 'chain'})\n",
      "----------------------------------------\n",
      "RunLog({'final_output': None,\n",
      " 'id': '285c7584-ffc6-4fda-8de4-3a2a96530f6c',\n",
      " 'logs': {'Docs': {'end_time': None,\n",
      "                   'final_output': None,\n",
      "                   'id': 'd6cba482-cd44-4f72-bab0-7fe738b5d482',\n",
      "                   'metadata': {'ls_embedding_provider': 'HuggingFaceEmbeddings',\n",
      "                                'ls_retriever_name': 'vectorstore',\n",
      "                                'ls_vector_store_provider': 'FAISS'},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2024-09-24T20:44:13.157+00:00',\n",
      "                   'streamed_output': [],\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['seq:step:2', 'FAISS', 'HuggingFaceEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'name': 'RunnableSequence',\n",
      " 'streamed_output': [],\n",
      " 'type': 'chain'})\n",
      "----------------------------------------\n",
      "RunLog({'final_output': None,\n",
      " 'id': '285c7584-ffc6-4fda-8de4-3a2a96530f6c',\n",
      " 'logs': {'Docs': {'end_time': '2024-09-24T20:44:13.202+00:00',\n",
      "                   'final_output': {'documents': [Document(page_content=\"Anirban is Ritish's Father\"),\n",
      "                                                  Document(page_content=\"Rekha is the name of Ritish's Mother\"),\n",
      "                                                  Document(page_content=\"Rohit is Ritish's Younger Brother\"),\n",
      "                                                  Document(page_content='Ritish has a 2.5 month old son !')]},\n",
      "                   'id': 'd6cba482-cd44-4f72-bab0-7fe738b5d482',\n",
      "                   'metadata': {'ls_embedding_provider': 'HuggingFaceEmbeddings',\n",
      "                                'ls_retriever_name': 'vectorstore',\n",
      "                                'ls_vector_store_provider': 'FAISS'},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2024-09-24T20:44:13.157+00:00',\n",
      "                   'streamed_output': [],\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['seq:step:2', 'FAISS', 'HuggingFaceEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'name': 'RunnableSequence',\n",
      " 'streamed_output': [],\n",
      " 'type': 'chain'})\n",
      "----------------------------------------\n",
      "RunLog({'final_output': \"Here's the\",\n",
      " 'id': '285c7584-ffc6-4fda-8de4-3a2a96530f6c',\n",
      " 'logs': {'Docs': {'end_time': '2024-09-24T20:44:13.202+00:00',\n",
      "                   'final_output': {'documents': [Document(page_content=\"Anirban is Ritish's Father\"),\n",
      "                                                  Document(page_content=\"Rekha is the name of Ritish's Mother\"),\n",
      "                                                  Document(page_content=\"Rohit is Ritish's Younger Brother\"),\n",
      "                                                  Document(page_content='Ritish has a 2.5 month old son !')]},\n",
      "                   'id': 'd6cba482-cd44-4f72-bab0-7fe738b5d482',\n",
      "                   'metadata': {'ls_embedding_provider': 'HuggingFaceEmbeddings',\n",
      "                                'ls_retriever_name': 'vectorstore',\n",
      "                                'ls_vector_store_provider': 'FAISS'},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2024-09-24T20:44:13.157+00:00',\n",
      "                   'streamed_output': [],\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['seq:step:2', 'FAISS', 'HuggingFaceEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'name': 'RunnableSequence',\n",
      " 'streamed_output': [\"Here's the\"],\n",
      " 'type': 'chain'})\n",
      "----------------------------------------\n",
      "RunLog({'final_output': \"Here's the breakdown based on the provided context:\\n\"\n",
      "                 '\\n'\n",
      "                 \"* **Anirban's Wife:**\",\n",
      " 'id': '285c7584-ffc6-4fda-8de4-3a2a96530f6c',\n",
      " 'logs': {'Docs': {'end_time': '2024-09-24T20:44:13.202+00:00',\n",
      "                   'final_output': {'documents': [Document(page_content=\"Anirban is Ritish's Father\"),\n",
      "                                                  Document(page_content=\"Rekha is the name of Ritish's Mother\"),\n",
      "                                                  Document(page_content=\"Rohit is Ritish's Younger Brother\"),\n",
      "                                                  Document(page_content='Ritish has a 2.5 month old son !')]},\n",
      "                   'id': 'd6cba482-cd44-4f72-bab0-7fe738b5d482',\n",
      "                   'metadata': {'ls_embedding_provider': 'HuggingFaceEmbeddings',\n",
      "                                'ls_retriever_name': 'vectorstore',\n",
      "                                'ls_vector_store_provider': 'FAISS'},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2024-09-24T20:44:13.157+00:00',\n",
      "                   'streamed_output': [],\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['seq:step:2', 'FAISS', 'HuggingFaceEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'name': 'RunnableSequence',\n",
      " 'streamed_output': [\"Here's the\",\n",
      "                     ' breakdown based on the provided context:\\n'\n",
      "                     '\\n'\n",
      "                     \"* **Anirban's Wife:**\"],\n",
      " 'type': 'chain'})\n",
      "----------------------------------------\n",
      "RunLog({'final_output': \"Here's the breakdown based on the provided context:\\n\"\n",
      "                 '\\n'\n",
      "                 '* **Anirban\\'s Wife:** The context states that \"Rekha is the '\n",
      "                 \"name of Ritish's Mother\",\n",
      " 'id': '285c7584-ffc6-4fda-8de4-3a2a96530f6c',\n",
      " 'logs': {'Docs': {'end_time': '2024-09-24T20:44:13.202+00:00',\n",
      "                   'final_output': {'documents': [Document(page_content=\"Anirban is Ritish's Father\"),\n",
      "                                                  Document(page_content=\"Rekha is the name of Ritish's Mother\"),\n",
      "                                                  Document(page_content=\"Rohit is Ritish's Younger Brother\"),\n",
      "                                                  Document(page_content='Ritish has a 2.5 month old son !')]},\n",
      "                   'id': 'd6cba482-cd44-4f72-bab0-7fe738b5d482',\n",
      "                   'metadata': {'ls_embedding_provider': 'HuggingFaceEmbeddings',\n",
      "                                'ls_retriever_name': 'vectorstore',\n",
      "                                'ls_vector_store_provider': 'FAISS'},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2024-09-24T20:44:13.157+00:00',\n",
      "                   'streamed_output': [],\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['seq:step:2', 'FAISS', 'HuggingFaceEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'name': 'RunnableSequence',\n",
      " 'streamed_output': [\"Here's the\",\n",
      "                     ' breakdown based on the provided context:\\n'\n",
      "                     '\\n'\n",
      "                     \"* **Anirban's Wife:**\",\n",
      "                     ' The context states that \"Rekha is the name of Ritish\\'s '\n",
      "                     'Mother'],\n",
      " 'type': 'chain'})\n",
      "----------------------------------------\n",
      "RunLog({'final_output': \"Here's the breakdown based on the provided context:\\n\"\n",
      "                 '\\n'\n",
      "                 '* **Anirban\\'s Wife:** The context states that \"Rekha is the '\n",
      "                 'name of Ritish\\'s Mother\". Since Anirban is Ritish\\'s '\n",
      "                 \"father, **Rekha is Anirban's wife**.\\n\"\n",
      "                 \"* **Eklavya's Uncle:**\",\n",
      " 'id': '285c7584-ffc6-4fda-8de4-3a2a96530f6c',\n",
      " 'logs': {'Docs': {'end_time': '2024-09-24T20:44:13.202+00:00',\n",
      "                   'final_output': {'documents': [Document(page_content=\"Anirban is Ritish's Father\"),\n",
      "                                                  Document(page_content=\"Rekha is the name of Ritish's Mother\"),\n",
      "                                                  Document(page_content=\"Rohit is Ritish's Younger Brother\"),\n",
      "                                                  Document(page_content='Ritish has a 2.5 month old son !')]},\n",
      "                   'id': 'd6cba482-cd44-4f72-bab0-7fe738b5d482',\n",
      "                   'metadata': {'ls_embedding_provider': 'HuggingFaceEmbeddings',\n",
      "                                'ls_retriever_name': 'vectorstore',\n",
      "                                'ls_vector_store_provider': 'FAISS'},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2024-09-24T20:44:13.157+00:00',\n",
      "                   'streamed_output': [],\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['seq:step:2', 'FAISS', 'HuggingFaceEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'name': 'RunnableSequence',\n",
      " 'streamed_output': [\"Here's the\",\n",
      "                     ' breakdown based on the provided context:\\n'\n",
      "                     '\\n'\n",
      "                     \"* **Anirban's Wife:**\",\n",
      "                     ' The context states that \"Rekha is the name of Ritish\\'s '\n",
      "                     'Mother',\n",
      "                     '\". Since Anirban is Ritish\\'s father, **Rekha is '\n",
      "                     \"Anirban's wife**.\\n\"\n",
      "                     \"* **Eklavya's Uncle:**\"],\n",
      " 'type': 'chain'})\n",
      "----------------------------------------\n",
      "RunLog({'final_output': \"Here's the breakdown based on the provided context:\\n\"\n",
      "                 '\\n'\n",
      "                 '* **Anirban\\'s Wife:** The context states that \"Rekha is the '\n",
      "                 'name of Ritish\\'s Mother\". Since Anirban is Ritish\\'s '\n",
      "                 \"father, **Rekha is Anirban's wife**.\\n\"\n",
      "                 '* **Eklavya\\'s Uncle:**  The context tells us \"Ritish has a '\n",
      "                 '2.5 month old son!\".  We can infer that Ritish\\'s son is '\n",
      "                 'Eklav',\n",
      " 'id': '285c7584-ffc6-4fda-8de4-3a2a96530f6c',\n",
      " 'logs': {'Docs': {'end_time': '2024-09-24T20:44:13.202+00:00',\n",
      "                   'final_output': {'documents': [Document(page_content=\"Anirban is Ritish's Father\"),\n",
      "                                                  Document(page_content=\"Rekha is the name of Ritish's Mother\"),\n",
      "                                                  Document(page_content=\"Rohit is Ritish's Younger Brother\"),\n",
      "                                                  Document(page_content='Ritish has a 2.5 month old son !')]},\n",
      "                   'id': 'd6cba482-cd44-4f72-bab0-7fe738b5d482',\n",
      "                   'metadata': {'ls_embedding_provider': 'HuggingFaceEmbeddings',\n",
      "                                'ls_retriever_name': 'vectorstore',\n",
      "                                'ls_vector_store_provider': 'FAISS'},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2024-09-24T20:44:13.157+00:00',\n",
      "                   'streamed_output': [],\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['seq:step:2', 'FAISS', 'HuggingFaceEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'name': 'RunnableSequence',\n",
      " 'streamed_output': [\"Here's the\",\n",
      "                     ' breakdown based on the provided context:\\n'\n",
      "                     '\\n'\n",
      "                     \"* **Anirban's Wife:**\",\n",
      "                     ' The context states that \"Rekha is the name of Ritish\\'s '\n",
      "                     'Mother',\n",
      "                     '\". Since Anirban is Ritish\\'s father, **Rekha is '\n",
      "                     \"Anirban's wife**.\\n\"\n",
      "                     \"* **Eklavya's Uncle:**\",\n",
      "                     '  The context tells us \"Ritish has a 2.5 month old '\n",
      "                     'son!\".  We can infer that Ritish\\'s son is Eklav'],\n",
      " 'type': 'chain'})\n",
      "----------------------------------------\n",
      "RunLog({'final_output': \"Here's the breakdown based on the provided context:\\n\"\n",
      "                 '\\n'\n",
      "                 '* **Anirban\\'s Wife:** The context states that \"Rekha is the '\n",
      "                 'name of Ritish\\'s Mother\". Since Anirban is Ritish\\'s '\n",
      "                 \"father, **Rekha is Anirban's wife**.\\n\"\n",
      "                 '* **Eklavya\\'s Uncle:**  The context tells us \"Ritish has a '\n",
      "                 '2.5 month old son!\".  We can infer that Ritish\\'s son is '\n",
      "                 \"Eklavya.  Since Rohit is Ritish's younger brother, **Rohit \"\n",
      "                 \"is Eklavya's uncle**. \\n\",\n",
      " 'id': '285c7584-ffc6-4fda-8de4-3a2a96530f6c',\n",
      " 'logs': {'Docs': {'end_time': '2024-09-24T20:44:13.202+00:00',\n",
      "                   'final_output': {'documents': [Document(page_content=\"Anirban is Ritish's Father\"),\n",
      "                                                  Document(page_content=\"Rekha is the name of Ritish's Mother\"),\n",
      "                                                  Document(page_content=\"Rohit is Ritish's Younger Brother\"),\n",
      "                                                  Document(page_content='Ritish has a 2.5 month old son !')]},\n",
      "                   'id': 'd6cba482-cd44-4f72-bab0-7fe738b5d482',\n",
      "                   'metadata': {'ls_embedding_provider': 'HuggingFaceEmbeddings',\n",
      "                                'ls_retriever_name': 'vectorstore',\n",
      "                                'ls_vector_store_provider': 'FAISS'},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2024-09-24T20:44:13.157+00:00',\n",
      "                   'streamed_output': [],\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['seq:step:2', 'FAISS', 'HuggingFaceEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'name': 'RunnableSequence',\n",
      " 'streamed_output': [\"Here's the\",\n",
      "                     ' breakdown based on the provided context:\\n'\n",
      "                     '\\n'\n",
      "                     \"* **Anirban's Wife:**\",\n",
      "                     ' The context states that \"Rekha is the name of Ritish\\'s '\n",
      "                     'Mother',\n",
      "                     '\". Since Anirban is Ritish\\'s father, **Rekha is '\n",
      "                     \"Anirban's wife**.\\n\"\n",
      "                     \"* **Eklavya's Uncle:**\",\n",
      "                     '  The context tells us \"Ritish has a 2.5 month old '\n",
      "                     'son!\".  We can infer that Ritish\\'s son is Eklav',\n",
      "                     \"ya.  Since Rohit is Ritish's younger brother, **Rohit is \"\n",
      "                     \"Eklavya's uncle**. \\n\"],\n",
      " 'type': 'chain'})\n"
     ]
    }
   ],
   "source": [
    "## Stream Incremental RunState with diff=False\n",
    "async for chunk in retrievalChain.astream_log(input=question,include_names=[\"Docs\"],diff=False):\n",
    "    print(\"-\"*40)\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5752bdb-e961-4df7-a5df-35c2c5938abc",
   "metadata": {},
   "source": [
    "<h3>Runnable Parallel</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "867e2bdd-c3bb-452d-95da-476687bca7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1=ChatPromptTemplate.from_template(template=\"Tell Me a Joke about {topic}\")|llm\n",
    "chain2=ChatPromptTemplate.from_template(template=\"Write a Poem on the Following {subject}\")|llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0cb768f-ddb2-40a5-9e1d-1abd50662f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedChain=RunnableParallel(joke=chain1,poem=chain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af5385f8-0c18-4789-aae4-62f3fdea5cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the Titanic sink? \n",
      "\n",
      "Because it couldn't find a parking space! \n",
      "\n",
      "Took 1.872040033340454 Seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "print(chain1.invoke(input={\"topic\":\"Titanic\"}).content)\n",
    "print(f\"Took {time.time()-start} Seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d015166-429d-41e0-97a9-3cbc1ceda53a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A steel behemoth, a dream come true,\n",
      "The Titanic, a marvel, grand and new.\n",
      "From Belfast's shores, she sailed with pride,\n",
      "A symbol of progress, on the ocean tide.\n",
      "\n",
      "Her decks were bustling, a vibrant scene,\n",
      "With passengers of every rank and glean.\n",
      "From wealthy tycoons to families bold,\n",
      "Each with their stories, yet to unfold.\n",
      "\n",
      "The band played melodies, sweet and clear,\n",
      "As the ship glided, banishing all fear.\n",
      "But fate had a cruel, and icy hand,\n",
      "A chilling whisper, across the land.\n",
      "\n",
      "An iceberg loomed, in the starlit night,\n",
      "A collision fatal, a tragic plight.\n",
      "The ship began to sink, a mournful cry,\n",
      "As hope dwindled, beneath the sky.\n",
      "\n",
      "Lifeboats strained, with souls in despair,\n",
      "As the Titanic, met her final prayer.\n",
      "The ocean claimed her, in its cold embrace,\n",
      "Leaving behind, a haunting trace.\n",
      "\n",
      "A monument to ambition's might,\n",
      "A reminder of loss, in the darkest night.\n",
      "The Titanic's story, forever told,\n",
      "Of pride and tragedy, both brave and bold. \n",
      "\n",
      "Took 1.7491569519042969 Seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "print(chain2.invoke(input={\"subject\":\"Titanic\"}).content)\n",
    "print(f\"Took {time.time()-start} Seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b511e1da-4e1d-48c1-9c22-affe89d1732f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': AIMessage(content=\"Why did the Titanic sink?\\n\\nBecause it couldn't find a parking space in the iceberg lot! \\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-609d15f6-c612-4f8e-a794-26b63ce8f5a7-0', usage_metadata={'input_tokens': 7, 'output_tokens': 21, 'total_tokens': 28}), 'poem': AIMessage(content=\"A steel leviathan, a dream of might,\\nThe Titanic, bathed in moonlight's light.\\nAcross the ocean, a majestic stride,\\nA ship of dreams, with nowhere to hide.\\n\\nHer decks alive with laughter, song, and cheer,\\nThe wealthy, the hopeful, gathering here.\\nFirst class opulence, a gilded cage,\\nWhile steerage huddled, turning a new page.\\n\\nBut fate, it whispered, a chilling breeze,\\nA warning ignored, a silent disease.\\nAn iceberg loomed, a silent threat,\\nAnd in a moment, all was set.\\n\\nA deafening crash, a shuddering groan,\\nThe Titanic's heart, forever alone.\\nPanic surged, as the icy grip took hold,\\nA human tragedy, a story untold.\\n\\nThe lifeboats filled, a desperate race,\\nLeaving behind, a vacant space.\\nMen, women, children, lost in the night,\\nTheir dreams extinguished, in the cold, dark light.\\n\\nThe ocean swallowed, a ship so grand,\\nA reminder of life, a fleeting hand.\\nThe Titanic sleeps, beneath the waves,\\nA silent monument, to those she craves. \\n\\nThe echoes linger, of that fateful night,\\nA tragic reminder, of what we might.\\nThe Titanic's story, a lesson we learn,\\nOf pride and ambition, and the lessons we yearn. \\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-b0bb2396-f3a6-4c05-ba34-a38642238c04-0', usage_metadata={'input_tokens': 8, 'output_tokens': 291, 'total_tokens': 299})}\n",
      "Took 3.0105791091918945 Seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "print(combinedChain.invoke(input={\"subject\":\"Titanic\",\"topic\":\"Titanic\"}))\n",
    "print(f\"Took {time.time()-start} Seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05fc7a7f-8387-4451-a8b9-60f1e361d018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': AIMessage(content=\"Why didn't the Titanic sink faster? \\n\\nBecause it was full of holes! \\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-ac5cba43-736d-4351-882a-5992a2c6f37c-0', usage_metadata={'input_tokens': 7, 'output_tokens': 18, 'total_tokens': 25}),\n",
       " 'poem': AIMessage(content=\"A steel leviathan, a dream of might,\\nThe Titanic sailed, a beacon bright.\\nA grand facade, a promise bold,\\nOf luxury and stories yet untold.\\n\\nAcross the ocean, a majestic glide,\\nWith passengers aboard, their hopes inside.\\nA band played tunes, a joyous air,\\nUnknowing of the darkness lurking there.\\n\\nThe iceberg loomed, a silent threat,\\nA fatal blow, a fate they'd met.\\nThe ship, once proud, now ripped apart,\\nA chilling scream, a broken heart.\\n\\nThe night grew cold, the waters deep,\\nAs souls succumbed, their final sleep.\\nA symphony of cries, a desperate plea,\\nLost in the vast, cold, unforgiving sea.\\n\\nThe Titanic sank, a legend born,\\nA tragic tale, a lesson to be sworn.\\nOf human folly, pride's cruel hand,\\nAnd the fragility of life's grand stand.\\n\\nNow in the depths, a silent tomb,\\nA reminder of fate's darkest loom.\\nThe Titanic sleeps, a haunting sight,\\nA monument to the darkest night. \\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-4bbb7667-1dd6-4f2a-b9eb-dfa3b0515066-0', usage_metadata={'input_tokens': 8, 'output_tokens': 235, 'total_tokens': 243})}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnableParallel({'joke':chain1,'poem':chain2}).invoke(input={\"subject\":\"Titanic\",\"topic\":\"Titanic\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badbb3e6-8e8c-490c-9f65-97bcfadd11f6",
   "metadata": {},
   "source": [
    "<h3> Parallelism on Batches</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2bd16df6-e9f5-48e3-867b-6b3ecdcd9c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content=\"Why did the Titanic sink? \\n\\nBecause it couldn't find a parking space in the iceberg lot! \\n\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-f01b7aa5-e956-4af4-8bcb-df0bdfd70625-0'), AIMessage(content='Why did the Bengali man cross the road? \\n\\nTo get to the other side of the **ghat**! \\n\\n(Get it? Ghat is a riverbank, a common feature in Kolkata.) \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-505d9611-e902-4474-936c-3d0af9b48f8f-0')]\n",
      "Took 0.9421513080596924 Seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "print(chain1.batch(inputs=[{\"topic\":\"Titanic\"},{\"topic\":\"Kolkata\"}]))\n",
    "print(f\"Took {time.time()-start} Seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4eb4ee09-52e2-4ffb-a76f-e41b8a5a40a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content=\"A steel leviathan, a dream of might,\\nThe Titanic, gleaming, bathed in light.\\nA promise of a journey, swift and grand,\\nAcross the ocean, to a promised land.\\n\\nHer decks, a bustling city, life in bloom,\\nWith laughter, music, chasing away the gloom.\\nThe wealthy, the hopeful, all aboard,\\nA tapestry of stories, each word adored.\\n\\nBut fate, a cruel and silent hand,\\nHad spun a different thread, a tragic plan.\\nAn iceberg, looming, cold and stark,\\nA fatal collision, leaving its dark mark.\\n\\nThe ocean roared, a symphony of dread,\\nAs icy water filled the ship, instead\\nOf warmth and hope, a chilling, icy tomb,\\nA final waltz, played by the ocean's boom.\\n\\nFrom gilded halls to steerage, all in fear,\\nThe cries of anguish, echoing far and near.\\nLifeboats filled, leaving souls behind,\\nA tragic spectacle, etched in mankind's mind.\\n\\nThe Titanic sank, a legend born,\\nA symbol of ambition, tragically torn.\\nA reminder of the fragile human plight,\\nOf dreams shattered, in the cold, dark night.\\n\\nSo let us pause, and hold this memory dear,\\nOf those who perished, and the lessons we hold near.\\nFor in the depths, their stories still reside,\\nOf love, of hope, of loss, and the ocean's tide. \\n\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-60c3dfdb-0bf2-4ace-a01b-ae381113995e-0'), AIMessage(content=\"Where Ganges flows, a city sleeps,\\nKolkata, whispers in her dreams.\\nA tapestry of life, she keeps,\\nWhere history and present gleams.\\n\\nFrom Victoria's reign, a grand facade,\\nTo bustling streets, a vibrant hum.\\nA city built on stories, clad,\\nIn colours, where the senses come.\\n\\nThe scent of spices, fills the air,\\nFrom roadside stalls, to markets grand.\\nA melody of life, laid bare,\\nIn music, dance, a helping hand.\\n\\nThe Howrah Bridge, a steel embrace,\\nConnecting shores, a timeless view.\\nA city's soul, its vibrant space,\\nWhere dreams take flight, forever new.\\n\\nThe Kali Temple, ancient, strong,\\nWhispers of faith, in fervent prayer.\\nA city's heart, where right and wrong,\\nAre weighed, with burdens, we all share.\\n\\nFrom College Street, to Park Street's light,\\nA city's pulse, a beating drum.\\nA tapestry of day and night,\\nKolkata, where the future's spun.\\n\\nSo let us wander, through her maze,\\nEmbrace her spirit, strong and bold.\\nA city that forever sways,\\nA story whispered, yet untold. \\n\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-fa91f6d2-e27f-4b30-87d9-9289b16d3e85-0')]\n",
      "Took 2.2068328857421875 Seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "print(chain2.batch(inputs=[{\"subject\":\"Titanic\"},{\"subject\":\"Kolkata\"}]))\n",
    "print(f\"Took {time.time()-start} Seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d696c5e3-81de-4a40-b145-d4d9210d6800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'joke': AIMessage(content=\"Why did the Titanic sink? \\n\\nBecause it couldn't find a parking space at the bottom of the ocean! \\n\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-2ba715f8-ddd2-40f5-a3bb-f24864b95dc7-0'), 'poem': AIMessage(content=\"A steel leviathan, a dream of might,\\nThe Titanic, a beacon in the night.\\nAcross the waves, she sailed with grace,\\nA gilded cage, a fleeting space.\\n\\nHer decks a haven, filled with glee,\\nOf laughter, music, destiny.\\nThe band played on, a mournful tune,\\nAs fate's dark hand began to loom.\\n\\nAn iceberg, stark, against the sky,\\nA silent threat, a piercing cry.\\nThe ship, she shuddered, groaned in pain,\\nAs icy water filled her veins.\\n\\nThe lifeboats filled, a desperate plea,\\nFor those left behind, a chilling decree.\\nThe ocean claimed her, cold and deep,\\nA watery grave, where secrets sleep.\\n\\nA monument to pride and loss,\\nA chilling tale, a haunting cross.\\nThe Titanic's legend lives on still,\\nA reminder of human will,\\nAnd the fragility of life's embrace,\\nIn the face of fate, in time and space. \\n\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-8748d99e-8401-422e-be27-f2866cc5c353-0')}, {'joke': AIMessage(content='', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'SAFETY', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'MEDIUM', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'LOW', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-8643aefc-d05e-4f9c-aa43-fb46bc9d8149-0'), 'poem': AIMessage(content=\"Where Ganges flows, a city dreams,\\nKolkata, whispers in sunbeams.\\nA tapestry of old and new,\\nA story told, in shades of blue.\\n\\nThe Howrah Bridge, a steel-wrought grace,\\nReflects the city's vibrant face.\\nVictoria Memorial, a marble queen,\\nA silent witness, a timeless scene.\\n\\nFrom teeming markets, bustling streets,\\nTo ancient temples, quiet retreats.\\nThe scent of spices, a fragrant haze,\\nA symphony of sounds, a vibrant maze.\\n\\nThe trams, a rumble, a gentle sway,\\nA timeless rhythm, come what may.\\nThe rickshaw wallahs, with stories to tell,\\nOf lives lived, and lessons well.\\n\\nFrom Jorasanko's tales of Tagore's art,\\nTo Kalighat's devotion, a beating heart.\\nThe city breathes, a living soul,\\nA journey through time, taking its toll.\\n\\nKolkata, a city of contrasts bold,\\nA story whispered, a story told.\\nWhere dreams take flight, and spirits soar,\\nA city loved, forevermore. \\n\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-4098fc71-a48c-4ee1-ae5e-94add47fa611-0')}]\n",
      "Took 2.9161577224731445 Seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "print(combinedChain.batch(inputs=[\n",
    "                                    {\"subject\":\"Titanic\",\"topic\":\"Titanic\"},  # Joke on Titanic and Poem on Titanic\n",
    "                                    {\"subject\":\"Kolkata\",\"topic\":\"Kolkata\"}  # Joke on Kolkata and Poem on Kolkata\n",
    "                          ]))\n",
    "print(f\"Took {time.time()-start} Seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0d4e7bd9-473b-4fd9-8b83-30bbd6a9be90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       +--------------------------+                        \n",
      "                       | Parallel<joke,poem>Input |                        \n",
      "                       +--------------------------+                        \n",
      "                       *****                   *****                       \n",
      "                    ***                             ***                    \n",
      "                 ***                                   ***                 \n",
      "  +--------------------+                          +--------------------+   \n",
      "  | ChatPromptTemplate |                          | ChatPromptTemplate |   \n",
      "  +--------------------+                          +--------------------+   \n",
      "             *                                               *             \n",
      "             *                                               *             \n",
      "             *                                               *             \n",
      "+------------------------+                      +------------------------+ \n",
      "| ChatGoogleGenerativeAI |                      | ChatGoogleGenerativeAI | \n",
      "+------------------------+                      +------------------------+ \n",
      "                       *****                   *****                       \n",
      "                            ***             ***                            \n",
      "                               ***       ***                               \n",
      "                      +---------------------------+                        \n",
      "                      | Parallel<joke,poem>Output |                        \n",
      "                      +---------------------------+                        \n"
     ]
    }
   ],
   "source": [
    "combinedChain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "77b6f2bd-18f2-4343-90e7-d126dcff4893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatPromptTemplate(input_variables=['topic'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], template='Tell Me a Joke about {topic}'))]),\n",
       " ChatPromptTemplate(input_variables=['subject'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['subject'], template='Write a Poem on the Following {subject}'))])]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedChain.get_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e642f121-0c8c-4526-9e2a-55c9a028a98b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
