{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb9a1021-80d9-47df-b0b8-60f8b9f578af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.runnables import RunnablePassthrough,RunnableLambda, Runnable, RunnableParallel,RunnableConfig\n",
    "from langchain_core.messages import AIMessage\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.tools.render import render_text_description\n",
    "from langchain.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate,SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from operator import itemgetter\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "import json\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import FAISS,Chroma\n",
    "from operator import itemgetter\n",
    "import time\n",
    "import grandalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7baa65c0-b251-4a5c-a250-a1fd841db12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv(\"../.env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "690ea463-62e0-4bb9-824a-12544700ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm=ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-001\")\n",
    "llm=ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0704ec51-a830-4859-870e-bd51e3e89e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_template(\n",
    "    template=\"Tell me a 200 words story on {topic}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e5e322f-eadb-44ee-a87c-fe9d929670ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87f1b53-bc30-481b-a2ee-8a1d68a183e4",
   "metadata": {},
   "source": [
    "<h2> Input Schema </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdec1c4b-c237-4dcb-b63d-2dea95828551",
   "metadata": {},
   "source": [
    "<h5>The Input Schema of the chain is the input schema of its first part, the prompt</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f516968-f75b-4b50-9fa3-76d6a6504baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'topic': {'title': 'Topic', 'type': 'string'}},\n",
       " 'required': ['topic'],\n",
       " 'title': 'PromptInput',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1345d7c-1a5a-48a1-a8ab-c28e02e51563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'topic': {'title': 'Topic', 'type': 'string'}},\n",
       " 'required': ['topic'],\n",
       " 'title': 'PromptInput',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.input_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6777a6c-9a01-4a5f-982c-fd520100f156",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$defs': {'AIMessage': {'additionalProperties': True,\n",
       "   'description': 'Message from an AI.\\n\\nAIMessage is returned from a chat model as a response to a prompt.\\n\\nThis message represents the output of the model and consists of both\\nthe raw output as returned by the model together standardized fields\\n(e.g., tool calls, usage metadata) added by the LangChain framework.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'ai',\n",
       "     'default': 'ai',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'example': {'default': False, 'title': 'Example', 'type': 'boolean'},\n",
       "    'tool_calls': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/ToolCall'},\n",
       "     'title': 'Tool Calls',\n",
       "     'type': 'array'},\n",
       "    'invalid_tool_calls': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/InvalidToolCall'},\n",
       "     'title': 'Invalid Tool Calls',\n",
       "     'type': 'array'},\n",
       "    'usage_metadata': {'anyOf': [{'$ref': '#/$defs/UsageMetadata'},\n",
       "      {'type': 'null'}],\n",
       "     'default': None}},\n",
       "   'required': ['content'],\n",
       "   'title': 'AIMessage',\n",
       "   'type': 'object'},\n",
       "  'AIMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Message chunk from an AI.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'AIMessageChunk',\n",
       "     'default': 'AIMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'example': {'default': False, 'title': 'Example', 'type': 'boolean'},\n",
       "    'tool_calls': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/ToolCall'},\n",
       "     'title': 'Tool Calls',\n",
       "     'type': 'array'},\n",
       "    'invalid_tool_calls': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/InvalidToolCall'},\n",
       "     'title': 'Invalid Tool Calls',\n",
       "     'type': 'array'},\n",
       "    'usage_metadata': {'anyOf': [{'$ref': '#/$defs/UsageMetadata'},\n",
       "      {'type': 'null'}],\n",
       "     'default': None},\n",
       "    'tool_call_chunks': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/ToolCallChunk'},\n",
       "     'title': 'Tool Call Chunks',\n",
       "     'type': 'array'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'AIMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'ChatMessage': {'additionalProperties': True,\n",
       "   'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'chat',\n",
       "     'default': 'chat',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role'],\n",
       "   'title': 'ChatMessage',\n",
       "   'type': 'object'},\n",
       "  'ChatMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Chat Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'ChatMessageChunk',\n",
       "     'default': 'ChatMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role'],\n",
       "   'title': 'ChatMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'ChatPromptValueConcrete': {'description': 'Chat prompt value which explicitly lists out the message types it accepts.\\n\\nFor use in external schemas.',\n",
       "   'properties': {'messages': {'items': {'oneOf': [{'$ref': '#/$defs/AIMessage'},\n",
       "       {'$ref': '#/$defs/HumanMessage'},\n",
       "       {'$ref': '#/$defs/ChatMessage'},\n",
       "       {'$ref': '#/$defs/SystemMessage'},\n",
       "       {'$ref': '#/$defs/FunctionMessage'},\n",
       "       {'$ref': '#/$defs/ToolMessage'},\n",
       "       {'$ref': '#/$defs/AIMessageChunk'},\n",
       "       {'$ref': '#/$defs/HumanMessageChunk'},\n",
       "       {'$ref': '#/$defs/ChatMessageChunk'},\n",
       "       {'$ref': '#/$defs/SystemMessageChunk'},\n",
       "       {'$ref': '#/$defs/FunctionMessageChunk'},\n",
       "       {'$ref': '#/$defs/ToolMessageChunk'}]},\n",
       "     'title': 'Messages',\n",
       "     'type': 'array'},\n",
       "    'type': {'const': 'ChatPromptValueConcrete',\n",
       "     'default': 'ChatPromptValueConcrete',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'}},\n",
       "   'required': ['messages'],\n",
       "   'title': 'ChatPromptValueConcrete',\n",
       "   'type': 'object'},\n",
       "  'FunctionMessage': {'additionalProperties': True,\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.\\n\\nFunctionMessage are an older version of the ToolMessage schema, and\\ndo not contain the tool_call_id field.\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'function',\n",
       "     'default': 'function',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content', 'name'],\n",
       "   'title': 'FunctionMessage',\n",
       "   'type': 'object'},\n",
       "  'FunctionMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Function Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'FunctionMessageChunk',\n",
       "     'default': 'FunctionMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content', 'name'],\n",
       "   'title': 'FunctionMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'HumanMessage': {'additionalProperties': True,\n",
       "   'description': 'Message from a human.\\n\\nHumanMessages are messages that are passed in from a human to the model.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Instantiate a chat model and invoke it with the messages\\n        model = ...\\n        print(model.invoke(messages))',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'human',\n",
       "     'default': 'human',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'example': {'default': False, 'title': 'Example', 'type': 'boolean'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'HumanMessage',\n",
       "   'type': 'object'},\n",
       "  'HumanMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Human Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'HumanMessageChunk',\n",
       "     'default': 'HumanMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'example': {'default': False, 'title': 'Example', 'type': 'boolean'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'HumanMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'InputTokenDetails': {'description': 'Breakdown of input token counts.\\n\\nDoes *not* need to sum to full input token count. Does *not* need to have all keys.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"audio\": 10,\\n            \"cache_creation\": 200,\\n            \"cache_read\": 100,\\n        }\\n\\n.. versionadded:: 0.3.9',\n",
       "   'properties': {'audio': {'title': 'Audio', 'type': 'integer'},\n",
       "    'cache_creation': {'title': 'Cache Creation', 'type': 'integer'},\n",
       "    'cache_read': {'title': 'Cache Read', 'type': 'integer'}},\n",
       "   'title': 'InputTokenDetails',\n",
       "   'type': 'object'},\n",
       "  'InvalidToolCall': {'description': 'Allowance for errors made by LLM.\\n\\nHere we add an `error` key to surface errors made during generation\\n(e.g., invalid JSON arguments.)',\n",
       "   'properties': {'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'title': 'Name'},\n",
       "    'args': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Args'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "    'error': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'title': 'Error'},\n",
       "    'type': {'const': 'invalid_tool_call', 'title': 'Type', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'error'],\n",
       "   'title': 'InvalidToolCall',\n",
       "   'type': 'object'},\n",
       "  'OutputTokenDetails': {'description': 'Breakdown of output token counts.\\n\\nDoes *not* need to sum to full output token count. Does *not* need to have all keys.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"audio\": 10,\\n            \"reasoning\": 200,\\n        }\\n\\n.. versionadded:: 0.3.9',\n",
       "   'properties': {'audio': {'title': 'Audio', 'type': 'integer'},\n",
       "    'reasoning': {'title': 'Reasoning', 'type': 'integer'}},\n",
       "   'title': 'OutputTokenDetails',\n",
       "   'type': 'object'},\n",
       "  'StringPromptValue': {'description': 'String prompt value.',\n",
       "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "    'type': {'const': 'StringPromptValue',\n",
       "     'default': 'StringPromptValue',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'}},\n",
       "   'required': ['text'],\n",
       "   'title': 'StringPromptValue',\n",
       "   'type': 'object'},\n",
       "  'SystemMessage': {'additionalProperties': True,\n",
       "   'description': 'Message for priming AI behavior.\\n\\nThe system message is usually passed in as the first of a sequence\\nof input messages.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Define a chat model and invoke it with the messages\\n        print(model.invoke(messages))',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'system',\n",
       "     'default': 'system',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'SystemMessage',\n",
       "   'type': 'object'},\n",
       "  'SystemMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'System Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'SystemMessageChunk',\n",
       "     'default': 'SystemMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'SystemMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'ToolCall': {'description': 'Represents a request to call a tool.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"name\": \"foo\",\\n            \"args\": {\"a\": 1},\\n            \"id\": \"123\"\\n        }\\n\\n    This represents a request to call the tool named \"foo\" with arguments {\"a\": 1}\\n    and an identifier of \"123\".',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'additionalProperties': True, 'title': 'Args', 'type': 'object'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "    'type': {'const': 'tool_call', 'title': 'Type', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id'],\n",
       "   'title': 'ToolCall',\n",
       "   'type': 'object'},\n",
       "  'ToolCallChunk': {'description': 'A chunk of a tool call (e.g., as part of a stream).\\n\\nWhen merging ToolCallChunks (e.g., via AIMessageChunk.__add__),\\nall string attributes are concatenated. Chunks are only merged if their\\nvalues of `index` are equal and not None.\\n\\nExample:\\n\\n.. code-block:: python\\n\\n    left_chunks = [ToolCallChunk(name=\"foo\", args=\\'{\"a\":\\', index=0)]\\n    right_chunks = [ToolCallChunk(name=None, args=\\'1}\\', index=0)]\\n\\n    (\\n        AIMessageChunk(content=\"\", tool_call_chunks=left_chunks)\\n        + AIMessageChunk(content=\"\", tool_call_chunks=right_chunks)\\n    ).tool_call_chunks == [ToolCallChunk(name=\\'foo\\', args=\\'{\"a\":1}\\', index=0)]',\n",
       "   'properties': {'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'title': 'Name'},\n",
       "    'args': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Args'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "    'index': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "     'title': 'Index'},\n",
       "    'type': {'const': 'tool_call_chunk', 'title': 'Type', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'index'],\n",
       "   'title': 'ToolCallChunk',\n",
       "   'type': 'object'},\n",
       "  'ToolMessage': {'additionalProperties': True,\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.\\n\\nToolMessages contain the result of a tool invocation. Typically, the result\\nis encoded inside the `content` field.\\n\\nExample: A ToolMessage representing a result of 42 from a tool call with id\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        ToolMessage(content=\\'42\\', tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\')\\n\\n\\nExample: A ToolMessage where only part of the tool output is sent to the model\\n    and the full output is passed in to artifact.\\n\\n    .. versionadded:: 0.2.17\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        tool_output = {\\n            \"stdout\": \"From the graph we can see that the correlation between x and y is ...\",\\n            \"stderr\": None,\\n            \"artifacts\": {\"type\": \"image\", \"base64_data\": \"/9j/4gIcSU...\"},\\n        }\\n\\n        ToolMessage(\\n            content=tool_output[\"stdout\"],\\n            artifact=tool_output,\\n            tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\',\\n        )\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'tool',\n",
       "     'default': 'tool',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'},\n",
       "    'artifact': {'default': None, 'title': 'Artifact'},\n",
       "    'status': {'default': 'success',\n",
       "     'enum': ['success', 'error'],\n",
       "     'title': 'Status',\n",
       "     'type': 'string'}},\n",
       "   'required': ['content', 'tool_call_id'],\n",
       "   'title': 'ToolMessage',\n",
       "   'type': 'object'},\n",
       "  'ToolMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Tool Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'ToolMessageChunk',\n",
       "     'default': 'ToolMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'},\n",
       "    'artifact': {'default': None, 'title': 'Artifact'},\n",
       "    'status': {'default': 'success',\n",
       "     'enum': ['success', 'error'],\n",
       "     'title': 'Status',\n",
       "     'type': 'string'}},\n",
       "   'required': ['content', 'tool_call_id'],\n",
       "   'title': 'ToolMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'UsageMetadata': {'description': 'Usage metadata for a message, such as token counts.\\n\\nThis is a standard representation of token usage that is consistent across models.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"input_tokens\": 350,\\n            \"output_tokens\": 240,\\n            \"total_tokens\": 590,\\n            \"input_token_details\": {\\n                \"audio\": 10,\\n                \"cache_creation\": 200,\\n                \"cache_read\": 100,\\n            },\\n            \"output_token_details\": {\\n                \"audio\": 10,\\n                \"reasoning\": 200,\\n            }\\n        }\\n\\n.. versionchanged:: 0.3.9\\n\\n    Added ``input_token_details`` and ``output_token_details``.',\n",
       "   'properties': {'input_tokens': {'title': 'Input Tokens', 'type': 'integer'},\n",
       "    'output_tokens': {'title': 'Output Tokens', 'type': 'integer'},\n",
       "    'total_tokens': {'title': 'Total Tokens', 'type': 'integer'},\n",
       "    'input_token_details': {'$ref': '#/$defs/InputTokenDetails'},\n",
       "    'output_token_details': {'$ref': '#/$defs/OutputTokenDetails'}},\n",
       "   'required': ['input_tokens', 'output_tokens', 'total_tokens'],\n",
       "   'title': 'UsageMetadata',\n",
       "   'type': 'object'}},\n",
       " 'anyOf': [{'type': 'string'},\n",
       "  {'$ref': '#/$defs/StringPromptValue'},\n",
       "  {'$ref': '#/$defs/ChatPromptValueConcrete'},\n",
       "  {'items': {'oneOf': [{'$ref': '#/$defs/AIMessage'},\n",
       "     {'$ref': '#/$defs/HumanMessage'},\n",
       "     {'$ref': '#/$defs/ChatMessage'},\n",
       "     {'$ref': '#/$defs/SystemMessage'},\n",
       "     {'$ref': '#/$defs/FunctionMessage'},\n",
       "     {'$ref': '#/$defs/ToolMessage'},\n",
       "     {'$ref': '#/$defs/AIMessageChunk'},\n",
       "     {'$ref': '#/$defs/HumanMessageChunk'},\n",
       "     {'$ref': '#/$defs/ChatMessageChunk'},\n",
       "     {'$ref': '#/$defs/SystemMessageChunk'},\n",
       "     {'$ref': '#/$defs/FunctionMessageChunk'},\n",
       "     {'$ref': '#/$defs/ToolMessageChunk'}]},\n",
       "   'type': 'array'}],\n",
       " 'title': 'ChatOpenAIInput'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not the same as the the chain and the prompt\n",
    "llm.input_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7d711c-a094-4759-b1f5-3623ef7a45bf",
   "metadata": {},
   "source": [
    "<h3>Output Schema</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b06cf2-c065-49c5-ba49-9b3e2d852d7f",
   "metadata": {},
   "source": [
    "<h5>The Output Schema of the chain is the output schema of its last part, in this case a ChatModel, which outputs a ChatMessage</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25bd8448-09f7-47d2-9c0d-f3e738d37e3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$defs': {'AIMessage': {'additionalProperties': True,\n",
       "   'description': 'Message from an AI.\\n\\nAIMessage is returned from a chat model as a response to a prompt.\\n\\nThis message represents the output of the model and consists of both\\nthe raw output as returned by the model together standardized fields\\n(e.g., tool calls, usage metadata) added by the LangChain framework.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'ai',\n",
       "     'default': 'ai',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'example': {'default': False, 'title': 'Example', 'type': 'boolean'},\n",
       "    'tool_calls': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/ToolCall'},\n",
       "     'title': 'Tool Calls',\n",
       "     'type': 'array'},\n",
       "    'invalid_tool_calls': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/InvalidToolCall'},\n",
       "     'title': 'Invalid Tool Calls',\n",
       "     'type': 'array'},\n",
       "    'usage_metadata': {'anyOf': [{'$ref': '#/$defs/UsageMetadata'},\n",
       "      {'type': 'null'}],\n",
       "     'default': None}},\n",
       "   'required': ['content'],\n",
       "   'title': 'AIMessage',\n",
       "   'type': 'object'},\n",
       "  'AIMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Message chunk from an AI.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'AIMessageChunk',\n",
       "     'default': 'AIMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'example': {'default': False, 'title': 'Example', 'type': 'boolean'},\n",
       "    'tool_calls': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/ToolCall'},\n",
       "     'title': 'Tool Calls',\n",
       "     'type': 'array'},\n",
       "    'invalid_tool_calls': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/InvalidToolCall'},\n",
       "     'title': 'Invalid Tool Calls',\n",
       "     'type': 'array'},\n",
       "    'usage_metadata': {'anyOf': [{'$ref': '#/$defs/UsageMetadata'},\n",
       "      {'type': 'null'}],\n",
       "     'default': None},\n",
       "    'tool_call_chunks': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/ToolCallChunk'},\n",
       "     'title': 'Tool Call Chunks',\n",
       "     'type': 'array'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'AIMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'ChatMessage': {'additionalProperties': True,\n",
       "   'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'chat',\n",
       "     'default': 'chat',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role'],\n",
       "   'title': 'ChatMessage',\n",
       "   'type': 'object'},\n",
       "  'ChatMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Chat Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'ChatMessageChunk',\n",
       "     'default': 'ChatMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role'],\n",
       "   'title': 'ChatMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'FunctionMessage': {'additionalProperties': True,\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.\\n\\nFunctionMessage are an older version of the ToolMessage schema, and\\ndo not contain the tool_call_id field.\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'function',\n",
       "     'default': 'function',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content', 'name'],\n",
       "   'title': 'FunctionMessage',\n",
       "   'type': 'object'},\n",
       "  'FunctionMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Function Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'FunctionMessageChunk',\n",
       "     'default': 'FunctionMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content', 'name'],\n",
       "   'title': 'FunctionMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'HumanMessage': {'additionalProperties': True,\n",
       "   'description': 'Message from a human.\\n\\nHumanMessages are messages that are passed in from a human to the model.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Instantiate a chat model and invoke it with the messages\\n        model = ...\\n        print(model.invoke(messages))',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'human',\n",
       "     'default': 'human',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'example': {'default': False, 'title': 'Example', 'type': 'boolean'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'HumanMessage',\n",
       "   'type': 'object'},\n",
       "  'HumanMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Human Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'HumanMessageChunk',\n",
       "     'default': 'HumanMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'example': {'default': False, 'title': 'Example', 'type': 'boolean'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'HumanMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'InputTokenDetails': {'description': 'Breakdown of input token counts.\\n\\nDoes *not* need to sum to full input token count. Does *not* need to have all keys.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"audio\": 10,\\n            \"cache_creation\": 200,\\n            \"cache_read\": 100,\\n        }\\n\\n.. versionadded:: 0.3.9',\n",
       "   'properties': {'audio': {'title': 'Audio', 'type': 'integer'},\n",
       "    'cache_creation': {'title': 'Cache Creation', 'type': 'integer'},\n",
       "    'cache_read': {'title': 'Cache Read', 'type': 'integer'}},\n",
       "   'title': 'InputTokenDetails',\n",
       "   'type': 'object'},\n",
       "  'InvalidToolCall': {'description': 'Allowance for errors made by LLM.\\n\\nHere we add an `error` key to surface errors made during generation\\n(e.g., invalid JSON arguments.)',\n",
       "   'properties': {'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'title': 'Name'},\n",
       "    'args': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Args'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "    'error': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'title': 'Error'},\n",
       "    'type': {'const': 'invalid_tool_call', 'title': 'Type', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'error'],\n",
       "   'title': 'InvalidToolCall',\n",
       "   'type': 'object'},\n",
       "  'OutputTokenDetails': {'description': 'Breakdown of output token counts.\\n\\nDoes *not* need to sum to full output token count. Does *not* need to have all keys.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"audio\": 10,\\n            \"reasoning\": 200,\\n        }\\n\\n.. versionadded:: 0.3.9',\n",
       "   'properties': {'audio': {'title': 'Audio', 'type': 'integer'},\n",
       "    'reasoning': {'title': 'Reasoning', 'type': 'integer'}},\n",
       "   'title': 'OutputTokenDetails',\n",
       "   'type': 'object'},\n",
       "  'SystemMessage': {'additionalProperties': True,\n",
       "   'description': 'Message for priming AI behavior.\\n\\nThe system message is usually passed in as the first of a sequence\\nof input messages.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Define a chat model and invoke it with the messages\\n        print(model.invoke(messages))',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'system',\n",
       "     'default': 'system',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'SystemMessage',\n",
       "   'type': 'object'},\n",
       "  'SystemMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'System Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'SystemMessageChunk',\n",
       "     'default': 'SystemMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'SystemMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'ToolCall': {'description': 'Represents a request to call a tool.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"name\": \"foo\",\\n            \"args\": {\"a\": 1},\\n            \"id\": \"123\"\\n        }\\n\\n    This represents a request to call the tool named \"foo\" with arguments {\"a\": 1}\\n    and an identifier of \"123\".',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'additionalProperties': True, 'title': 'Args', 'type': 'object'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "    'type': {'const': 'tool_call', 'title': 'Type', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id'],\n",
       "   'title': 'ToolCall',\n",
       "   'type': 'object'},\n",
       "  'ToolCallChunk': {'description': 'A chunk of a tool call (e.g., as part of a stream).\\n\\nWhen merging ToolCallChunks (e.g., via AIMessageChunk.__add__),\\nall string attributes are concatenated. Chunks are only merged if their\\nvalues of `index` are equal and not None.\\n\\nExample:\\n\\n.. code-block:: python\\n\\n    left_chunks = [ToolCallChunk(name=\"foo\", args=\\'{\"a\":\\', index=0)]\\n    right_chunks = [ToolCallChunk(name=None, args=\\'1}\\', index=0)]\\n\\n    (\\n        AIMessageChunk(content=\"\", tool_call_chunks=left_chunks)\\n        + AIMessageChunk(content=\"\", tool_call_chunks=right_chunks)\\n    ).tool_call_chunks == [ToolCallChunk(name=\\'foo\\', args=\\'{\"a\":1}\\', index=0)]',\n",
       "   'properties': {'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'title': 'Name'},\n",
       "    'args': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Args'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "    'index': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "     'title': 'Index'},\n",
       "    'type': {'const': 'tool_call_chunk', 'title': 'Type', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'index'],\n",
       "   'title': 'ToolCallChunk',\n",
       "   'type': 'object'},\n",
       "  'ToolMessage': {'additionalProperties': True,\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.\\n\\nToolMessages contain the result of a tool invocation. Typically, the result\\nis encoded inside the `content` field.\\n\\nExample: A ToolMessage representing a result of 42 from a tool call with id\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        ToolMessage(content=\\'42\\', tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\')\\n\\n\\nExample: A ToolMessage where only part of the tool output is sent to the model\\n    and the full output is passed in to artifact.\\n\\n    .. versionadded:: 0.2.17\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        tool_output = {\\n            \"stdout\": \"From the graph we can see that the correlation between x and y is ...\",\\n            \"stderr\": None,\\n            \"artifacts\": {\"type\": \"image\", \"base64_data\": \"/9j/4gIcSU...\"},\\n        }\\n\\n        ToolMessage(\\n            content=tool_output[\"stdout\"],\\n            artifact=tool_output,\\n            tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\',\\n        )\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'tool',\n",
       "     'default': 'tool',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'},\n",
       "    'artifact': {'default': None, 'title': 'Artifact'},\n",
       "    'status': {'default': 'success',\n",
       "     'enum': ['success', 'error'],\n",
       "     'title': 'Status',\n",
       "     'type': 'string'}},\n",
       "   'required': ['content', 'tool_call_id'],\n",
       "   'title': 'ToolMessage',\n",
       "   'type': 'object'},\n",
       "  'ToolMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Tool Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'ToolMessageChunk',\n",
       "     'default': 'ToolMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'},\n",
       "    'artifact': {'default': None, 'title': 'Artifact'},\n",
       "    'status': {'default': 'success',\n",
       "     'enum': ['success', 'error'],\n",
       "     'title': 'Status',\n",
       "     'type': 'string'}},\n",
       "   'required': ['content', 'tool_call_id'],\n",
       "   'title': 'ToolMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'UsageMetadata': {'description': 'Usage metadata for a message, such as token counts.\\n\\nThis is a standard representation of token usage that is consistent across models.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"input_tokens\": 350,\\n            \"output_tokens\": 240,\\n            \"total_tokens\": 590,\\n            \"input_token_details\": {\\n                \"audio\": 10,\\n                \"cache_creation\": 200,\\n                \"cache_read\": 100,\\n            },\\n            \"output_token_details\": {\\n                \"audio\": 10,\\n                \"reasoning\": 200,\\n            }\\n        }\\n\\n.. versionchanged:: 0.3.9\\n\\n    Added ``input_token_details`` and ``output_token_details``.',\n",
       "   'properties': {'input_tokens': {'title': 'Input Tokens', 'type': 'integer'},\n",
       "    'output_tokens': {'title': 'Output Tokens', 'type': 'integer'},\n",
       "    'total_tokens': {'title': 'Total Tokens', 'type': 'integer'},\n",
       "    'input_token_details': {'$ref': '#/$defs/InputTokenDetails'},\n",
       "    'output_token_details': {'$ref': '#/$defs/OutputTokenDetails'}},\n",
       "   'required': ['input_tokens', 'output_tokens', 'total_tokens'],\n",
       "   'title': 'UsageMetadata',\n",
       "   'type': 'object'}},\n",
       " 'oneOf': [{'$ref': '#/$defs/AIMessage'},\n",
       "  {'$ref': '#/$defs/HumanMessage'},\n",
       "  {'$ref': '#/$defs/ChatMessage'},\n",
       "  {'$ref': '#/$defs/SystemMessage'},\n",
       "  {'$ref': '#/$defs/FunctionMessage'},\n",
       "  {'$ref': '#/$defs/ToolMessage'},\n",
       "  {'$ref': '#/$defs/AIMessageChunk'},\n",
       "  {'$ref': '#/$defs/HumanMessageChunk'},\n",
       "  {'$ref': '#/$defs/ChatMessageChunk'},\n",
       "  {'$ref': '#/$defs/SystemMessageChunk'},\n",
       "  {'$ref': '#/$defs/FunctionMessageChunk'},\n",
       "  {'$ref': '#/$defs/ToolMessageChunk'}],\n",
       " 'title': 'ChatOpenAIOutput'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.output_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4286c156-5ad8-48e6-9c62-000bd802c5d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$defs': {'AIMessage': {'additionalProperties': True,\n",
       "   'description': 'Message from an AI.\\n\\nAIMessage is returned from a chat model as a response to a prompt.\\n\\nThis message represents the output of the model and consists of both\\nthe raw output as returned by the model together standardized fields\\n(e.g., tool calls, usage metadata) added by the LangChain framework.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'ai',\n",
       "     'default': 'ai',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'example': {'default': False, 'title': 'Example', 'type': 'boolean'},\n",
       "    'tool_calls': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/ToolCall'},\n",
       "     'title': 'Tool Calls',\n",
       "     'type': 'array'},\n",
       "    'invalid_tool_calls': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/InvalidToolCall'},\n",
       "     'title': 'Invalid Tool Calls',\n",
       "     'type': 'array'},\n",
       "    'usage_metadata': {'anyOf': [{'$ref': '#/$defs/UsageMetadata'},\n",
       "      {'type': 'null'}],\n",
       "     'default': None}},\n",
       "   'required': ['content'],\n",
       "   'title': 'AIMessage',\n",
       "   'type': 'object'},\n",
       "  'AIMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Message chunk from an AI.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'AIMessageChunk',\n",
       "     'default': 'AIMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'example': {'default': False, 'title': 'Example', 'type': 'boolean'},\n",
       "    'tool_calls': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/ToolCall'},\n",
       "     'title': 'Tool Calls',\n",
       "     'type': 'array'},\n",
       "    'invalid_tool_calls': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/InvalidToolCall'},\n",
       "     'title': 'Invalid Tool Calls',\n",
       "     'type': 'array'},\n",
       "    'usage_metadata': {'anyOf': [{'$ref': '#/$defs/UsageMetadata'},\n",
       "      {'type': 'null'}],\n",
       "     'default': None},\n",
       "    'tool_call_chunks': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/ToolCallChunk'},\n",
       "     'title': 'Tool Call Chunks',\n",
       "     'type': 'array'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'AIMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'ChatMessage': {'additionalProperties': True,\n",
       "   'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'chat',\n",
       "     'default': 'chat',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role'],\n",
       "   'title': 'ChatMessage',\n",
       "   'type': 'object'},\n",
       "  'ChatMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Chat Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'ChatMessageChunk',\n",
       "     'default': 'ChatMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role'],\n",
       "   'title': 'ChatMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'FunctionMessage': {'additionalProperties': True,\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.\\n\\nFunctionMessage are an older version of the ToolMessage schema, and\\ndo not contain the tool_call_id field.\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'function',\n",
       "     'default': 'function',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content', 'name'],\n",
       "   'title': 'FunctionMessage',\n",
       "   'type': 'object'},\n",
       "  'FunctionMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Function Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'FunctionMessageChunk',\n",
       "     'default': 'FunctionMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content', 'name'],\n",
       "   'title': 'FunctionMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'HumanMessage': {'additionalProperties': True,\n",
       "   'description': 'Message from a human.\\n\\nHumanMessages are messages that are passed in from a human to the model.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Instantiate a chat model and invoke it with the messages\\n        model = ...\\n        print(model.invoke(messages))',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'human',\n",
       "     'default': 'human',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'example': {'default': False, 'title': 'Example', 'type': 'boolean'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'HumanMessage',\n",
       "   'type': 'object'},\n",
       "  'HumanMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Human Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'HumanMessageChunk',\n",
       "     'default': 'HumanMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'example': {'default': False, 'title': 'Example', 'type': 'boolean'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'HumanMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'InputTokenDetails': {'description': 'Breakdown of input token counts.\\n\\nDoes *not* need to sum to full input token count. Does *not* need to have all keys.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"audio\": 10,\\n            \"cache_creation\": 200,\\n            \"cache_read\": 100,\\n        }\\n\\n.. versionadded:: 0.3.9',\n",
       "   'properties': {'audio': {'title': 'Audio', 'type': 'integer'},\n",
       "    'cache_creation': {'title': 'Cache Creation', 'type': 'integer'},\n",
       "    'cache_read': {'title': 'Cache Read', 'type': 'integer'}},\n",
       "   'title': 'InputTokenDetails',\n",
       "   'type': 'object'},\n",
       "  'InvalidToolCall': {'description': 'Allowance for errors made by LLM.\\n\\nHere we add an `error` key to surface errors made during generation\\n(e.g., invalid JSON arguments.)',\n",
       "   'properties': {'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'title': 'Name'},\n",
       "    'args': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Args'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "    'error': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'title': 'Error'},\n",
       "    'type': {'const': 'invalid_tool_call', 'title': 'Type', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'error'],\n",
       "   'title': 'InvalidToolCall',\n",
       "   'type': 'object'},\n",
       "  'OutputTokenDetails': {'description': 'Breakdown of output token counts.\\n\\nDoes *not* need to sum to full output token count. Does *not* need to have all keys.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"audio\": 10,\\n            \"reasoning\": 200,\\n        }\\n\\n.. versionadded:: 0.3.9',\n",
       "   'properties': {'audio': {'title': 'Audio', 'type': 'integer'},\n",
       "    'reasoning': {'title': 'Reasoning', 'type': 'integer'}},\n",
       "   'title': 'OutputTokenDetails',\n",
       "   'type': 'object'},\n",
       "  'SystemMessage': {'additionalProperties': True,\n",
       "   'description': 'Message for priming AI behavior.\\n\\nThe system message is usually passed in as the first of a sequence\\nof input messages.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Define a chat model and invoke it with the messages\\n        print(model.invoke(messages))',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'system',\n",
       "     'default': 'system',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'SystemMessage',\n",
       "   'type': 'object'},\n",
       "  'SystemMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'System Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'SystemMessageChunk',\n",
       "     'default': 'SystemMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'SystemMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'ToolCall': {'description': 'Represents a request to call a tool.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"name\": \"foo\",\\n            \"args\": {\"a\": 1},\\n            \"id\": \"123\"\\n        }\\n\\n    This represents a request to call the tool named \"foo\" with arguments {\"a\": 1}\\n    and an identifier of \"123\".',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'additionalProperties': True, 'title': 'Args', 'type': 'object'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "    'type': {'const': 'tool_call', 'title': 'Type', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id'],\n",
       "   'title': 'ToolCall',\n",
       "   'type': 'object'},\n",
       "  'ToolCallChunk': {'description': 'A chunk of a tool call (e.g., as part of a stream).\\n\\nWhen merging ToolCallChunks (e.g., via AIMessageChunk.__add__),\\nall string attributes are concatenated. Chunks are only merged if their\\nvalues of `index` are equal and not None.\\n\\nExample:\\n\\n.. code-block:: python\\n\\n    left_chunks = [ToolCallChunk(name=\"foo\", args=\\'{\"a\":\\', index=0)]\\n    right_chunks = [ToolCallChunk(name=None, args=\\'1}\\', index=0)]\\n\\n    (\\n        AIMessageChunk(content=\"\", tool_call_chunks=left_chunks)\\n        + AIMessageChunk(content=\"\", tool_call_chunks=right_chunks)\\n    ).tool_call_chunks == [ToolCallChunk(name=\\'foo\\', args=\\'{\"a\":1}\\', index=0)]',\n",
       "   'properties': {'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'title': 'Name'},\n",
       "    'args': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Args'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "    'index': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "     'title': 'Index'},\n",
       "    'type': {'const': 'tool_call_chunk', 'title': 'Type', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'index'],\n",
       "   'title': 'ToolCallChunk',\n",
       "   'type': 'object'},\n",
       "  'ToolMessage': {'additionalProperties': True,\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.\\n\\nToolMessages contain the result of a tool invocation. Typically, the result\\nis encoded inside the `content` field.\\n\\nExample: A ToolMessage representing a result of 42 from a tool call with id\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        ToolMessage(content=\\'42\\', tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\')\\n\\n\\nExample: A ToolMessage where only part of the tool output is sent to the model\\n    and the full output is passed in to artifact.\\n\\n    .. versionadded:: 0.2.17\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        tool_output = {\\n            \"stdout\": \"From the graph we can see that the correlation between x and y is ...\",\\n            \"stderr\": None,\\n            \"artifacts\": {\"type\": \"image\", \"base64_data\": \"/9j/4gIcSU...\"},\\n        }\\n\\n        ToolMessage(\\n            content=tool_output[\"stdout\"],\\n            artifact=tool_output,\\n            tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\',\\n        )\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'tool',\n",
       "     'default': 'tool',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'},\n",
       "    'artifact': {'default': None, 'title': 'Artifact'},\n",
       "    'status': {'default': 'success',\n",
       "     'enum': ['success', 'error'],\n",
       "     'title': 'Status',\n",
       "     'type': 'string'}},\n",
       "   'required': ['content', 'tool_call_id'],\n",
       "   'title': 'ToolMessage',\n",
       "   'type': 'object'},\n",
       "  'ToolMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Tool Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'const': 'ToolMessageChunk',\n",
       "     'default': 'ToolMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'},\n",
       "    'artifact': {'default': None, 'title': 'Artifact'},\n",
       "    'status': {'default': 'success',\n",
       "     'enum': ['success', 'error'],\n",
       "     'title': 'Status',\n",
       "     'type': 'string'}},\n",
       "   'required': ['content', 'tool_call_id'],\n",
       "   'title': 'ToolMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'UsageMetadata': {'description': 'Usage metadata for a message, such as token counts.\\n\\nThis is a standard representation of token usage that is consistent across models.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"input_tokens\": 350,\\n            \"output_tokens\": 240,\\n            \"total_tokens\": 590,\\n            \"input_token_details\": {\\n                \"audio\": 10,\\n                \"cache_creation\": 200,\\n                \"cache_read\": 100,\\n            },\\n            \"output_token_details\": {\\n                \"audio\": 10,\\n                \"reasoning\": 200,\\n            }\\n        }\\n\\n.. versionchanged:: 0.3.9\\n\\n    Added ``input_token_details`` and ``output_token_details``.',\n",
       "   'properties': {'input_tokens': {'title': 'Input Tokens', 'type': 'integer'},\n",
       "    'output_tokens': {'title': 'Output Tokens', 'type': 'integer'},\n",
       "    'total_tokens': {'title': 'Total Tokens', 'type': 'integer'},\n",
       "    'input_token_details': {'$ref': '#/$defs/InputTokenDetails'},\n",
       "    'output_token_details': {'$ref': '#/$defs/OutputTokenDetails'}},\n",
       "   'required': ['input_tokens', 'output_tokens', 'total_tokens'],\n",
       "   'title': 'UsageMetadata',\n",
       "   'type': 'object'}},\n",
       " 'oneOf': [{'$ref': '#/$defs/AIMessage'},\n",
       "  {'$ref': '#/$defs/HumanMessage'},\n",
       "  {'$ref': '#/$defs/ChatMessage'},\n",
       "  {'$ref': '#/$defs/SystemMessage'},\n",
       "  {'$ref': '#/$defs/FunctionMessage'},\n",
       "  {'$ref': '#/$defs/ToolMessage'},\n",
       "  {'$ref': '#/$defs/AIMessageChunk'},\n",
       "  {'$ref': '#/$defs/HumanMessageChunk'},\n",
       "  {'$ref': '#/$defs/ChatMessageChunk'},\n",
       "  {'$ref': '#/$defs/SystemMessageChunk'},\n",
       "  {'$ref': '#/$defs/FunctionMessageChunk'},\n",
       "  {'$ref': '#/$defs/ToolMessageChunk'}],\n",
       " 'title': 'ChatOpenAIOutput'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.output_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a2e88e-80eb-4dba-b0c8-a03760444e3b",
   "metadata": {},
   "source": [
    "<h3>Stream</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c090f21-8c75-447c-8c01-4ebc54ea0ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There once lived a beautiful bear in the heart of the forest named Ben. Ben was well-known for his gentle nature and kind heart. He spent his days exploring the woods, playing with his friends, and enjoying the simple pleasures of nature.\n",
      "\n",
      "One day, as Ben was taking a walk through the forest, he stumbled upon a group of hunters. They were setting traps and preparing to catch innocent animals for their own selfish purposes. Ben's heart sank as he realized the danger his friends were in.\n",
      "\n",
      "Filled with determination, Ben decided to take action. He bravely confronted the hunters, standing between them and the defenseless animals. With a fierce roar, he warned them to leave the forest and never return.\n",
      "\n",
      "The hunters, taken aback by Ben's courage and strength, quickly retreated, never to be seen again. Ben had saved his friends and protected the forest from harm.\n",
      "\n",
      "From that day on, Ben was hailed as a hero among the animals of the forest. He continued to roam the woods, watching over his friends and ensuring their safety. And though he may have been a bear of few words, his actions spoke volumes about his bravery and his unwavering commitment to protecting those he loved."
     ]
    }
   ],
   "source": [
    "for s in chain.stream(input={'topic':'bear'},):\n",
    "    print(s.content,end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc05fbb-1792-4f7d-95f0-01cebd14270e",
   "metadata": {},
   "source": [
    "<h3>Invoke</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c986bbfd-367f-4a7a-8651-db741acae6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Once in a dense forest, there lived a large and fearsome bear named Brawn. Despite his intimidating appearance, Brawn was actually a kind-hearted creature who cared deeply for his fellow forest animals. He would often help them gather food, protect them from predators, and even play games with the younger ones.\\n\\nOne day, a group of hunters entered the forest, determined to capture Brawn and sell him to a circus. The other animals were terrified and didn't know what to do. But Brawn knew he had to protect his friends, so he devised a plan.\\n\\nHe led the hunters on a wild chase through the forest, using his speed and agility to outrun them at every turn. As the hunters grew tired and frustrated, Brawn snuck back to the other animals and told them to hide in a nearby cave.\\n\\nThe hunters eventually gave up and left the forest, defeated and empty-handed. The animals emerged from their hiding spot and cheered for their brave friend, Brawn the bear.\\n\\nFrom that day on, Brawn was hailed as a hero among the forest creatures. They admired his courage and loyalty, and knew they could always count on him to keep them safe. And Brawn was happy knowing that he had earned the respect and gratitude of his friends.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input={\"topic\":\"bear\"}).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d4369-dab9-4cd6-90fc-b9caa073b5ec",
   "metadata": {},
   "source": [
    "<h3>Batch</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6026869a-45cf-4e0c-94a6-d138746fd3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Long ago, in a dense forest, there lived a fearsome bear named Grizzly. Grizzly was known throughout the forest as the largest and fiercest bear, striking fear into the hearts of all the creatures that lived there.\\n\\nOne day, a group of hunters came to the forest in search of a great challenge. They had heard tales of Grizzly and were eager to test their skills against such a powerful beast. The hunters set traps and laid bait, hoping to catch the mighty bear.\\n\\nBut Grizzly was no fool. He sensed the danger and cunningly avoided the traps, outsmarting the hunters at every turn. The hunters grew frustrated, determined to capture the elusive bear.\\n\\nAs the days passed, Grizzly grew tired of the constant threat to his life. He decided it was time to teach the hunters a lesson they would never forget. With a mighty roar, Grizzly charged at the hunters, sending them running in fear.\\n\\nFrom that day on, the hunters knew to never underestimate the power and intelligence of the great bear, Grizzly. And Grizzly continued to roam the forest, respected and feared by all who crossed his path.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 231, 'prompt_tokens': 16, 'total_tokens': 247, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Cxe9uAuAh8J94bK83F8qVS0tqI8nN', 'finish_reason': 'stop', 'logprobs': None}, id='run--c9083669-12ab-4f52-9112-1918b25ac10c-0', usage_metadata={'input_tokens': 16, 'output_tokens': 231, 'total_tokens': 247, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " AIMessage(content=\"Virat Kohli was born on November 5, 1988, in Delhi, India. From a young age, he showed a natural talent for cricket, and his determination and hard work soon paid off. He made his debut for the Indian national team in 2008, and quickly became one of the most promising players in the country.\\n\\nKohli's aggressive batting style and exceptional fielding skills set him apart from his peers, and he soon established himself as a key player in the Indian team. He quickly rose through the ranks and became the captain of the national team in 2013, leading them to many victories in both Test matches and One Day Internationals.\\n\\nKnown for his fiery temperament and passion for the game, Kohli has earned a reputation as one of the best batsmen in the world. His hunger for success and his relentless pursuit of excellence have made him a role model for aspiring cricketers everywhere.\\n\\nOff the field, Kohli is a devoted husband to his actress wife, Anushka Sharma, and a philanthropist with a heart of gold. He is involved in various charity initiatives and uses his platform to raise awareness about important social issues.\\n\\nVirat Kohli's journey from a young cricket enthusiast to a global icon is a testament to his talent, hard work, and unwavering determination to succeed. He continues to inspire millions of fans around the world with his extraordinary skills and passionate approach to the game.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 293, 'prompt_tokens': 19, 'total_tokens': 312, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Cxe9umjfTeHx9boJ0j5CbC6FM9XuS', 'finish_reason': 'stop', 'logprobs': None}, id='run--1d821b63-3f52-4691-b565-d13c0d4db53b-0', usage_metadata={'input_tokens': 19, 'output_tokens': 293, 'total_tokens': 312, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch(inputs=[\n",
    "    {\"topic\":\"bear\"},\n",
    "    {\"topic\":\"Virat Kohli\"}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99e530de-b3bd-4921-9e38-7f98c0fcb999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Once upon a time in a dense forest, there lived a lonely bear named Barnaby. He was known for his massive size and strength, but also for his gentle and kind nature. Despite his intimidating appearance, Barnaby was loved by all the animals in the forest.\\n\\nOne day, Barnaby stumbled upon a group of hunters who were looking for the perfect trophy to take home. The hunters were determined to capture Barnaby and sell him to a zoo for money. Fearful for his life, Barnaby knew he had to do something to protect himself.\\n\\nWith a heavy heart, Barnaby decided to leave the forest and seek refuge in the nearby mountains. As he roamed the rugged terrain, he faced many challenges and obstacles along the way. But through sheer determination and perseverance, Barnaby finally found a safe haven where he could live in peace and solitude.\\n\\nYears passed, and the forest animals never forgot their beloved Barnaby. They would often visit him in the mountains, bringing him gifts and sharing stories of their adventures. Despite being far away from his home, Barnaby was grateful to have found a new family who accepted him for who he truly was - a gentle giant with a heart of gold.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 241, 'prompt_tokens': 16, 'total_tokens': 257, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CxeAY8rUWw5SCgBlrfHOqShG6OErl', 'finish_reason': 'stop', 'logprobs': None}, id='run--cd1d0dd9-14c5-47e1-bcef-88e4c5c4fb63-0', usage_metadata={'input_tokens': 16, 'output_tokens': 241, 'total_tokens': 257, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " AIMessage(content=\"Virat Kohli is a name synonymous with cricket excellence. Hailing from Delhi, India, he began his cricketing journey at a young age and quickly rose through the ranks to become one of the most renowned players in the world.\\n\\nKnown for his aggressive batting style and unwavering determination, Virat has broken numerous records and established himself as a force to be reckoned with on the cricket field. His passion for the game is evident in every match he plays, as he consistently delivers outstanding performances and leads his team to victory.\\n\\nOff the field, Virat is known for his philanthropy work and charitable endeavors. He is a role model for many aspiring cricketers and is admired for his dedication to the sport and his commitment to giving back to the community.\\n\\nVirat's journey to success has not been without its challenges, but it is his resilience and perseverance that have truly set him apart. He continues to inspire fans and fellow players alike with his incredible talent and unshakeable spirit.\\n\\nIn conclusion, Virat Kohli is more than just a cricket player  he is a legend in the making, a true icon of the sport, and a source of inspiration for all who have the privilege of watching him play.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 246, 'prompt_tokens': 19, 'total_tokens': 265, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CxeAYrzOsptvEK6ME6WDP2w94ngpw', 'finish_reason': 'stop', 'logprobs': None}, id='run--5276c57b-89b4-4d2e-a6b1-12a1d9ddc564-0', usage_metadata={'input_tokens': 19, 'output_tokens': 246, 'total_tokens': 265, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting Concurrency\n",
    "\n",
    "chain.batch(\n",
    "    inputs=[\n",
    "    {\"topic\":\"bear\"},\n",
    "    {\"topic\":\"Virat Kohli\"},\n",
    "    ],\n",
    "    config={\n",
    "        \"max_concurrency\":5\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85a7468-1394-49f8-a250-6259beb0917e",
   "metadata": {},
   "source": [
    "<h3>Async Stream</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dea5abef-d6bb-4110-b3a2-ce8648091047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the heart of the forest lived a mighty brown bear named Leo. He was the largest and strongest bear in the woods, and he ruled over all the other animals with a firm but fair paw.\n",
      "\n",
      "Leo was a kind and gentle leader, always looking out for the well-being of his fellow creatures. He would often roam the forest, making sure everyone had enough food to eat and a warm den to sleep in. The other animals respected and admired him, knowing they were safe under his protection.\n",
      "\n",
      "However, one day a group of hunters arrived in the forest, hoping to capture Leo and take him away to a zoo. The animals were terrified, but Leo stood his ground, ready to defend his home and his friends at any cost.\n",
      "\n",
      "A fierce battle ensued, with Leo using all his strength and courage to protect his fellow creatures. In the end, the hunters were no match for the mighty bear, and they were forced to retreat from the forest.\n",
      "\n",
      "The other animals cheered and celebrated their hero, grateful for his bravery and loyalty. And from that day on, Leo was not just their king, but their guardian and savior as well."
     ]
    }
   ],
   "source": [
    "async for s in chain.astream(input={'topic':'bear'}):\n",
    "    print(s.content,end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647defea-f37e-43c9-921e-e32e59b5a4a6",
   "metadata": {},
   "source": [
    "<h3> Async Invoke </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "557a4aa5-fb9b-4c86-bc13-c5c5f6555a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Rohit Sharma was a young man with a dream. From a small town in India, he had always been passionate about cricket. He spent hours practicing on dusty fields, honing his skills and perfecting his technique.\\n\\nDespite facing numerous challenges and setbacks along the way, Rohit never gave up on his dream. He worked hard, pushing himself to be better each day. His perseverance paid off when he was selected to play for the Indian national team.\\n\\nRohit quickly made a name for himself as a talented and explosive batsman. His ability to score big runs and lead his team to victory earned him the nickname \"Hitman.\" He was loved by fans and respected by his teammates for his dedication and work ethic.\\n\\nWith each match, Rohit continued to improve and break records. He became the first cricketer in the world to score three double centuries in One Day Internationals. His talent and determination set him apart from his peers, making him one of the most formidable players in the game.\\n\\nRohit Sharma\\'s story was a testament to the power of hard work and perseverance. His journey from a small town boy to a cricketing superstar inspired millions around the world to never give up on their dreams.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 247, 'prompt_tokens': 18, 'total_tokens': 265, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CxeBu1kza95kUfEvOmlrblcjYraXR', 'finish_reason': 'stop', 'logprobs': None}, id='run--9296c14b-ef51-4d40-84e8-b922a2d0611e-0', usage_metadata={'input_tokens': 18, 'output_tokens': 247, 'total_tokens': 265, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chain.ainvoke(input={\"topic\":\"Rohit Sharma\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba824958-097a-4ca4-bc01-831142e48470",
   "metadata": {},
   "source": [
    "<h3>Async Batch </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bea462f3-40e2-4ead-99d8-7ea02727555b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"Sachin Tendulkar was undeniably one of the greatest cricketers of all time. His story began in Mumbai, where he showed immense talent and passion for the sport from a very young age. As a child, he would spend hours practicing in the streets of his neighborhood, dreaming of one day playing for the Indian national team.\\n\\nHis hard work and perseverance paid off when he made his international debut at the age of just 16. Despite facing much older and more experienced opponents, Sachin quickly proved himself to be a prodigy, scoring centuries and breaking records with astonishing regularity.\\n\\nOver the course of his career, Sachin became a national hero in India, with millions of fans around the world tuning in to watch him play. His skill with the bat was unmatched, and he faced some of the best bowlers in the world with grace and determination.\\n\\nBut it wasn't just his skill on the field that made Sachin so beloved. He was known for his humility, his sportsmanship, and his dedication to giving back to his community. Sachin Tendulkar was more than just a cricketer  he was an inspiration to millions, showing that with hard work, passion, and dedication, anything is possible.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 252, 'prompt_tokens': 21, 'total_tokens': 273, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CxeC9HFzSR4QcSscftFunEcLF9tTd', 'finish_reason': 'stop', 'logprobs': None}, id='run--b396af96-9eac-453d-9ed8-ba630cdd8705-0', usage_metadata={'input_tokens': 21, 'output_tokens': 252, 'total_tokens': 273, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " AIMessage(content='Shane Warne was a legendary Australian cricketer known for his incredible skills as a leg-spin bowler. Born in Victoria in 1969, Warne made his international debut in 1992 and quickly established himself as one of the best bowlers in the world.\\n\\nWith his trademark delivery known as the Ball of the Century, Warne became famous for his ability to bamboozle batsmen with his spin and guile. He played a crucial role in Australias dominance in Test cricket during the 1990s and early 2000s, helping the team win multiple Ashes series and the World Cup.\\n\\nOff the field, Warne was known for his charismatic personality and larger-than-life persona. He was often in the headlines for his controversial comments and off-field antics, but his dedication to the game was never in doubt.\\n\\nDespite facing his fair share of controversies and setbacks, Warne continued to excel on the cricket field and was considered one of the greatest bowlers of all time. His record of 708 Test wickets stood for many years before being surpassed by other bowlers.\\n\\nIn retirement, Warne has become a successful commentator and poker player, further cementing his status as a true sports icon. His legacy in the world of cricket will never be forgotten, and he will always be remembered as one of the games greatest players.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 276, 'prompt_tokens': 18, 'total_tokens': 294, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CxeC98qjKJ1QKY84yELh0lxhqvwza', 'finish_reason': 'stop', 'logprobs': None}, id='run--d06455ac-a2bf-421f-8ccb-af444822d1c6-0', usage_metadata={'input_tokens': 18, 'output_tokens': 276, 'total_tokens': 294, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chain.abatch(inputs=[{\"topic\":\"Sachin Tendulkar\"},{\"topic\":\"Shane Warne\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2baecc-f5bf-4720-b663-f0c54f9715bc",
   "metadata": {},
   "source": [
    "<h3>Event Reference</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28f36f6f-6634-4e23-aac2-19cf07a38209",
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(template=template)\n",
    "\n",
    "vectorStore=FAISS.from_texts(\n",
    "    texts=[\"Ritish has a 18 month old son !\",\n",
    "           \"Rohit is Ritish's Younger Brother\",\n",
    "           \"Eklavya is Ritish's Son\"\n",
    "           \"Rekha is the name of Ritish's Mother\",\n",
    "           \"Anirban is Ritish's Father\"],\n",
    "    embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever=vectorStore.as_retriever()\n",
    "\n",
    "outputParser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e681b51-acb8-4abe-8afb-ab229b94cac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrievalChain=RunnablePassthrough.assign(context=itemgetter(\"question\")|retriever.with_config(run_name=\"Docs\") ) | prompt | llm.with_config(run_name=\"my_llm\") | outputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f83a4f7-29ab-4ade-8f55-90048d1f9c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question={\"question\":\"Who is Anirban's Wife and who is Eklavya's Uncle?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbbe73d9-ab29-4ab6-8e21-f96209d8484d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anirban's wife is Rekha, and Eklavya's uncle is Rohit.\n"
     ]
    }
   ],
   "source": [
    "print(retrievalChain.invoke(input=question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a52a72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_retriever_start', 'name': 'Docs', 'run_id': '9c264c6c-416a-40e9-a6e0-e1cd7a1da3ce', 'tags': ['seq:step:2', 'FAISS', 'OpenAIEmbeddings'], 'metadata': {'ls_retriever_name': 'vectorstore', 'ls_vector_store_provider': 'FAISS', 'ls_embedding_provider': 'OpenAIEmbeddings'}, 'data': {'input': {'query': \"Who is Anirban's Wife and who is Eklavya's Uncle?\"}}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_retriever_end', 'name': 'Docs', 'run_id': '9c264c6c-416a-40e9-a6e0-e1cd7a1da3ce', 'tags': ['seq:step:2', 'FAISS', 'OpenAIEmbeddings'], 'metadata': {'ls_retriever_name': 'vectorstore', 'ls_vector_store_provider': 'FAISS', 'ls_embedding_provider': 'OpenAIEmbeddings', 'LANGSMITH_ENDPOINT': 'https://api.smith.langchain.com', 'LANGSMITH_PROJECT': 'tutorial-project', 'LANGSMITH_TRACING': 'true', 'revision_id': 'da0f6c7-dirty'}, 'data': {'input': {'query': \"Who is Anirban's Wife and who is Eklavya's Uncle?\"}, 'output': {'documents': [Document(id='070cd071-88b3-4a2c-b2bb-3a47fe0766a3', metadata={}, page_content=\"Anirban is Ritish's Father\"), Document(id='7232316e-dfe2-41d6-9396-bb59602ea9f0', metadata={}, page_content=\"Eklavya is Ritish's SonRekha is the name of Ritish's Mother\"), Document(id='9ed7ab3d-a152-43cd-91e4-aed21eda3cd1', metadata={}, page_content=\"Rohit is Ritish's Younger Brother\"), Document(id='b3c9243c-1c52-467c-a322-322046b0b5b3', metadata={}, page_content='Ritish has a 18 month old son !')]}}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_start', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'input': {'messages': [[HumanMessage(content='\\nAnswer the question based only on the following context:\\n[Document(id=\\'070cd071-88b3-4a2c-b2bb-3a47fe0766a3\\', metadata={}, page_content=\"Anirban is Ritish\\'s Father\"), Document(id=\\'7232316e-dfe2-41d6-9396-bb59602ea9f0\\', metadata={}, page_content=\"Eklavya is Ritish\\'s SonRekha is the name of Ritish\\'s Mother\"), Document(id=\\'9ed7ab3d-a152-43cd-91e4-aed21eda3cd1\\', metadata={}, page_content=\"Rohit is Ritish\\'s Younger Brother\"), Document(id=\\'b3c9243c-1c52-467c-a322-322046b0b5b3\\', metadata={}, page_content=\\'Ritish has a 18 month old son !\\')]\\n\\nQuestion: Who is Anirban\\'s Wife and who is Eklavya\\'s Uncle?\\n', additional_kwargs={}, response_metadata={})]]}}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='An', additional_kwargs={}, response_metadata={}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='ir', additional_kwargs={}, response_metadata={}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='ban', additional_kwargs={}, response_metadata={}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=\"'s\", additional_kwargs={}, response_metadata={}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' wife', additional_kwargs={}, response_metadata={}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' Re', additional_kwargs={}, response_metadata={}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='k', additional_kwargs={}, response_metadata={}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='ha', additional_kwargs={}, response_metadata={}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' E', additional_kwargs={}, response_metadata={}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='kl', additional_kwargs={}, response_metadata={}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='avy', additional_kwargs={}, response_metadata={}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='a', additional_kwargs={}, response_metadata={}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=\"'s\", additional_kwargs={}, response_metadata={}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' uncle', additional_kwargs={}, response_metadata={}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' Roh', additional_kwargs={}, response_metadata={}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='it', additional_kwargs={}, response_metadata={}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_stream', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b')}, 'parent_ids': []} \n",
      "\n",
      "{'event': 'on_chat_model_end', 'name': 'my_llm', 'run_id': 'e0150899-f5c4-46ef-a3d7-7b21b5e14d9b', 'tags': ['seq:step:3'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'input': {'messages': [[HumanMessage(content='\\nAnswer the question based only on the following context:\\n[Document(id=\\'070cd071-88b3-4a2c-b2bb-3a47fe0766a3\\', metadata={}, page_content=\"Anirban is Ritish\\'s Father\"), Document(id=\\'7232316e-dfe2-41d6-9396-bb59602ea9f0\\', metadata={}, page_content=\"Eklavya is Ritish\\'s SonRekha is the name of Ritish\\'s Mother\"), Document(id=\\'9ed7ab3d-a152-43cd-91e4-aed21eda3cd1\\', metadata={}, page_content=\"Rohit is Ritish\\'s Younger Brother\"), Document(id=\\'b3c9243c-1c52-467c-a322-322046b0b5b3\\', metadata={}, page_content=\\'Ritish has a 18 month old son !\\')]\\n\\nQuestion: Who is Anirban\\'s Wife and who is Eklavya\\'s Uncle?\\n', additional_kwargs={}, response_metadata={})]]}, 'output': {'generations': [[{'generation_info': {'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, 'type': 'ChatGenerationChunk', 'message': AIMessageChunk(content=\"Anirban's wife is Rekha, and Eklavya's uncle is Rohit.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run--e0150899-f5c4-46ef-a3d7-7b21b5e14d9b'), 'text': \"Anirban's wife is Rekha, and Eklavya's uncle is Rohit.\"}]], 'llm_output': None, 'run': None, 'type': 'LLMResult'}}, 'parent_ids': []} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "async for event in retrievalChain.astream_events(input=question,\n",
    "                                                 version=\"v1\",\n",
    "                                                 include_names=[\"Docs\",\"my_llm\"]\n",
    "                                                ):\n",
    "    print(event,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3230d52e-7091-4cf2-b888-dcf370d5fb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved the following Documents:\n",
      "[Document(id='070cd071-88b3-4a2c-b2bb-3a47fe0766a3', metadata={}, page_content=\"Anirban is Ritish's Father\"), Document(id='7232316e-dfe2-41d6-9396-bb59602ea9f0', metadata={}, page_content=\"Eklavya is Ritish's SonRekha is the name of Ritish's Mother\"), Document(id='9ed7ab3d-a152-43cd-91e4-aed21eda3cd1', metadata={}, page_content=\"Rohit is Ritish's Younger Brother\"), Document(id='b3c9243c-1c52-467c-a322-322046b0b5b3', metadata={}, page_content='Ritish has a 18 month old son !')]\n",
      "\n",
      "Streaming LLM\n",
      "|An|ir|ban|'s| wife| is| Re|k|ha| and| E|kl|avy|a|'s| uncle| is| Roh|it|.||Done Streaming LLM.\n"
     ]
    }
   ],
   "source": [
    "async for event in retrievalChain.astream_events(input=question,\n",
    "                                                 version=\"v1\",\n",
    "                                                 include_names=[\"Docs\",\"my_llm\"]\n",
    "                                                ):\n",
    "    kind=event['event']\n",
    "    if kind==\"on_chat_model_stream\":\n",
    "        print(event[\"data\"][\"chunk\"].content,end=\"|\")\n",
    "    elif kind==\"on_chat_model_start\":\n",
    "        print(\"\\nStreaming LLM\")\n",
    "    elif kind==\"on_chat_model_end\":\n",
    "        print(\"Done Streaming LLM.\")\n",
    "    elif kind==\"on_retriever_end\":\n",
    "        print(\"Retrieved the following Documents:\")\n",
    "        print(event[\"data\"][\"output\"][\"documents\"])\n",
    "    elif kind==\"on_tool_end\":\n",
    "        print(f\"Ended Tool: {event['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7baea12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved the following Documents:\n",
      "[Document(id='070cd071-88b3-4a2c-b2bb-3a47fe0766a3', metadata={}, page_content=\"Anirban is Ritish's Father\"), Document(id='7232316e-dfe2-41d6-9396-bb59602ea9f0', metadata={}, page_content=\"Eklavya is Ritish's SonRekha is the name of Ritish's Mother\"), Document(id='9ed7ab3d-a152-43cd-91e4-aed21eda3cd1', metadata={}, page_content=\"Rohit is Ritish's Younger Brother\"), Document(id='b3c9243c-1c52-467c-a322-322046b0b5b3', metadata={}, page_content='Ritish has a 18 month old son !')]\n",
      "\n",
      "Streaming LLM\n",
      "|An|ir|ban|'s| wife| is| Re|k|ha| and| E|kl|avy|a|'s| uncle| is| Roh|it|.||Done Streaming LLM.\n"
     ]
    }
   ],
   "source": [
    "async for event in retrievalChain.astream_events(input=question,\n",
    "                                                 version=\"v2\",\n",
    "                                                 include_names=[\"Docs\",\"my_llm\"]\n",
    "                                                ):\n",
    "    kind=event['event']\n",
    "    if kind==\"on_chat_model_stream\":\n",
    "        print(event[\"data\"][\"chunk\"].content,end=\"|\")\n",
    "    elif kind==\"on_chat_model_start\":\n",
    "        print(\"\\nStreaming LLM\")\n",
    "    elif kind==\"on_chat_model_end\":\n",
    "        print(\"Done Streaming LLM.\")\n",
    "    elif kind==\"on_retriever_end\":\n",
    "        print(\"Retrieved the following Documents:\")\n",
    "        print(event['data']['output'])\n",
    "        # print(event[\"data\"][\"output\"][\"documents\"])\n",
    "    elif kind==\"on_tool_end\":\n",
    "        print(f\"Ended Tool: {event['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "859e0241-7e14-428e-8fb7-929500d9f0be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "RunLogPatch({'op': 'replace',\n",
      "  'path': '',\n",
      "  'value': {'final_output': None,\n",
      "            'id': '51cd7d04-383e-45db-b4a0-29d319fa3f20',\n",
      "            'logs': {},\n",
      "            'name': 'RunnableSequence',\n",
      "            'streamed_output': [],\n",
      "            'type': 'chain'}})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/Docs',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '1b6c6dff-cadb-4a15-9366-2e8ebddc44d4',\n",
      "            'metadata': {'ls_embedding_provider': 'HuggingFaceEmbeddings',\n",
      "                         'ls_retriever_name': 'vectorstore',\n",
      "                         'ls_vector_store_provider': 'FAISS'},\n",
      "            'name': 'Docs',\n",
      "            'start_time': '2025-06-04T13:31:28.709+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:2', 'FAISS', 'HuggingFaceEmbeddings'],\n",
      "            'type': 'retriever'}})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/Docs/final_output',\n",
      "  'value': {'documents': [Document(id='ff006209-317b-444c-a9fc-53a071e0d30b', metadata={}, page_content=\"Anirban is Ritish's Father\"),\n",
      "                          Document(id='d9d3ca99-6542-41fa-8425-5e04603e4456', metadata={}, page_content=\"Eklavya is Ritish's SonRekha is the name of Ritish's Mother\"),\n",
      "                          Document(id='4f946bb7-1c22-4e8d-a92e-6770170c32c5', metadata={}, page_content=\"Rohit is Ritish's Younger Brother\"),\n",
      "                          Document(id='52a32645-9b15-4a84-b7e0-24a5cf925726', metadata={}, page_content='Ritish has a 10 month old son !')]}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/Docs/end_time',\n",
      "  'value': '2025-06-04T13:31:28.749+00:00'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'Based'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': 'Based'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' on the provided'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': 'Based on the provided'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': \" information:\\n\\n*   Anirban's wife is not mentioned.\"},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'Based on the provided information:\\n'\n",
      "           '\\n'\n",
      "           \"*   Anirban's wife is not mentioned.\"})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': \"*   Eklavya's uncle is Rohit.\"},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'Based on the provided information:\\n'\n",
      "           '\\n'\n",
      "           \"*   Anirban's wife is not mentioned.*   Eklavya's uncle is Rohit.\"})\n"
     ]
    }
   ],
   "source": [
    "async for chunk in retrievalChain.astream_log(input=question,include_names=[\"Docs\"]):\n",
    "    print(\"-\"*40)\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "51648bec-669e-42cd-a6c8-af81db67ade0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "RunLog({'final_output': None,\n",
      " 'id': '285c7584-ffc6-4fda-8de4-3a2a96530f6c',\n",
      " 'logs': {},\n",
      " 'name': 'RunnableSequence',\n",
      " 'streamed_output': [],\n",
      " 'type': 'chain'})\n",
      "----------------------------------------\n",
      "RunLog({'final_output': None,\n",
      " 'id': '285c7584-ffc6-4fda-8de4-3a2a96530f6c',\n",
      " 'logs': {'Docs': {'end_time': None,\n",
      "                   'final_output': None,\n",
      "                   'id': 'd6cba482-cd44-4f72-bab0-7fe738b5d482',\n",
      "                   'metadata': {'ls_embedding_provider': 'HuggingFaceEmbeddings',\n",
      "                                'ls_retriever_name': 'vectorstore',\n",
      "                                'ls_vector_store_provider': 'FAISS'},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2024-09-24T20:44:13.157+00:00',\n",
      "                   'streamed_output': [],\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['seq:step:2', 'FAISS', 'HuggingFaceEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'name': 'RunnableSequence',\n",
      " 'streamed_output': [],\n",
      " 'type': 'chain'})\n",
      "----------------------------------------\n",
      "RunLog({'final_output': None,\n",
      " 'id': '285c7584-ffc6-4fda-8de4-3a2a96530f6c',\n",
      " 'logs': {'Docs': {'end_time': '2024-09-24T20:44:13.202+00:00',\n",
      "                   'final_output': {'documents': [Document(page_content=\"Anirban is Ritish's Father\"),\n",
      "                                                  Document(page_content=\"Rekha is the name of Ritish's Mother\"),\n",
      "                                                  Document(page_content=\"Rohit is Ritish's Younger Brother\"),\n",
      "                                                  Document(page_content='Ritish has a 2.5 month old son !')]},\n",
      "                   'id': 'd6cba482-cd44-4f72-bab0-7fe738b5d482',\n",
      "                   'metadata': {'ls_embedding_provider': 'HuggingFaceEmbeddings',\n",
      "                                'ls_retriever_name': 'vectorstore',\n",
      "                                'ls_vector_store_provider': 'FAISS'},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2024-09-24T20:44:13.157+00:00',\n",
      "                   'streamed_output': [],\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['seq:step:2', 'FAISS', 'HuggingFaceEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'name': 'RunnableSequence',\n",
      " 'streamed_output': [],\n",
      " 'type': 'chain'})\n",
      "----------------------------------------\n",
      "RunLog({'final_output': \"Here's the\",\n",
      " 'id': '285c7584-ffc6-4fda-8de4-3a2a96530f6c',\n",
      " 'logs': {'Docs': {'end_time': '2024-09-24T20:44:13.202+00:00',\n",
      "                   'final_output': {'documents': [Document(page_content=\"Anirban is Ritish's Father\"),\n",
      "                                                  Document(page_content=\"Rekha is the name of Ritish's Mother\"),\n",
      "                                                  Document(page_content=\"Rohit is Ritish's Younger Brother\"),\n",
      "                                                  Document(page_content='Ritish has a 2.5 month old son !')]},\n",
      "                   'id': 'd6cba482-cd44-4f72-bab0-7fe738b5d482',\n",
      "                   'metadata': {'ls_embedding_provider': 'HuggingFaceEmbeddings',\n",
      "                                'ls_retriever_name': 'vectorstore',\n",
      "                                'ls_vector_store_provider': 'FAISS'},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2024-09-24T20:44:13.157+00:00',\n",
      "                   'streamed_output': [],\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['seq:step:2', 'FAISS', 'HuggingFaceEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'name': 'RunnableSequence',\n",
      " 'streamed_output': [\"Here's the\"],\n",
      " 'type': 'chain'})\n",
      "----------------------------------------\n",
      "RunLog({'final_output': \"Here's the breakdown based on the provided context:\\n\"\n",
      "                 '\\n'\n",
      "                 \"* **Anirban's Wife:**\",\n",
      " 'id': '285c7584-ffc6-4fda-8de4-3a2a96530f6c',\n",
      " 'logs': {'Docs': {'end_time': '2024-09-24T20:44:13.202+00:00',\n",
      "                   'final_output': {'documents': [Document(page_content=\"Anirban is Ritish's Father\"),\n",
      "                                                  Document(page_content=\"Rekha is the name of Ritish's Mother\"),\n",
      "                                                  Document(page_content=\"Rohit is Ritish's Younger Brother\"),\n",
      "                                                  Document(page_content='Ritish has a 2.5 month old son !')]},\n",
      "                   'id': 'd6cba482-cd44-4f72-bab0-7fe738b5d482',\n",
      "                   'metadata': {'ls_embedding_provider': 'HuggingFaceEmbeddings',\n",
      "                                'ls_retriever_name': 'vectorstore',\n",
      "                                'ls_vector_store_provider': 'FAISS'},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2024-09-24T20:44:13.157+00:00',\n",
      "                   'streamed_output': [],\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['seq:step:2', 'FAISS', 'HuggingFaceEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'name': 'RunnableSequence',\n",
      " 'streamed_output': [\"Here's the\",\n",
      "                     ' breakdown based on the provided context:\\n'\n",
      "                     '\\n'\n",
      "                     \"* **Anirban's Wife:**\"],\n",
      " 'type': 'chain'})\n",
      "----------------------------------------\n",
      "RunLog({'final_output': \"Here's the breakdown based on the provided context:\\n\"\n",
      "                 '\\n'\n",
      "                 '* **Anirban\\'s Wife:** The context states that \"Rekha is the '\n",
      "                 \"name of Ritish's Mother\",\n",
      " 'id': '285c7584-ffc6-4fda-8de4-3a2a96530f6c',\n",
      " 'logs': {'Docs': {'end_time': '2024-09-24T20:44:13.202+00:00',\n",
      "                   'final_output': {'documents': [Document(page_content=\"Anirban is Ritish's Father\"),\n",
      "                                                  Document(page_content=\"Rekha is the name of Ritish's Mother\"),\n",
      "                                                  Document(page_content=\"Rohit is Ritish's Younger Brother\"),\n",
      "                                                  Document(page_content='Ritish has a 2.5 month old son !')]},\n",
      "                   'id': 'd6cba482-cd44-4f72-bab0-7fe738b5d482',\n",
      "                   'metadata': {'ls_embedding_provider': 'HuggingFaceEmbeddings',\n",
      "                                'ls_retriever_name': 'vectorstore',\n",
      "                                'ls_vector_store_provider': 'FAISS'},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2024-09-24T20:44:13.157+00:00',\n",
      "                   'streamed_output': [],\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['seq:step:2', 'FAISS', 'HuggingFaceEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'name': 'RunnableSequence',\n",
      " 'streamed_output': [\"Here's the\",\n",
      "                     ' breakdown based on the provided context:\\n'\n",
      "                     '\\n'\n",
      "                     \"* **Anirban's Wife:**\",\n",
      "                     ' The context states that \"Rekha is the name of Ritish\\'s '\n",
      "                     'Mother'],\n",
      " 'type': 'chain'})\n",
      "----------------------------------------\n",
      "RunLog({'final_output': \"Here's the breakdown based on the provided context:\\n\"\n",
      "                 '\\n'\n",
      "                 '* **Anirban\\'s Wife:** The context states that \"Rekha is the '\n",
      "                 'name of Ritish\\'s Mother\". Since Anirban is Ritish\\'s '\n",
      "                 \"father, **Rekha is Anirban's wife**.\\n\"\n",
      "                 \"* **Eklavya's Uncle:**\",\n",
      " 'id': '285c7584-ffc6-4fda-8de4-3a2a96530f6c',\n",
      " 'logs': {'Docs': {'end_time': '2024-09-24T20:44:13.202+00:00',\n",
      "                   'final_output': {'documents': [Document(page_content=\"Anirban is Ritish's Father\"),\n",
      "                                                  Document(page_content=\"Rekha is the name of Ritish's Mother\"),\n",
      "                                                  Document(page_content=\"Rohit is Ritish's Younger Brother\"),\n",
      "                                                  Document(page_content='Ritish has a 2.5 month old son !')]},\n",
      "                   'id': 'd6cba482-cd44-4f72-bab0-7fe738b5d482',\n",
      "                   'metadata': {'ls_embedding_provider': 'HuggingFaceEmbeddings',\n",
      "                                'ls_retriever_name': 'vectorstore',\n",
      "                                'ls_vector_store_provider': 'FAISS'},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2024-09-24T20:44:13.157+00:00',\n",
      "                   'streamed_output': [],\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['seq:step:2', 'FAISS', 'HuggingFaceEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'name': 'RunnableSequence',\n",
      " 'streamed_output': [\"Here's the\",\n",
      "                     ' breakdown based on the provided context:\\n'\n",
      "                     '\\n'\n",
      "                     \"* **Anirban's Wife:**\",\n",
      "                     ' The context states that \"Rekha is the name of Ritish\\'s '\n",
      "                     'Mother',\n",
      "                     '\". Since Anirban is Ritish\\'s father, **Rekha is '\n",
      "                     \"Anirban's wife**.\\n\"\n",
      "                     \"* **Eklavya's Uncle:**\"],\n",
      " 'type': 'chain'})\n",
      "----------------------------------------\n",
      "RunLog({'final_output': \"Here's the breakdown based on the provided context:\\n\"\n",
      "                 '\\n'\n",
      "                 '* **Anirban\\'s Wife:** The context states that \"Rekha is the '\n",
      "                 'name of Ritish\\'s Mother\". Since Anirban is Ritish\\'s '\n",
      "                 \"father, **Rekha is Anirban's wife**.\\n\"\n",
      "                 '* **Eklavya\\'s Uncle:**  The context tells us \"Ritish has a '\n",
      "                 '2.5 month old son!\".  We can infer that Ritish\\'s son is '\n",
      "                 'Eklav',\n",
      " 'id': '285c7584-ffc6-4fda-8de4-3a2a96530f6c',\n",
      " 'logs': {'Docs': {'end_time': '2024-09-24T20:44:13.202+00:00',\n",
      "                   'final_output': {'documents': [Document(page_content=\"Anirban is Ritish's Father\"),\n",
      "                                                  Document(page_content=\"Rekha is the name of Ritish's Mother\"),\n",
      "                                                  Document(page_content=\"Rohit is Ritish's Younger Brother\"),\n",
      "                                                  Document(page_content='Ritish has a 2.5 month old son !')]},\n",
      "                   'id': 'd6cba482-cd44-4f72-bab0-7fe738b5d482',\n",
      "                   'metadata': {'ls_embedding_provider': 'HuggingFaceEmbeddings',\n",
      "                                'ls_retriever_name': 'vectorstore',\n",
      "                                'ls_vector_store_provider': 'FAISS'},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2024-09-24T20:44:13.157+00:00',\n",
      "                   'streamed_output': [],\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['seq:step:2', 'FAISS', 'HuggingFaceEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'name': 'RunnableSequence',\n",
      " 'streamed_output': [\"Here's the\",\n",
      "                     ' breakdown based on the provided context:\\n'\n",
      "                     '\\n'\n",
      "                     \"* **Anirban's Wife:**\",\n",
      "                     ' The context states that \"Rekha is the name of Ritish\\'s '\n",
      "                     'Mother',\n",
      "                     '\". Since Anirban is Ritish\\'s father, **Rekha is '\n",
      "                     \"Anirban's wife**.\\n\"\n",
      "                     \"* **Eklavya's Uncle:**\",\n",
      "                     '  The context tells us \"Ritish has a 2.5 month old '\n",
      "                     'son!\".  We can infer that Ritish\\'s son is Eklav'],\n",
      " 'type': 'chain'})\n",
      "----------------------------------------\n",
      "RunLog({'final_output': \"Here's the breakdown based on the provided context:\\n\"\n",
      "                 '\\n'\n",
      "                 '* **Anirban\\'s Wife:** The context states that \"Rekha is the '\n",
      "                 'name of Ritish\\'s Mother\". Since Anirban is Ritish\\'s '\n",
      "                 \"father, **Rekha is Anirban's wife**.\\n\"\n",
      "                 '* **Eklavya\\'s Uncle:**  The context tells us \"Ritish has a '\n",
      "                 '2.5 month old son!\".  We can infer that Ritish\\'s son is '\n",
      "                 \"Eklavya.  Since Rohit is Ritish's younger brother, **Rohit \"\n",
      "                 \"is Eklavya's uncle**. \\n\",\n",
      " 'id': '285c7584-ffc6-4fda-8de4-3a2a96530f6c',\n",
      " 'logs': {'Docs': {'end_time': '2024-09-24T20:44:13.202+00:00',\n",
      "                   'final_output': {'documents': [Document(page_content=\"Anirban is Ritish's Father\"),\n",
      "                                                  Document(page_content=\"Rekha is the name of Ritish's Mother\"),\n",
      "                                                  Document(page_content=\"Rohit is Ritish's Younger Brother\"),\n",
      "                                                  Document(page_content='Ritish has a 2.5 month old son !')]},\n",
      "                   'id': 'd6cba482-cd44-4f72-bab0-7fe738b5d482',\n",
      "                   'metadata': {'ls_embedding_provider': 'HuggingFaceEmbeddings',\n",
      "                                'ls_retriever_name': 'vectorstore',\n",
      "                                'ls_vector_store_provider': 'FAISS'},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2024-09-24T20:44:13.157+00:00',\n",
      "                   'streamed_output': [],\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['seq:step:2', 'FAISS', 'HuggingFaceEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'name': 'RunnableSequence',\n",
      " 'streamed_output': [\"Here's the\",\n",
      "                     ' breakdown based on the provided context:\\n'\n",
      "                     '\\n'\n",
      "                     \"* **Anirban's Wife:**\",\n",
      "                     ' The context states that \"Rekha is the name of Ritish\\'s '\n",
      "                     'Mother',\n",
      "                     '\". Since Anirban is Ritish\\'s father, **Rekha is '\n",
      "                     \"Anirban's wife**.\\n\"\n",
      "                     \"* **Eklavya's Uncle:**\",\n",
      "                     '  The context tells us \"Ritish has a 2.5 month old '\n",
      "                     'son!\".  We can infer that Ritish\\'s son is Eklav',\n",
      "                     \"ya.  Since Rohit is Ritish's younger brother, **Rohit is \"\n",
      "                     \"Eklavya's uncle**. \\n\"],\n",
      " 'type': 'chain'})\n"
     ]
    }
   ],
   "source": [
    "## Stream Incremental RunState with diff=False\n",
    "async for chunk in retrievalChain.astream_log(input=question,include_names=[\"Docs\"],diff=False):\n",
    "    print(\"-\"*40)\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5752bdb-e961-4df7-a5df-35c2c5938abc",
   "metadata": {},
   "source": [
    "<h3>Runnable Parallel</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "867e2bdd-c3bb-452d-95da-476687bca7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1=ChatPromptTemplate.from_template(template=\"Tell Me a Joke about {topic}\")|llm\n",
    "chain2=ChatPromptTemplate.from_template(template=\"Write a Poem on the Following {subject}\")|llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0cb768f-ddb2-40a5-9e1d-1abd50662f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedChain=RunnableParallel(joke=chain1,poem=chain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af5385f8-0c18-4789-aae4-62f3fdea5cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the iceberg go to therapy?\n",
      "\n",
      "Because it had some serious emotional issues to work through after sinking the Titanic.\n",
      "Took 0.9242572784423828 Seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "print(chain1.invoke(input={\"topic\":\"Titanic\"}).content)\n",
    "print(f\"Took {time.time()-start} Seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d015166-429d-41e0-97a9-3cbc1ceda53a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic, oh mighty ship of steel,\n",
      "A wonder of the age, so grand and real.\n",
      "Set sail on a fateful night,\n",
      "Destined for glory, bathed in light.\n",
      "\n",
      "But fate had other plans in store,\n",
      "As the iceberg loomed, a deadly roar.\n",
      "The collision was swift, the damage done,\n",
      "And the unsinkable ship, began to run.\n",
      "\n",
      "Panic erupted, chaos reigned,\n",
      "As the passengers faced a fate unexplained.\n",
      "The lifeboats filled, the cries were heard,\n",
      "As the Titanic slowly, tragically, was interred.\n",
      "\n",
      "The music played, the lights went dim,\n",
      "As the ocean claimed its solemn hymn.\n",
      "The stars bore witness to the tragic end,\n",
      "Of a ship so grand, that fate did bend.\n",
      "\n",
      "Yet in the midst of tragedy and loss,\n",
      "Stories of heroism, of love, across\n",
      "The waves of time, they still endure,\n",
      "A testament to the human spirit, pure.\n",
      "\n",
      "Titanic, a name that will forever be,\n",
      "A reminder of the fragility of the sea.\n",
      "A lesson learned, not to be lost,\n",
      "In the depths of the ocean, at any cost.\n",
      "Took 1.8193910121917725 Seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "print(chain2.invoke(input={\"subject\":\"Titanic\"}).content)\n",
    "print(f\"Took {time.time()-start} Seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b511e1da-4e1d-48c1-9c22-affe89d1732f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': AIMessage(content='Why did the iceberg get a bad reputation?\\n\\nBecause it sank a lot of relationships.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-001', 'safety_ratings': []}, id='run-8c045317-3103-4ee4-8f4d-48fe5368d52a-0', usage_metadata={'input_tokens': 6, 'output_tokens': 19, 'total_tokens': 25, 'input_token_details': {'cache_read': 0}}), 'poem': AIMessage(content=\"The Dream of Iron, forged in fire's heart,\\nA floating palace, set to play its part.\\nTitanic, queen of ocean, bold and grand,\\nA marvel built by human skill and hand.\\n\\nShe slipped her moorings, Belfast left behind,\\nA promise whispered on the salty wind.\\nOf gilded halls and dinners, rich and deep,\\nWhere fortunes mingled, secrets they would keep.\\n\\nThe steerage huddled, hopes within their breast,\\nA new life beckoned, westward to the West.\\nThey dreamt of freedom, land and open sky,\\nUnburdened futures, as the days flew by.\\n\\nBut fate, it lurked, a shadow in the blue,\\nA frozen menace, waiting to break through.\\nAn iceberg drifted, silent, cold, and grim,\\nA deadly challenge to the ocean's whim.\\n\\nThe warning came, too late, a whispered dread,\\nA scraping shudder, as the metal bled.\\nThe mighty vessel, wounded to the core,\\nBegan to tremble, sinking evermore.\\n\\nThe band played bravely, as the water rose,\\nA final anthem, silencing all woes.\\nThe cries of terror, swallowed by the night,\\nAs icy waves extinguished every light.\\n\\nFrom lifeboats lowered, desperate pleas were heard,\\nA tapestry of sorrow, every whispered word.\\nThe strong fought fiercely, for a chance to live,\\nWhile weaker souls had nothing left to give.\\n\\nThe ocean claimed her, swallowed her whole down,\\nA graveyard silent, where the dreams all drown.\\nTitanic sleeps, beneath the waves so deep,\\nA tragic legend, secrets she will keep.\\n\\nA monument to hubris, pride, and loss,\\nA reminder whispered, counting up the cost.\\nOf nature's power, and the fragile thread,\\nThat binds us mortals, living and the dead.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-001', 'safety_ratings': []}, id='run-74b1996c-f35b-4684-b75e-21429fb1edb4-0', usage_metadata={'input_tokens': 7, 'output_tokens': 389, 'total_tokens': 396, 'input_token_details': {'cache_read': 0}})}\n",
      "Took 3.8050782680511475 Seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "print(combinedChain.invoke(input={\"subject\":\"Titanic\",\"topic\":\"Titanic\"}))\n",
    "print(f\"Took {time.time()-start} Seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05fc7a7f-8387-4451-a8b9-60f1e361d018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 2.749480724334717 Seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "RunnableParallel({'joke':chain1,'poem':chain2}).invoke(input={\"subject\":\"Titanic\",\"topic\":\"Titanic\"})\n",
    "print(f\"Took {time.time()-start} Seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "affb68fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  joke: ChatPromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Tell Me a Joke about {topic}'), additional_kwargs={})])\n",
       "        | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000029F6B5C8410>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000029F4FC91050>, root_client=<openai.OpenAI object at 0x0000029F6B1FF3D0>, root_async_client=<openai.AsyncOpenAI object at 0x0000029F6B5C8750>, model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
       "  poem: ChatPromptTemplate(input_variables=['subject'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['subject'], input_types={}, partial_variables={}, template='Write a Poem on the Following {subject}'), additional_kwargs={})])\n",
       "        | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000029F6B5C8410>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000029F4FC91050>, root_client=<openai.OpenAI object at 0x0000029F6B1FF3D0>, root_async_client=<openai.AsyncOpenAI object at 0x0000029F6B5C8750>, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badbb3e6-8e8c-490c-9f65-97bcfadd11f6",
   "metadata": {},
   "source": [
    "<h3> Parallelism on Batches</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2bd16df6-e9f5-48e3-867b-6b3ecdcd9c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content=\"Why did the iceberg break up with the Titanic? \\n\\nIt just couldn't handle the pressure.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 14, 'total_tokens': 33, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CxeWyQeCD0mue3w2hQS4uReGKEBEK', 'finish_reason': 'stop', 'logprobs': None}, id='run--d0cb9e73-1598-4c13-b4f1-0dbe60e05efa-0', usage_metadata={'input_tokens': 14, 'output_tokens': 19, 'total_tokens': 33, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Why did the chicken go to Kolkata?\\n\\nTo get to the other side of the Howrah Bridge!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 14, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CxeWzBmRkPRLYOCBkocM4UDEFXPWf', 'finish_reason': 'stop', 'logprobs': None}, id='run--34bb3c7e-a147-4bf9-b1e7-0c6c72c9c70d-0', usage_metadata={'input_tokens': 14, 'output_tokens': 20, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "Took 1.669067144393921 Seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "print(chain1.batch(inputs=[{\"topic\":\"Titanic\"},{\"topic\":\"Kolkata\"}]))\n",
    "print(f\"Took {time.time()-start} Seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4eb4ee09-52e2-4ffb-a76f-e41b8a5a40a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content=\"In the dead of night, a towering ship set sail\\nThe Titanic, grand and magnificent, its beauty did prevail\\nA marvel of engineering, a testament to man's might\\nBut little did they know, it would face a fateful fight\\n\\nAcross the cold Atlantic, she glided with grace\\nA symbol of luxury, a vision of elegance and pace\\nBut lurking beneath the surface, danger lay in wait\\nAn iceberg stood silent, sealing the ship's dark fate\\n\\nIn an instant, the world was turned upside down\\nAs the Titanic collided with a force unseen and profound\\nPanic and chaos ensued, as the ship began to sink\\nThe screams of the terrified, the water turning pink\\n\\nBrave souls rose up, to help those in need\\nBut the icy waters took their toll, a price no one could heed\\nThe Titanic, once mighty, now lay broken and still\\nA tragic reminder, of the power of nature's will\\n\\nWe remember the lives lost, the courage and the pain\\nThe Titanic, a legend, will forever remain\\nA lesson to us all, of hubris and of pride\\nAnd how even the mightiest can be taken by the tide.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 241, 'prompt_tokens': 15, 'total_tokens': 256, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CxeX404QLMhAJaLJEpIzYPK3nBeLv', 'finish_reason': 'stop', 'logprobs': None}, id='run--b9f913a7-7121-4a3d-8cf8-2bfe2c971d41-0', usage_metadata={'input_tokens': 15, 'output_tokens': 241, 'total_tokens': 256, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content=\"In the bustling city of Kolkata, \\nWhere culture and history intertwine,\\nThe streets are alive with the sound,\\nOf vendors selling their wares and haggling abound.\\n\\nFrom the iconic Howrah Bridge,\\nTo the majestic Victoria Memorial,\\nEvery corner tells a story,\\nOf a city filled with glory.\\n\\nThe trams chug along the streets,\\nWhile ancient buildings stand tall,\\nA reminder of the city's past,\\nAnd how it's weathered it all.\\n\\nThe people are warm and friendly,\\nTheir hearts as big as the city's soul,\\nIn Kolkata, there's a sense of unity,\\nA bond that makes the city whole.\\n\\nSo here's to Kolkata, a city so grand,\\nWhere tradition meets modernity hand in hand,\\nIt's a place like no other, with a unique charm,\\nA city that's bound to leave you with a sense of calm.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 175, 'prompt_tokens': 15, 'total_tokens': 190, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CxeX5sNIhhb7Ir4JAwmpsCu4hlHsG', 'finish_reason': 'stop', 'logprobs': None}, id='run--be1250c7-5ce1-44c8-961a-398a232d3c94-0', usage_metadata={'input_tokens': 15, 'output_tokens': 175, 'total_tokens': 190, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "Took 2.3610002994537354 Seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "print(chain2.batch(inputs=[{\"subject\":\"Titanic\"},{\"subject\":\"Kolkata\"}]))\n",
    "print(f\"Took {time.time()-start} Seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d696c5e3-81de-4a40-b145-d4d9210d6800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'joke': AIMessage(content=\"Why did the iceberg refuse to apologize to the Titanic?\\n\\nBecause it didn't want to break the ice!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 14, 'total_tokens': 35, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CxeXUqqFACkBnpvKMphFZoBSE3IuY', 'finish_reason': 'stop', 'logprobs': None}, id='run--903fef6a-a6b2-4bb6-a426-03af330d992e-0', usage_metadata={'input_tokens': 14, 'output_tokens': 21, 'total_tokens': 35, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), 'poem': AIMessage(content=\"Titanic, a ship of grandeur and grace\\nSailing through the vast ocean space\\nIts towering structure, a sight to behold\\nA marvel of engineering, a tale to be told\\n\\nOn that fateful night, tragedy struck\\nIcebergs looming, the ship ran amok\\nSinking into the cold, unforgiving sea\\nA haunting reminder of our mortality\\n\\nBrave souls fought to survive\\nIn the icy waters, struggling to stay alive\\nTheir courage and strength, a beacon of hope\\nIn the midst of despair, they somehow cope\\n\\nThe Titanic, now a legend of the sea\\nA symbol of hubris, of humanity's fee\\nWe remember those lost, their stories untold\\nIn the depths of the ocean, their memories hold\\n\\nSo let us never forget the lessons learned\\nFrom the tragedy of the Titanic, we discern\\nThat even the mightiest can fall from grace\\nA humbling reminder in this fast-paced race\\n\\nTitanic, a ship of grandeur and grace\\nForever etched in history, in time and space\\nMay we honor the lives lost that night\\nAnd strive to make the world a little more bright.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 237, 'prompt_tokens': 15, 'total_tokens': 252, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CxeXU1vxzkWYzvk8fzu1zKfXU5pr0', 'finish_reason': 'stop', 'logprobs': None}, id='run--dfb2c795-a2b4-4719-a33a-84148b3adc71-0', usage_metadata={'input_tokens': 15, 'output_tokens': 237, 'total_tokens': 252, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}, {'joke': AIMessage(content='Why did the ghost refuse to haunt Kolkata? Because it heard there were too many \"boos\" there already!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 14, 'total_tokens': 37, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CxeXUiNWUAuuhSkc3F6kgs8n47CVq', 'finish_reason': 'stop', 'logprobs': None}, id='run--b30b40be-5000-4c11-be66-eedd599972b2-0', usage_metadata={'input_tokens': 14, 'output_tokens': 23, 'total_tokens': 37, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), 'poem': AIMessage(content=\"Kolkata, city of joy\\nWhere tradition meets modernity\\nStreets buzzing with life\\nAnd history in every corner you see\\n\\nThe Howrah Bridge stands tall\\nA symbol of the city's glory\\nThe Ganges flows by\\nA river of stories untold and ancient\\n\\nFrom the vibrant markets of New Market\\nTo the tranquil gardens of Victoria Memorial\\nKolkata enchants with its beauty\\nAnd leaves a lasting impression on all\\n\\nThe trams rattle along the streets\\nA relic of the past still cherished\\nThe yellow taxis honk their way\\nThrough the chaotic but charming city\\n\\nBengali sweets and chai\\nDelight the taste buds of all\\nAnd the music of Rabindra Sangeet\\nFills the air with soul-stirring melodies\\n\\nKolkata, city of poets and artists\\nWhere creativity thrives and dreams take flight\\nA place where history and modernity\\nCoexist in perfect harmony, shining bright\\n\\nSo here's to Kolkata, city of joy\\nA place that captures hearts and souls\\nWhere every corner tells a story\\nAnd every moment is pure gold.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 226, 'prompt_tokens': 15, 'total_tokens': 241, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CxeXUCdewK9xiOJOmYQ48YmcBTMX4', 'finish_reason': 'stop', 'logprobs': None}, id='run--467517d4-a53e-4305-8c53-918a425de33e-0', usage_metadata={'input_tokens': 15, 'output_tokens': 226, 'total_tokens': 241, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}]\n",
      "Took 2.8879458904266357 Seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "print(combinedChain.batch(inputs=[\n",
    "                                    {\"subject\":\"Titanic\",\"topic\":\"Titanic\"},  # Joke on Titanic and Poem on Titanic\n",
    "                                    {\"subject\":\"Kolkata\",\"topic\":\"Kolkata\"}  # Joke on Kolkata and Poem on Kolkata\n",
    "                          ]))\n",
    "print(f\"Took {time.time()-start} Seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0d4e7bd9-473b-4fd9-8b83-30bbd6a9be90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               +--------------------------+                \n",
      "               | Parallel<joke,poem>Input |                \n",
      "               +--------------------------+                \n",
      "                   ***               ***                   \n",
      "                ***                     ***                \n",
      "              **                           **              \n",
      "+--------------------+              +--------------------+ \n",
      "| ChatPromptTemplate |              | ChatPromptTemplate | \n",
      "+--------------------+              +--------------------+ \n",
      "           *                                   *           \n",
      "           *                                   *           \n",
      "           *                                   *           \n",
      "    +------------+                      +------------+     \n",
      "    | ChatOpenAI |                      | ChatOpenAI |     \n",
      "    +------------+*                     +------------+     \n",
      "                   ***               ***                   \n",
      "                      ***         ***                      \n",
      "                         **     **                         \n",
      "              +---------------------------+                \n",
      "              | Parallel<joke,poem>Output |                \n",
      "              +---------------------------+                \n"
     ]
    }
   ],
   "source": [
    "combinedChain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "77b6f2bd-18f2-4343-90e7-d126dcff4893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatPromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Tell Me a Joke about {topic}'), additional_kwargs={})]),\n",
       " ChatPromptTemplate(input_variables=['subject'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['subject'], input_types={}, partial_variables={}, template='Write a Poem on the Following {subject}'), additional_kwargs={})])]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedChain.get_prompts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcnenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
