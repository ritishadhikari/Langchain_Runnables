{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "161f832b-77da-4da3-bd14-30e59c4aca05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI 1\\.conda\\envs\\oaivenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough,RunnableLambda, Runnable, RunnableParallel,RunnableConfig,RunnableGenerator\n",
    "from langchain_core.messages import AIMessage\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from langchain.prompts import ChatPromptTemplate,SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser,StrOutputParser\n",
    "from operator import itemgetter\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "import json\n",
    "from langchain_community.vectorstores import FAISS,Chroma\n",
    "from operator import itemgetter\n",
    "import time\n",
    "import grandalf\n",
    "from typing import Iterator,List,AsyncIterator\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain.runnables.hub import HubRunnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5efd4d4d-e14a-447f-a954-f18ce211e7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv(\"D:\\LLM Courses\\Master Langchain Udemy\\.env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "888397b1-1b84-4d55-b12f-ed2ce3d99801",
   "metadata": {},
   "outputs": [],
   "source": [
    "llmGemini=ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "llmGPT=ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e48c1ef-22fe-45c1-b09f-9cc9dfc0ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1=ChatPromptTemplate.from_template(\n",
    "    template=\"What is the city {person} is from?\"\n",
    ")\n",
    "\n",
    "prompt2=ChatPromptTemplate.from_template(\n",
    "    template=\"What Country is the city {city} in? Respond in {language}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "483e7227-4696-4e1b-a79a-23f8efb73e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1=prompt1|llmGemini|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c26b93e8-9716-43c7-b991-467b1a914d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain2={\"city\":chain1,\"language\":itemgetter(\"language\")}|prompt2|llmGemini|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f9cf734-3474-45de-b367-43e1739752c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ওসামা বিন লাদেনের জন্মস্থান রিয়াদ, **সৌদি আরব**। \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chain2.invoke(input={\"person\":\"Osama Bin Laden\",\"language\":\"Bengali\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92544d7f-1ad6-41f7-8395-47e974d06c66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               +------------------------------+        \n",
      "               | Parallel<city,language>Input |        \n",
      "               +------------------------------+        \n",
      "                     ***               ***             \n",
      "                  ***                     **           \n",
      "                **                          ***        \n",
      "  +--------------------+                       **      \n",
      "  | ChatPromptTemplate |                        *      \n",
      "  +--------------------+                        *      \n",
      "             *                                  *      \n",
      "             *                                  *      \n",
      "             *                                  *      \n",
      "+------------------------+                      *      \n",
      "| ChatGoogleGenerativeAI |                      *      \n",
      "+------------------------+                      *      \n",
      "             *                                  *      \n",
      "             *                                  *      \n",
      "             *                                  *      \n",
      "    +-----------------+                     +--------+ \n",
      "    | StrOutputParser |                     | Lambda | \n",
      "    +-----------------+                   **+--------+ \n",
      "                     ***               ***             \n",
      "                        ***         ***                \n",
      "                           **     **                   \n",
      "              +-------------------------------+        \n",
      "              | Parallel<city,language>Output |        \n",
      "              +-------------------------------+        \n",
      "                               *                       \n",
      "                               *                       \n",
      "                               *                       \n",
      "                    +--------------------+             \n",
      "                    | ChatPromptTemplate |             \n",
      "                    +--------------------+             \n",
      "                               *                       \n",
      "                               *                       \n",
      "                               *                       \n",
      "                  +------------------------+           \n",
      "                  | ChatGoogleGenerativeAI |           \n",
      "                  +------------------------+           \n",
      "                               *                       \n",
      "                               *                       \n",
      "                               *                       \n",
      "                     +-----------------+               \n",
      "                     | StrOutputParser |               \n",
      "                     +-----------------+               \n",
      "                               *                       \n",
      "                               *                       \n",
      "                               *                       \n",
      "                  +-----------------------+            \n",
      "                  | StrOutputParserOutput |            \n",
      "                  +-----------------------+            \n"
     ]
    }
   ],
   "source": [
    "chain2.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fa42e8-af84-4de7-9689-d40302216444",
   "metadata": {},
   "source": [
    "<h3>A More Complex Multiple Chain</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c947360c-3f2b-4ffe-a2f7-a2fa79717dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough,RunnableLambda, Runnable, RunnableParallel\n",
    "\n",
    "llmGemini=ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "prompt1=ChatPromptTemplate.from_template(\n",
    "    template=\"generate a {attribute} color. Return the name of the color and nothing else:\"\n",
    ")\n",
    "\n",
    "prompt2=ChatPromptTemplate.from_template(\n",
    "    template=\"what is a fruit of color: {color}. Return the name of the fruit and nothing else:\"\n",
    ")\n",
    "\n",
    "prompt3=ChatPromptTemplate.from_template(\n",
    "    template=\"what is a country with a flag that has the color: {color}. Return the name of the country and nothing else:\"\n",
    ")\n",
    "\n",
    "prompt4=ChatPromptTemplate.from_template(\n",
    "    template=\"What is the color of {fruit} and the flag of {country}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13351be6-46ab-4275-8241-bee603db64b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "colorChain={\"attribute\":RunnablePassthrough()} | prompt1 | llmGemini | StrOutputParser()\n",
    "\n",
    "fruitChain={\"color\":colorChain}|prompt2|llmGemini|StrOutputParser()\n",
    "\n",
    "countryChain={\"color\":colorChain}|prompt3|llmGemini|StrOutputParser()\n",
    "\n",
    "fruitAndCountryChain=RunnableParallel({\"fruit\":fruitChain,\"country\":countryChain})|prompt4|llmGemini|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1822e9dd-43a0-48b4-aa56-1f0fe773d0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* **Banana:** Yellow\n",
      "* **Flag of Ukraine:** Blue and yellow \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fruitAndCountryChain.invoke(input={\"attribute\":\"Yellow\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "238465ac-4263-4a2c-a8b9-ccf8dd8474aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  +------------------------------+                   \n",
      "                  | Parallel<fruit,country>Input |                   \n",
      "                  +------------------------------+                   \n",
      "                      ***                  ***                       \n",
      "                  ****                        ****                   \n",
      "                **                                **                 \n",
      "      +-------------+                         +-------------+        \n",
      "      | Passthrough |                         | Passthrough |        \n",
      "      +-------------+                         +-------------+        \n",
      "             *                                        *              \n",
      "             *                                        *              \n",
      "             *                                        *              \n",
      "  +--------------------+                   +--------------------+    \n",
      "  | ChatPromptTemplate |                   | ChatPromptTemplate |    \n",
      "  +--------------------+                   +--------------------+    \n",
      "             *                                        *              \n",
      "             *                                        *              \n",
      "             *                                        *              \n",
      "+------------------------+               +------------------------+  \n",
      "| ChatGoogleGenerativeAI |               | ChatGoogleGenerativeAI |  \n",
      "+------------------------+               +------------------------+  \n",
      "             *                                        *              \n",
      "             *                                        *              \n",
      "             *                                        *              \n",
      "    +-----------------+                     +-----------------+      \n",
      "    | StrOutputParser |                     | StrOutputParser |      \n",
      "    +-----------------+                     +-----------------+      \n",
      "             *                                        *              \n",
      "             *                                        *              \n",
      "             *                                        *              \n",
      "  +--------------------+                   +--------------------+    \n",
      "  | ChatPromptTemplate |                   | ChatPromptTemplate |    \n",
      "  +--------------------+                   +--------------------+    \n",
      "             *                                        *              \n",
      "             *                                        *              \n",
      "             *                                        *              \n",
      "+------------------------+               +------------------------+  \n",
      "| ChatGoogleGenerativeAI |               | ChatGoogleGenerativeAI |  \n",
      "+------------------------+               +------------------------+  \n",
      "             *                                        *              \n",
      "             *                                        *              \n",
      "             *                                        *              \n",
      "    +-----------------+                     +-----------------+      \n",
      "    | StrOutputParser |                     | StrOutputParser |      \n",
      "    +-----------------+                     +-----------------+      \n",
      "                      ***                  ***                       \n",
      "                         ****          ****                          \n",
      "                             **      **                              \n",
      "                 +-------------------------------+                   \n",
      "                 | Parallel<fruit,country>Output |                   \n",
      "                 +-------------------------------+                   \n",
      "                                  *                                  \n",
      "                                  *                                  \n",
      "                                  *                                  \n",
      "                      +--------------------+                         \n",
      "                      | ChatPromptTemplate |                         \n",
      "                      +--------------------+                         \n",
      "                                  *                                  \n",
      "                                  *                                  \n",
      "                                  *                                  \n",
      "                    +------------------------+                       \n",
      "                    | ChatGoogleGenerativeAI |                       \n",
      "                    +------------------------+                       \n",
      "                                  *                                  \n",
      "                                  *                                  \n",
      "                                  *                                  \n",
      "                        +-----------------+                          \n",
      "                        | StrOutputParser |                          \n",
      "                        +-----------------+                          \n",
      "                                  *                                  \n",
      "                                  *                                  \n",
      "                                  *                                  \n",
      "                     +-----------------------+                       \n",
      "                     | StrOutputParserOutput |                       \n",
      "                     +-----------------------+                       \n"
     ]
    }
   ],
   "source": [
    "fruitAndCountryChain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b85e451-00fe-4da5-a43e-ce9a09ddd2b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
