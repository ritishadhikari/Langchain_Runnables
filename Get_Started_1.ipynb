{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50bf60b4-8a49-4bce-bdfc-a150f968036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.runnables import RunnablePassthrough,RunnableLambda, Runnable, RunnableParallel,RunnableConfig\n",
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate,SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from operator import itemgetter\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "import json\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import FAISS,Chroma\n",
    "from operator import itemgetter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c40a5a38-2bd3-4bfd-9fd8-1b4249b7ca1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv(\"../.env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ca20779-e3f3-4eda-83d5-daa70eb57157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm=ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-001\")\n",
    "llm=ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d9cd6e-e56e-443d-af28-c31e9bbff293",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_template(\n",
    "    template=\"Tell me a Short joke about {topic}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aadb410d-d800-47ae-a9a0-04be05826c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "outParser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0a41807-0f89-441d-8764-8e83dd7572ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|llm|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5972825-bcb3-4163-b237-c5ecc018dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "question={\"topic\":\"Virat Kohli\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26ee9f2d-c4e2-49de-afb3-9f116b4b8470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did Virat Kohli bring a ladder to the cricket match? \\n\\nBecause he heard the bowlers were pitching tents on the field!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input=question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd07b29-d222-4f86-b98c-d8b65d5cd4e2",
   "metadata": {},
   "source": [
    "<h3>Prompt</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fdf0379-1716-4bb2-ba2c-47fb1517f2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Tell me a Short joke about Virat Kohli', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promptValue=prompt.invoke(input=question)\n",
    "promptValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bda708cf-db98-4324-9c28-dabe634f4e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Tell me a Short joke about Virat Kohli', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promptValue.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fde623c6-6341-41d8-a2dd-61a6e3bdd267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Tell me a Short joke about Virat Kohli'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promptValue.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c996274-3ea5-4f67-9bcb-42e07dd81918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc': 1,\n",
       " 'type': 'constructor',\n",
       " 'id': ['langchain', 'prompts', 'chat', 'ChatPromptValue'],\n",
       " 'kwargs': {'messages': [HumanMessage(content='Tell me a Short joke about Virat Kohli', additional_kwargs={}, response_metadata={})]}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promptValue.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62880783-eec4-4db9-b842-a1b9a0f51408",
   "metadata": {},
   "source": [
    "<h3>Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acc404db-05b5-4207-86f4-3c0931b13d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did Virat Kohli bring a ladder to the cricket match?\\nBecause he heard the stumps were high and he wanted to be on top of his game!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 17, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CxSzzgRpNkZK3klCMSozTdJxCDPnj', 'finish_reason': 'stop', 'logprobs': None}, id='run--5dfc3c99-1e93-4da7-a91a-65456f57674b-0', usage_metadata={'input_tokens': 17, 'output_tokens': 33, 'total_tokens': 50, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message=llm.invoke(input=promptValue)\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd271da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did Virat Kohli bring a ladder to the cricket match?\\n\\nBecause he heard the match was going to be high-scoring!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 17, 'total_tokens': 44, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CxT0hFrpurItP7lempU0oLvw9rUo1', 'finish_reason': 'stop', 'logprobs': None}, id='run--543eec4f-2220-4a08-900b-f35b5029a3bb-0', usage_metadata={'input_tokens': 17, 'output_tokens': 27, 'total_tokens': 44, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message=llm.invoke(input=promptValue.to_messages())\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20ae09b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did Virat Kohli bring a ladder to the cricket match? \\n\\nBecause he heard the bowlers were going to pitch it up!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 19, 'total_tokens': 47, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CxT0rZXzYLY4AL1F1ABzZeTjsfR3i', 'finish_reason': 'stop', 'logprobs': None}, id='run--0b820fc6-80ec-4f6e-9c6a-110c3c197220-0', usage_metadata={'input_tokens': 19, 'output_tokens': 28, 'total_tokens': 47, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message=llm.invoke(input=promptValue.to_string())\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b6750d-d00f-498b-b270-cb30061f7682",
   "metadata": {},
   "source": [
    "<h3> Output Parser </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac598289-3c07-449c-8d92-ba28d8edb0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did Virat Kohli bring a ladder to the cricket match? \\n\\nBecause he heard the bowlers were going to pitch it up!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outParser.invoke(input=message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42af91b7-0e1f-48e3-9bf0-1b3b1303e047",
   "metadata": {},
   "source": [
    "<h3>RAG Example</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f03f50bb-2563-45e1-a772-4c8d9b1d5894",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=OpenAIEmbeddings() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5332f1f8-3465-469e-864c-b7be19bf0cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorStore=Chroma.from_texts(\n",
    "    texts=[\"Harrison worked at kensho\",\"bears like to eat honey\"],\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c3122a9-572f-4950-823b-2f2948e19178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000020DD0C02B90>, search_kwargs={})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorStore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "995047a3-5f8f-465f-8b14-a704d43c1620",
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"\n",
    "    Answer the question based only on the following context:\n",
    "    {context}\n",
    "    Question: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bf0360b-0b17-45e4-a9ef-70aff084f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_template(\n",
    "    template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d93732e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='bears like to eat honey'),\n",
       " Document(metadata={}, page_content='Harrison worked at kensho')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorStore.as_retriever().invoke(input=\"Who likes honey?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65ca45e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'How are you doing?'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnablePassthrough().invoke({\"context\":\"How are you doing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f43aa126-f251-43d0-a8ab-75ad28f94566",
   "metadata": {},
   "outputs": [],
   "source": [
    "setupAndRetrieval=RunnableParallel(\n",
    "    {\n",
    "        \"context\":vectorStore.as_retriever(),\n",
    "        \"question\":RunnablePassthrough()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70be4d91-f707-40d5-bc58-6483368825cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=setupAndRetrieval|prompt|llm|outParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "425c385c-29c5-4131-bc6b-04d29de5f656",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"Who worked at Kensho?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8b94012-182d-4d85-a88c-33cd55976a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 3.032109022140503 seconds\n"
     ]
    }
   ],
   "source": [
    "k=time.time()\n",
    "chain.invoke(input=question)\n",
    "print(f\"Time Taken: {time.time()-k} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b95f1a",
   "metadata": {},
   "source": [
    "<h3>Without Using Runnable Parallel </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a01d966",
   "metadata": {},
   "outputs": [],
   "source": [
    "chainTest=RunnablePassthrough.assign(context=itemgetter(\"question\")|vectorStore.as_retriever())|prompt|llm|outParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f190573",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"Who likes to eat honey??\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80f4c68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 1.1296615600585938 seconds\n"
     ]
    }
   ],
   "source": [
    "k=time.time()\n",
    "chainTest.invoke(input={\"question\":question})\n",
    "print(f\"Time Taken: {time.time()-k} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1eb3cd-8c07-4e4e-890e-a9d237cb9071",
   "metadata": {},
   "source": [
    "<h3> Retriever Part </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7fa32a40-b9a0-4272-96cc-b7584f0bef13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='bears like to eat honey'),\n",
       " Document(metadata={}, page_content='Harrison worked at kensho')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorStore.as_retriever().invoke(input=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be9aa9f8-b2ad-4b62-b180-07276acdb953",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(metadata={}, page_content='bears like to eat honey'),\n",
       "  Document(metadata={}, page_content='Harrison worked at kensho')],\n",
       " 'question': 'Who likes to eat honey??'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrievedContent=setupAndRetrieval.invoke(input=question)\n",
    "retrievedContent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ef37a4-aa2c-40ec-b5d5-e6435ee1cb6c",
   "metadata": {},
   "source": [
    "<h3>Prompt Part</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "864c3580-f8dc-4c8e-8225-f53cb73887fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content=\"\\n    Answer the question based only on the following context:\\n    [Document(metadata={}, page_content='bears like to eat honey'), Document(metadata={}, page_content='Harrison worked at kensho')]\\n    Question: Who likes to eat honey??\\n\", additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promptValue=prompt.invoke(input=retrievedContent)\n",
    "promptValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b60b25d9-00ec-448e-9081-868841ee71c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"\\n    Answer the question based only on the following context:\\n    [Document(metadata={}, page_content='bears like to eat honey'), Document(metadata={}, page_content='Harrison worked at kensho')]\\n    Question: Who likes to eat honey??\\n\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promptValue.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a99b5e42-fbf5-4ef4-b013-e0c344ce6d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "    Answer the question based only on the following context:\n",
      "    [Document(metadata={}, page_content='bears like to eat honey'), Document(metadata={}, page_content='Harrison worked at kensho')]\n",
      "    Question: Who likes to eat honey??\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(promptValue.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55115c53-c9ca-4023-bcad-ce9a2300513e",
   "metadata": {},
   "source": [
    "<h3> LLM </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62475ca5-2c0d-4c97-84b3-546cbe17e0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Based on the given context, bears like to eat honey.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 58, 'total_tokens': 70, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CxTRRGPPJ9pumRI26u8OmxrFgvsLE', 'finish_reason': 'stop', 'logprobs': None}, id='run--aeb7b7ae-eccf-4d55-b576-b78d321a4d1d-0', usage_metadata={'input_tokens': 58, 'output_tokens': 12, 'total_tokens': 70, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message=llm.invoke(input=promptValue)\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8cf6d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Bears like to eat honey.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 60, 'total_tokens': 67, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CxTRpSAvndZ6jTzKv8II80e1JNkGX', 'finish_reason': 'stop', 'logprobs': None}, id='run--54183ecf-ea08-49b4-bee4-eb6551d7ecd2-0', usage_metadata={'input_tokens': 60, 'output_tokens': 7, 'total_tokens': 67, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(input=promptValue.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "224d2c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Based on the provided context, bears like to eat honey.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 58, 'total_tokens': 70, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CxTSTRL9L2dCnULiVR0TCjjxleP4C', 'finish_reason': 'stop', 'logprobs': None}, id='run--ae1bffa0-e93a-401e-bde0-16d58affc856-0', usage_metadata={'input_tokens': 58, 'output_tokens': 12, 'total_tokens': 70, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(input=promptValue.to_messages())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7422ef06-43f5-41e3-9b84-76b8a06772ad",
   "metadata": {},
   "source": [
    "<h3>Output Parser</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f3a10b81-9fea-4410-a33d-7bfa7d6250b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the given context, bears like to eat honey.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=outParser.invoke(input=message)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcnenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
