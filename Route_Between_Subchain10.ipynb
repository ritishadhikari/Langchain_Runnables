{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18589721-1eb3-46a8-b213-bbe19228adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough,RunnableLambda, Runnable, RunnableParallel,RunnableConfig,RunnableGenerator\n",
    "from langchain_core.messages import AIMessage\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from langchain.prompts import ChatPromptTemplate,SystemMessagePromptTemplate, HumanMessagePromptTemplate,PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser,StrOutputParser\n",
    "from operator import itemgetter\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "import json\n",
    "from langchain_community.vectorstores import FAISS,Chroma\n",
    "from operator import itemgetter\n",
    "import time\n",
    "import grandalf\n",
    "from typing import Iterator,List,AsyncIterator\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain.runnables.hub import HubRunnable\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.utils.math import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7194882-b1da-4dfe-8f41-289e5397a408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv(\"../.env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f16a68f3-ae53-4522-923b-4d560d803aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "llmGemini=ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-001\")\n",
    "llmGPT=ChatOpenAI(model=\"gpt-4O-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d28e1c8-47fc-422f-bb87-c0cd8440feac",
   "metadata": {},
   "source": [
    "<h3>Using Runnable Lambda</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3619582-e740-4886-b579-e7f3d94e1466",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate.from_template(template=\"\"\"\n",
    "    Given the user question below, classify it as either being about `Langchain`,`Anthropic`, or `Other`\n",
    "\n",
    "    Do not respond with more than one word.\n",
    "\n",
    "    <question>\n",
    "    {question}\n",
    "    </question>\n",
    "\n",
    "    Classification:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88e471f9-2938-4457-bc74-106289e6b457",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|llmGemini|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e564fce7-06e4-486b-a61d-f6c3c145b627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anthropic'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input={\"question\":\"What is Claude LLM?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c6ff89a-a21d-474c-968a-fc66877dcf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchainChain=PromptTemplate.from_template(\n",
    "    template=\"\"\"\n",
    "        You are an expert in langchain.\\\n",
    "        Always answer questions starting with \"As Prof. Langchain told me\". \\\n",
    "        Respond to the following question:\n",
    "\n",
    "        Question: {question}\n",
    "        Answer:\n",
    "    \"\"\"\n",
    ")| llmGemini|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c13477e8-87f5-4623-beae-193aecfa2725",
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropicChain=PromptTemplate.from_template(\n",
    "    template=\"\"\"\n",
    "        You are an expert in anthropic.\\\n",
    "        Always answer questions starting with \"As Prof. Anthropic told me\". \\\n",
    "        Respond to the following question:\n",
    "\n",
    "        Question: {question}\n",
    "        Answer:\n",
    "    \"\"\"\n",
    ")| llmGemini|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "383a61fd-dcb6-4366-9624-6cfed57c496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generalChain=PromptTemplate.from_template(\n",
    "    template=\"\"\"\n",
    "        Respond to the following question:\n",
    "\n",
    "        Question: {question}\n",
    "        Answer:\n",
    "    \"\"\"\n",
    ")| llmGemini|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fcd5110-f532-4932-8907-ff13ec5defa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(info):\n",
    "    if \"anthropic\" in info[\"topic\"].lower():\n",
    "        return anthropicChain\n",
    "    elif \"langchain\" in info[\"topic\"].lower():\n",
    "        return langchainChain\n",
    "    else:\n",
    "        return generalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84267ce3-ccf1-46c2-b3dc-0b02d3c1a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalChain=RunnableParallel(\n",
    "    {\"topic\":chain,\"question\":RunnablePassthrough()}\n",
    ")|RunnableLambda(func=route)|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69b491d8-5c46-4959-b1ce-b3be98c96c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As Prof. Anthropic told me, Claude is a family of large language models created by Anthropic. It's designed to be helpful, harmless, and honest, aiming to be a useful AI assistant. Claude is known for its strong reasoning abilities, its ability to generate creative content, and its commitment to safety and ethical considerations in AI. Think of it as a powerful AI that's been carefully trained to be a responsible and beneficial tool.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalChain.invoke(input=\"What is Claude?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ddbb73b-fc6b-4e1e-ab50-313e0fe55d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As Prof. Langchain told me, a `ChatPromptTemplate` in Langchain is a way to structure and define prompts specifically for chat models. It\\'s designed to handle the multi-turn conversational nature of chat models, where you have a sequence of messages (e.g., system message, human message, AI message) rather than just a single prompt string.\\n\\nHere\\'s a breakdown of what it is and why it\\'s useful:\\n\\n*   **Purpose:** To create structured prompts for chat models, allowing you to define different roles (system, human, AI) and their corresponding message content.\\n\\n*   **Key Features:**\\n\\n    *   **Message Templates:** It\\'s built from a sequence of `BaseMessagePromptTemplate` objects. These templates define the role (e.g., `SystemMessagePromptTemplate`, `HumanMessagePromptTemplate`, `AIMessagePromptTemplate`) and the content of each message.\\n    *   **Variables:**  Message templates can include variables that are dynamically filled in at runtime using user-provided data. This allows you to create personalized and context-aware prompts.\\n    *   **Flexibility:**  It allows you to create complex conversational flows by defining the order and content of messages from different roles.\\n    *   **Standardization:** Provides a standardized way to define prompts, making it easier to reuse and maintain them.\\n\\n*   **How it Works:**\\n\\n    1.  **Define Message Templates:** You create individual message templates for each role you want to include in the conversation (system, human, AI). These templates contain the text of the message and any variables that need to be filled in.\\n    2.  **Assemble into a Template:** You combine these message templates into a `ChatPromptTemplate`. The order of the message templates determines the order of messages in the final prompt.\\n    3.  **Format the Prompt:** When you want to use the prompt, you call the `format()` or `format_messages()` method of the `ChatPromptTemplate`, providing the values for any variables in the message templates.\\n    4.  **Pass to Chat Model:** The formatted messages (a list of `BaseMessage` objects) are then passed to the chat model.\\n\\n*   **Example:**\\n\\n    ```python\\n    from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\\n    from langchain.prompts import SystemMessagePromptTemplate\\n\\n    template = ChatPromptTemplate.from_messages([\\n        SystemMessagePromptTemplate.from_template(\"You are a helpful assistant that translates {input_language} to {output_language}.\"),\\n        HumanMessagePromptTemplate.from_template(\"{text}\"),\\n    ])\\n\\n    prompt = template.format_messages(input_language=\"English\", output_language=\"French\", text=\"Hello, how are you?\")\\n\\n    print(prompt)\\n    ```\\n\\n    In this example, we define a `ChatPromptTemplate` with a system message (setting the role of the AI) and a human message (containing the user\\'s input). The `format_messages()` method fills in the variables and returns a list of `BaseMessage` objects, which can then be passed to a chat model.\\n\\n*   **Benefits:**\\n\\n    *   **Improved Control:** Gives you fine-grained control over the structure and content of prompts.\\n    *   **Context Management:** Makes it easier to manage the context of a conversation by explicitly defining the roles and content of each message.\\n    *   **Reusability:** Allows you to create reusable prompt templates that can be customized for different scenarios.\\n    *   **Maintainability:** Makes prompts easier to maintain and update.\\n\\nIn summary, `ChatPromptTemplate` is a powerful tool for building structured prompts for chat models in Langchain. It provides a flexible and standardized way to define conversational flows and manage the context of multi-turn conversations.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalChain.invoke(input=\"What is ChatPromptTemplate?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ab24136-caf7-44eb-8210-d3b64a714b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eklavya was a remarkable character from the Hindu epic, the Mahabharata. He was a young tribal prince known for his exceptional archery skills and unwavering devotion to his guru, Dronacharya. Although Dronacharya refused to accept him as a formal student due to his caste, Eklavya practiced diligently on his own, using a clay statue of Dronacharya as his guide. He became a more skilled archer than Arjuna, Dronacharya's favorite and most prized student. To uphold his promise to Arjuna that he would be the greatest archer, Dronacharya asked Eklavya for his right thumb as guru dakshina (teacher's fee). Eklavya, without hesitation, sacrificed his thumb, demonstrating his ultimate respect and devotion to his guru. This act crippled his archery abilities, but cemented his place in the epic as a symbol of dedication, self-learning, and the complexities of social hierarchy in ancient India.\n"
     ]
    }
   ],
   "source": [
    "print(finalChain.invoke(input=\"Who was Eklavya?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b01777-d6b6-42c7-8270-ed0afd7488c4",
   "metadata": {},
   "source": [
    "<h3> Routing by Symantic Similarity</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce96bf6d-4460-405f-bea2-eed9ed03a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95cc795d-520f-440a-8785-aa357c078d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\n",
    "You are so good because you are able to break down hard problems into their component parts, \\\n",
    "answer the component parts, and then put them together to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0cbd700-2293-4c9d-a6e9-21efc63dbaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_1456\\481481593.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings=SentenceTransformerEmbeddings()\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_1456\\481481593.py:1: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embeddings=SentenceTransformerEmbeddings()\n",
      "c:\\Users\\MSI\\anaconda3\\envs\\lcnenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings=SentenceTransformerEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6922a88-d874-4ad9-8571-9c97f8eed6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "promptTemplates=[physics_template,math_template]\n",
    "promptEmbeddings=embeddings.embed_documents(texts=promptTemplates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ea669a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(promptEmbeddings),len(promptEmbeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "843b526e-62d9-4fe0-a6d1-3ef35beb57f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustrations\n",
    "questions=[\"What's a Black Hole?\",\"What's Integral Calculus?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e87e6c2-01e1-41ff-b5ef-77b59aa5455e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25714647, 0.18505651],\n",
       "       [0.242622  , 0.2775209 ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(X=embeddings.embed_documents(texts=questions),Y=promptEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "590d7d62-6faf-40a5-8192-1673eea4a5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(X=embeddings.embed_documents(texts=questions),Y=promptEmbeddings).argmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9be65c38-c7ef-47d9-9b6c-5ed729b38566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promptRouter(input) -> ChatPromptTemplate:\n",
    "    queryEmbedding=embeddings.embed_query(text=input['query'])\n",
    "    similarity=cosine_similarity(X=[queryEmbedding],Y=promptEmbeddings)[0]\n",
    "    mostSimilarTemplate=promptTemplates[similarity.argmax()]\n",
    "    print(\"Using Math Template\" if mostSimilarTemplate==math_template else \"Using Physics Template\")\n",
    "    return PromptTemplate.from_template(template=mostSimilarTemplate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a91dc0bd-31f9-4c51-879b-f41c5a244058",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain={\"query\":RunnablePassthrough()}|RunnableLambda(func=promptRouter)|llmGemini|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "008b9e43-8beb-4387-85cb-8373d9f468b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Physics Template\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ah, an excellent question!\\n\\nIn a nutshell, a black hole is a region in spacetime where gravity is so strong that nothing, not even light, can escape.\\n\\nHere\\'s a breakdown:\\n\\n*   **Formation:** Black holes typically form from the remnants of massive stars that have exhausted their nuclear fuel. When these stars die, they collapse under their own gravity. If the star is massive enough, this collapse continues until all of its matter is crushed into an incredibly small space.\\n\\n*   **Event Horizon:** The \"point of no return\" around a black hole is called the event horizon. It\\'s the boundary beyond which escape is impossible. Think of it like a waterfall: once you\\'re over the edge, there\\'s no going back.\\n\\n*   **Singularity:** At the center of a black hole, according to current theory, lies a singularity. This is a point of infinite density where the laws of physics as we know them break down.\\n\\n*   **Gravity:** The immense gravity of a black hole warps the space and time around it. This distortion is what allows black holes to capture light and other forms of electromagnetic radiation.\\n\\nIn simple terms, imagine a cosmic vacuum cleaner with incredibly powerful suction. That\\'s a black hole!'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input=\"What's a Blackhole?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7599cf10-e283-408f-b84a-fa37ca5b5357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Math Template\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Okay, I can definitely break down the concept of trigonometry and explain it clearly. Here's how I'll approach it:\\n\\n1.  **Core Meaning/Etymology:** Start with the basic definition and where the word comes from.\\n2.  **Fundamental Concepts:** Explain the core relationships between angles and sides of triangles, especially right triangles.  This includes the trigonometric functions (sine, cosine, tangent, etc.).\\n3.  **Unit Circle:** Explain the unit circle and how it extends trigonometric functions beyond acute angles.\\n4.  **Applications:** Briefly touch on *why* trigonometry is useful in various fields.\\n5.  **Generalizations:** Mention how trigonometry extends beyond basic triangles to more abstract concepts.\\n\\nHere we go:\\n\\n**1. Core Meaning/Etymology:**\\n\\n*   Trigonometry, at its heart, is the study of the relationships between the angles and sides of triangles.\\n*   The word itself comes from Greek:\\n    *   *trigōnon* (triangle) + *metron* (measure)\\n\\n**2. Fundamental Concepts:**\\n\\n*   **Right Triangles:** The foundation of trigonometry lies in right-angled triangles (triangles with one angle of 90 degrees).\\n\\n    *   **Sides:** In a right triangle, we have:\\n        *   **Hypotenuse:** The side opposite the right angle (the longest side).\\n        *   **Opposite:** The side opposite to the angle we are considering (other than the right angle).\\n        *   **Adjacent:** The side adjacent to the angle we are considering (other than the right angle and the hypotenuse).\\n\\n    *   **Trigonometric Functions (Ratios):** These functions relate an angle to the ratio of two sides of the right triangle:\\n\\n        *   **Sine (sin):**  sin(angle) = Opposite / Hypotenuse\\n        *   **Cosine (cos):** cos(angle) = Adjacent / Hypotenuse\\n        *   **Tangent (tan):** tan(angle) = Opposite / Adjacent\\n        *   **Cosecant (csc):** csc(angle) = 1 / sin(angle) = Hypotenuse / Opposite\\n        *   **Secant (sec):** sec(angle) = 1 / cos(angle) = Hypotenuse / Adjacent\\n        *   **Cotangent (cot):** cot(angle) = 1 / tan(angle) = Adjacent / Opposite\\n\\n    *   **Mnemonic:** A common mnemonic to remember the primary ratios is **SOH CAH TOA**:\\n        *   **S**ine = **O**pposite / **H**ypotenuse\\n        *   **C**osine = **A**djacent / **H**ypotenuse\\n        *   **T**angent = **O**pposite / **A**djacent\\n\\n*   **Angle Measurement:** Angles are commonly measured in degrees (where a full circle is 360 degrees) or radians (where a full circle is 2π radians).\\n\\n**3. Unit Circle:**\\n\\n*   The **unit circle** is a circle with a radius of 1 centered at the origin of a coordinate plane.  It's a powerful tool for extending the definitions of trigonometric functions beyond angles between 0 and 90 degrees.\\n\\n*   **How it works:**\\n    *   For any angle θ, draw a line from the origin that makes an angle of θ with the positive x-axis.\\n    *   The point where this line intersects the unit circle has coordinates (x, y).\\n    *   Then:\\n        *   cos(θ) = x\\n        *   sin(θ) = y\\n        *   tan(θ) = y/x\\n\\n*   **Benefits:**\\n    *   Allows us to define trigonometric functions for angles of any size (positive, negative, greater than 360 degrees).\\n    *   Visualizes the periodic nature of trigonometric functions (they repeat their values after every 360 degrees or 2π radians).\\n    *   Helps understand trigonometric identities (equations that are true for all values of the angles).\\n\\n**4. Applications:**\\n\\nTrigonometry is used extensively in:\\n\\n*   **Navigation:** Calculating distances and directions.\\n*   **Engineering:** Designing structures, bridges, and machines.\\n*   **Physics:** Analyzing wave motion, optics, and mechanics.\\n*   **Surveying:** Measuring land and creating maps.\\n*   **Computer Graphics:** Creating realistic images and animations.\\n*   **Astronomy:** Calculating the positions and movements of celestial objects.\\n\\n**5. Generalizations:**\\n\\n*   **Beyond Triangles:** While trigonometry originates from triangles, the trigonometric functions themselves are fundamental mathematical functions that appear in many areas beyond geometry. They are used to model periodic phenomena (like sound waves, light waves, and alternating current).\\n*   **Spherical Trigonometry:** Deals with triangles on the surface of a sphere, which is crucial for navigation on the Earth.\\n*   **Complex Numbers:** Trigonometric functions are intimately related to complex numbers through Euler's formula (e<sup>ix</sup> = cos(x) + i sin(x)).\\n\\n**In Summary:**\\n\\nTrigonometry is the study of the relationships between angles and sides of triangles. It uses trigonometric functions (sine, cosine, tangent, etc.) to relate angles to ratios of sides. The unit circle provides a way to extend these functions to all angles. Trigonometry has vast applications in various fields that involve angles, distances, and periodic phenomena. It's a foundational area of mathematics with far-reaching consequences.\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input=\"What's Trigonometry?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "461dc4d7-c8dc-4c25-bd63-d5410ac40d6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " +----------------------+  \n",
      " | Parallel<query>Input |  \n",
      " +----------------------+  \n",
      "             *             \n",
      "             *             \n",
      "             *             \n",
      "      +-------------+      \n",
      "      | Passthrough |      \n",
      "      +-------------+      \n",
      "             *             \n",
      "             *             \n",
      "             *             \n",
      "     +--------------+      \n",
      "     | promptRouter |      \n",
      "     +--------------+      \n",
      "             *             \n",
      "             *             \n",
      "             *             \n",
      "+------------------------+ \n",
      "| ChatGoogleGenerativeAI | \n",
      "+------------------------+ \n",
      "             *             \n",
      "             *             \n",
      "             *             \n",
      "    +-----------------+    \n",
      "    | StrOutputParser |    \n",
      "    +-----------------+    \n",
      "             *             \n",
      "             *             \n",
      "             *             \n",
      "+-----------------------+  \n",
      "| StrOutputParserOutput |  \n",
      "+-----------------------+  \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa71d689-462d-420a-9e88-72f3e0bd8436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcnenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
