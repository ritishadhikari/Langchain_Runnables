{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "591c6f01-7ea4-473b-be98-9ab8aa73dd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI 1\\.conda\\envs\\oaivenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough,RunnableLambda, Runnable, RunnableParallel,RunnableConfig,RunnableGenerator\n",
    "from langchain_core.messages import AIMessage\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from langchain.prompts import ChatPromptTemplate,SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from operator import itemgetter\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "import json\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import FAISS,Chroma\n",
    "from operator import itemgetter\n",
    "import time\n",
    "import grandalf\n",
    "from typing import Iterator,List,AsyncIterator\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain.runnables.hub import HubRunnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dc55a1a-cb69-4166-8b51-eab998d3b40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv(\"D:\\LLM Courses\\Master Langchain Udemy\\.env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4fcdc85-d669-4029-bba4-f0130ec5bfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f43a982-2e3a-4a28-b85c-948f41da974d",
   "metadata": {},
   "source": [
    "<h3> Configurable Fields </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f2e9d44-4319-4c01-adec-9127373f67e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ChatOpenAI(temperature=0)\\\n",
    "    .configurable_fields\\\n",
    "        (\n",
    "            temperature=ConfigurableField\n",
    "                            (\n",
    "                                id=\"llmTemperature\",\n",
    "                                name=\"LLM Temperature\",\n",
    "                                description=\"The temperature of the LLM\"\n",
    "                            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3d6922d-010c-4160-9425-2fcd990dced4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='7', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 17, 'total_tokens': 18, 'completion_tokens_details': {'reasoning_tokens': 0}, 'prompt_tokens_details': {'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-76b9e37d-9f22-473d-9734-49a23b30c87a-0', usage_metadata={'input_tokens': 17, 'output_tokens': 1, 'total_tokens': 18})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(input=\"Select a Random Number between 1 and 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b68060fe-ad00-4e6d-b5d9-5f2a564a2a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'27'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StrOutputParser().invoke(model.invoke(input=\"Select a Random Number\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8573f372-04e8-44e3-90a5-123a89d3d55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='27', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 11, 'total_tokens': 12, 'completion_tokens_details': {'reasoning_tokens': 0}, 'prompt_tokens_details': {'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7fc20648-9a9a-4541-8088-6e1b98c54f46-0', usage_metadata={'input_tokens': 11, 'output_tokens': 1, 'total_tokens': 12})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.with_config(config={\"llmTemperature\":0.3}).invoke(input=\"Select a Random Number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36a338cb-9aa1-412c-b64e-35ea55cfee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_template(template=\"Pick a random Number above {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f030361e-a343-4c12-813f-f95e2369f65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|llm|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b429653e-1b9b-4ad9-b75c-2df0df858da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I can't pick a truly random number as I'm a language model. However, I can generate a random number for you using a random number generator. \\n\\nThe random number above 23 is: **37** \\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.with_config(config={\"llmTemperature\":0.2}).invoke(input={\"x\":23})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e252f95e-cd31-4248-9fb4-e4fbe93e9021",
   "metadata": {},
   "source": [
    "<h3>Hub Runnable</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92ef15b4-580a-4972-a291-fb2820ec4edf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI 1\\.conda\\envs\\oaivenv\\Lib\\site-packages\\langsmith\\client.py:323: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prompt=HubRunnable(owner_repo_commit=\"rlm/rag-prompt\").configurable_fields(\n",
    "    owner_repo_commit=ConfigurableField(\n",
    "        id=\"hub_commit\",\n",
    "        name=\"Hub Commit\",\n",
    "        description=\"The Hub Commit to Pull from\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "120b70a4-09a1-4ba8-8979-fdd521a5cf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: {question} \n",
      "Context: {context} \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(prompt.default.bound.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7c4daa0a-0fbc-41bc-9ca0-ac846c664a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: foo \n",
      "Context: bar \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(prompt.invoke(input={\"question\":\"foo\",\"context\":\"bar\"}).messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcb97424-5383-48c4-a7a9-9d9924385c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI 1\\.conda\\envs\\oaivenv\\Lib\\site-packages\\langsmith\\client.py:323: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]<<SYS>> You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.<</SYS>> \n",
      "Question: foo \n",
      "Context: bar \n",
      "Answer: [/INST]\n"
     ]
    }
   ],
   "source": [
    "print(prompt.with_config(\n",
    "    config={\"hub_commit\":\"rlm/rag-prompt-llama\"}\n",
    ").invoke(input={\"question\":\"foo\",\"context\":\"bar\"}).messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381c4825-98a9-410d-ade4-a9233b93ab5a",
   "metadata": {},
   "source": [
    "<h3> Configurable Alternatives</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "315836cd-a347-4d77-a6db-6710c09307ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGoogleGenerativeAI(temperature=0,model=\"gemini-1.5-flash\").configurable_alternatives(\n",
    "    which=ConfigurableField(id=\"llm\"),\n",
    "    default_key=\"gemini\",\n",
    "    openai=ChatOpenAI(model=\"gpt-3.5-turbo\",temperature=0)\n",
    "    ).configurable_fields(temperature=ConfigurableField(\n",
    "            id=\"llmTemperature\",\n",
    "            name=\"LLM Temperature\",\n",
    "            description=\"The temperature of the LLM\"  \n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a39b372-0da8-431b-9c10-02390f491ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_template(\n",
    "    template=\"Tell me a joke about {topic}\"\n",
    ")\n",
    "\n",
    "chain=prompt|llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7807f1c8-085f-41b5-976b-00ea39249c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the giraffe get a job at the library? \\n\\nBecause he was really good at reaching for the high shelves! ðŸ¦’ðŸ“š \\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-d99741d2-fbd0-48bd-9b05-4011660aa610-0', usage_metadata={'input_tokens': 8, 'output_tokens': 28, 'total_tokens': 36})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input={\"topic\":\"Giraffe\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "449ed7c6-a2cb-4ff0-9a56-af1290dbd6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the giraffe break up with the zebra? Because he was always telling tall tales!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 14, 'total_tokens': 34, 'completion_tokens_details': {'reasoning_tokens': 0}, 'prompt_tokens_details': {'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-aafcc223-3ee1-4608-9f9e-86050c13eec5-0', usage_metadata={'input_tokens': 14, 'output_tokens': 20, 'total_tokens': 34})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.with_config(\n",
    "    configurable={\"llm\":\"openai\",\"llmTemperature\":0.6}\n",
    ").invoke(input={\"topic\":\"Giraffe\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bf348ff-3d11-42ac-a98f-8c9ae6d2ae17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the giraffe get a job at the library? \\n\\nBecause he was really good at reaching for the high shelves! \\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-bbe83398-bc79-408d-be86-88a2ac7ba9c3-0', usage_metadata={'input_tokens': 8, 'output_tokens': 25, 'total_tokens': 33})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.with_config(\n",
    "    configurable={\"llm\":\"gemini\",\"llmTemperature\":0.3}\n",
    ").invoke(input={\"topic\":\"Giraffe\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a943dc7-85ef-40be-a51c-2097efcc26c9",
   "metadata": {},
   "source": [
    "<h3>With Prompts</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "747b06f8-ecdc-455e-8f76-1766b072034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_template(\n",
    "    template=\"Tell me a joke about {topic}\"\n",
    ").configurable_alternatives(\n",
    "    ConfigurableField(id=\"prompt\"),\n",
    "    default_key=\"joke\",\n",
    "    poem=ChatPromptTemplate.from_template(\n",
    "            template=\"Tell me a poem about {topic}\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c0cc32e-85e4-4208-bb7e-bb3371a1d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b58de0b1-b270-4234-baa7-5861d40f53d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='In the face of trials and tribulations,\\nPersistence is our guiding light,\\nThrough the darkest of situations,\\nIt keeps us pushing with all our might.\\n\\nWhen obstacles block our way,\\nAnd failure seems imminent,\\nPersistence helps us stay,\\nAnd continue our ascent.\\n\\nIt\\'s the fuel that drives us forward,\\nWhen all hope seems lost,\\nIt\\'s the voice that whispers, \"You can do it\",\\nNo matter the cost.\\n\\nWith persistence as our ally,\\nWe can conquer any foe,\\nNo challenge is too daunting,\\nNo mountain too high to go.\\n\\nSo let us hold onto this virtue,\\nAnd never let it fade,\\nFor with persistence as our compass,\\nSuccess will never evade.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 135, 'prompt_tokens': 13, 'total_tokens': 148, 'completion_tokens_details': {'reasoning_tokens': 0}, 'prompt_tokens_details': {'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-3e0b0a7f-1979-4cd2-b465-7e411b4923f1-0', usage_metadata={'input_tokens': 13, 'output_tokens': 135, 'total_tokens': 148})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.with_config(\n",
    "    configurable={\"llm\":\"openai\",\"llmTemperature\":0.6,'prompt':'poem'}\n",
    ").invoke(input={\"topic\":\"Persistence\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b455add0-9ad4-4fe7-ace4-4c0d3d6ff200",
   "metadata": {},
   "outputs": [],
   "source": [
    "openAIwithPoemPrompt=chain.with_config(\n",
    "    configurable={\"llm\":\"gemini\",\"llmTemperature\":0.6,'prompt':'poem'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08b5054a-f590-4704-a6e0-83a8da371dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The wind whispers through bamboo, a gentle, rustling sound,\n",
      "A silent symphony of nature, on hallowed, sacred ground.\n",
      "A single leaf falls, adrift on the breeze, a moment's fleeting grace,\n",
      "A reminder of impermanence, in time and in this space.\n",
      "\n",
      "A weathered stone sits, moss-covered, a witness to the years,\n",
      "Unmoved by storms that rage around, unburdened by fears.\n",
      "A simple cup of tea, held gently, the steam curls to the sky,\n",
      "Each sip a meditation, on the present, here and now, why?\n",
      "\n",
      "The mind, a restless monkey, leaps from thought to thought,\n",
      "But Zen invites us inward, to stillness, to be caught\n",
      "In the quiet of the moment, where truth is found at last,\n",
      "In the breath, the heartbeat, the present, forever and amassed.\n",
      "\n",
      "No need for grand pronouncements, no need for words to speak,\n",
      "Just the quiet understanding, a knowing, deep and meek.\n",
      "The path is paved with silence, with mindful steps we tread,\n",
      "In the stillness of our being, the true self is instead.\n",
      "\n",
      "So breathe in the cool air, let go of all you hold,\n",
      "Embrace the emptiness within, let your story unfold.\n",
      "For in the heart of Zen, a wisdom waits to be found,\n",
      "A peace that knows no boundaries, on sacred, hallowed ground. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(openAIwithPoemPrompt.invoke(input={\"topic\":\"Zen\"}).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414863ef-fb5d-4637-a8e7-70a96f32d021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
